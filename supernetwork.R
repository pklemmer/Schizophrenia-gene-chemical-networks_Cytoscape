## SETUP -----------------------------------------------------------------------------------------------------------------------

#Requires R 4.3.2 and Rtools 4.3
#dplyr 1.1.4; httr 1.4.7; BiocManager 1.30.22; rWikiPathways 1.22.1; RCy3 2.22.1
#Cytoscape 3.10.1

setwd("~/GitHub/SCZ-CNV")
  #Setting working directory
rm(list=ls(env=.GlobalEnv))
  #Cleaning up workspace
packages <- c("dplyr","httr","stringr","gprofiler2","rvest","tidyr","curl")
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
# if(!"rWikiPathways" %in% installed.packages()) {
#   if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
#   BiocManager::install("rWikiPathways")
# }
if(!"RCy3" %in% installed.packages()){
  if (!requireNamespace("BiocManager", quietly=TRUE))
    install.packages("BiocManager")
  BiocManager::install("RCy3")
}
 if(!"BridgeDbR" %in% installed.packages()){
   if (!requireNamespace("BiocManager", quietly=TRUE))
     install.packages("BiocManager")
   BiocManager::install("BridgeDbR")
 }
  #Checking if required packages are installed and installing if not
  #Different structure for rWikiPathways and RCy3 packages as these are not installed directly but via the BiocManager package
invisible(lapply(c(packages,"RCy3","BridgeDbR"), require, character.only = TRUE))
  #Loading libraries

sysdatetime <- Sys.time()
datetime <- format(sysdatetime, format = "%Y-%m-%d_%Hh%M")
dir.create("Outputs")
dir.create(sprintf("Outputs/Session-%s",datetime))
dir.create(sprintf("Outputs/Session-%s/Networks",datetime))
dir.create(sprintf("Outputs/Session-%s/Other",datetime))
  #Creating directories for outputs generated by this script to be saved in; new "Session" folder created each time the script is ran (contains generated networks, metadata, and sessionInfo)
nw_savepath <- sprintf("%1$s/Outputs/Session-%2$s/Networks/",getwd(),datetime)
other_savepath <- sprintf("%1$s/Outputs/Session-%2$s/Other/",getwd(),datetime)
dir.create(paste0(other_savepath,"WikiPathways"))
dir.create(paste0(other_savepath,"DisGeNET"))
dir.create(paste0(other_savepath,"AOP-Wiki"))
dir.create(paste0(other_savepath,"Clustering"))
dir.create(paste0(other_savepath,"CyTargetLinker"))
file.create(sprintf("Outputs/Session-%s/metadata.txt",datetime))
  #Creating a new metadata file with the current date and time as suffix for easier organisation
  #Such a metadata file should be generated every time this script is ran to record parameters and versions of functions or databases, including the time avoids files being overwritten if the script is run multiple times a day (can even include seconds if script is ran multiple times per minute)
metadata.add <- function(info) {
  write(sapply(info, as.character), sprintf("Outputs/Session-%s/metadata.txt",datetime),append=TRUE, sep = "\n")
}
metadata.add(sysdatetime)
metadata.add(Sys.timezone())
metadata.add("")
  #Adding the timezone, date, and time to the metadata 

invisible(file.create(sprintf("Outputs/Session-%s/sessioninfo-%s.txt",datetime,datetime)))
writeLines(capture.output(sessionInfo()),sprintf("Outputs/Session-%s/sessioninfo-%s.txt",datetime,datetime))
  #Generating and adding a sessionInfo file to the current session output folder

execution_times <- list()

start_section <- function(section_name) {
  execution_times[[section_name]] <<- Sys.time()
}

end_section <- function(section_name) {
  end_time <- Sys.time()
  start_time <- execution_times[[section_name]]
  execution_time <- end_time - start_time
  # Convert elapsed time to seconds
  execution_time_seconds <- as.numeric(execution_time, units = "secs")
  # Convert seconds to a human-readable format with two decimal places
  time_string <- format(round(execution_time_seconds, 2), nsmall = 2)
  # Add "s" for seconds
  time_string <- paste(time_string, "s", sep = "")
  measurements <- paste(section_name, "\t", time_string, "\n", sep = "")
  cat(measurements, file = sprintf("Outputs/Session-%s/execution-times.txt",datetime), append = TRUE)
  # Remove start time from the list
  execution_times[[section_name]] <- NULL
}


cytoscapePing()
cytoscapeVersionInfo()
  #Checking if Cytoscape is running and version info
metadata.add(capture.output(cytoscapeVersionInfo()))

checkinstall.app <- function(app) {
  status_string <- getAppStatus(app)
    #Getting install status of app
  words <- strsplit(status_string, " ")[[1]]
  last_word <- tail(words, 1)
    #getAppStatus returns a character string instead of a logical value, so the last word (usually either "Installed" or "Uninstalled") from the output is checked
  if (last_word == "Installed") {
    print(sprintf("App %s is already installed.",app))
    } else {
    installApp(app)
    print(sprintf("Installed app %s.",app))
    }
}
  #Function to check whether required Cytoscape apps are installed and installing them if not
applist <- c("stringApp","clusterMaker2","yFiles Layout Algorithms","CyTargetLinker")
  #WikiPathways v.3.3.10
  #DisGeNET-app v.7.3.0
  #CyTargetLinker v. 4.1.0
  #stringApp v. 2.0.2
  #BridgeDb v.1.2.0
  #clusterMaker2 v.2.3.4
lapply(applist,checkinstall.app)
  #Checking and installing (if required) necessary Cytoscape apps
lapply(applist,getAppInformation)
metadata.add("Required Cytoscape apps and versions:")
invisible(metadata.add(print(lapply(applist,getAppInformation))))
metadata.add("")

dir.create(paste0(getwd(),"/BridgeDb"))
bridgedb_dir <- paste0(getwd(),"/BridgeDb/Hs_Derby_Ensembl_108.bridge")
   #Defining directory in which BridgeDb mapping file is stored
getBridgeDbmap <- function(dir = bridgedb_dir, confirmation = "BridgeDb mapping file not detected. Download BridgeDb mapping file for Homo sapiens (800.4 MB)? (yes/no): ") {
   if(file.exists(dir)) {
     message("File already present at ", dir, " No files downloaded.")
   } else {
     confirm <- readline(prompt = confirmation)
     if (tolower(confirm) == "yes") {
       bridgedb_hs <- getDatabase("Homo sapiens",location=paste0(getwd(),"/BridgeDb"))
       message("BridgeDb mapping file downloaded to ",dir)
     } else {
       message("File download cancelled.")
       }
   }
 }
getBridgeDbmap()
  #Downloading the BridgeDb bridge file for Homo sapiens identifiers to the repo 
  #The directory is added to .gitignore to avoid uploading it to GitHub
  #This is a relatively large (800MB) file - downloading it once is sufficient
metadata.add("BridgeDb")
metadata.add("Homo sapiens bridge version 108")
metadata.add("")

# FUNCTION DICTIONARY-------------------------------------------------------------------------------------------------------------------
.defaultBaseUrl <- 'http://127.0.0.1:1234/v1'
  #Defining the default base URL found in the RCy3 source as R object for altmergeNetworks
altmergeNetworks <- function(               sources = NULL,
                                            title = NULL,
                                            operation = "union",
                                            nodeKeys = NULL,
                                            nodeMergeMap = NULL,
                                            nodesOnly = FALSE,
                                            edgeKeys = NULL,
                                            edgeMergeMap = NULL,
                                            networkMergeMap = NULL,
                                            inNetworkMerge = TRUE,
                                            base.url = .defaultBaseUrl) {
  cmd.string <- 'network merge' # a good start
  
  # sources must be suppled
  if(is.null(sources)) {
    message("Missing sources!")
    return(NULL)
  } else {
    sources.str <- paste(sources, collapse = ",")
    cmd.string <- paste0(cmd.string,' sources="',sources.str,'"')
  }
  
  # defaults
  cmd.string <- paste0(cmd.string,' operation=',operation)
  cmd.string <- paste0(cmd.string,' nodesOnly=',nodesOnly)
  cmd.string <- paste0(cmd.string,' inNetworkMerge=',inNetworkMerge)
  
  # optional args
  if(!is.null(title))
    cmd.string <- paste0(cmd.string,' netName="',title,'"')
  if(!is.null(nodeKeys))
    cmd.string <- paste0(cmd.string,' nodeKeys="',paste(nodeKeys, collapse = ","),'"')
  if(!is.null(edgeKeys))
    cmd.string <- paste0(cmd.string,' edgeKeys="',paste(edgeKeys, collapse = ","),'"')
  if(!is.null(nodeMergeMap)){
    nodeMergeMap.str <- paste(nodeMergeMap, collapse = ",")
    nodeMergeMap.str <- gsub("c\\(", "{", nodeMergeMap.str)
    nodeMergeMap.str <- gsub("\\)", "}", nodeMergeMap.str)
    cmd.string <- paste0(cmd.string,' nodeMergeMap="',nodeMergeMap.str,'"')
  }
  if(!is.null(edgeMergeMap)){
    edgeMergeMap.str <- paste(edgeMergeMap, collapse = ",")
    edgeMergeMap.str <- gsub("c\\(", "{", edgeMergeMap.str)
    edgeMergeMap.str <- gsub("\\)", "}", edgeMergeMap.str)
    cmd.string <- paste0(cmd.string,' edgeMergeMap="',edgeMergeMap.str,'"')
  }
  if(!is.null(networkMergeMap)){
    networkMergeMap.str <- paste(networkMergeMap, collapse = ",")
    networkMergeMap.str <- gsub("c\\(", "{", networkMergeMap.str)
    networkMergeMap.str <- gsub("\\)", "}", networkMergeMap.str)
    cmd.string <- paste0(cmd.string,' networkMergeMap="',networkMergeMap.str,'"')
  }
  
  res.data <- commandsPOST(cmd.string, base.url = base.url)
  
  if(!is.null(res.data$SUID))
    return(res.data$SUID)
  else
    return(res.data)
}
  #Normally, RCy3's 'mergeNetworks' function would be used to unify imported networks into one supernetwork
  #This function does however not work on the latest RCy3 release (v.2.22.1), but does work when running the script on RCy3 v.2.14.2
  #RCy3 2.14.2 requires R v.4.1.3, requiring the entire script to run on an old version of R for one function that is used once
  #Here, we redefine the function using the source code from RCy3 v.2.14.2 and simply use this alternate function to merge networks


sparqlquery <- function(endpoint,queryfile,output) {
  if (tolower(endpoint) %in% c("WikiPathways","wikipathways","wp","WP")) {
  file_path <- paste0(getwd(),sprintf("/Data/WikiPathways/%s",queryfile))
    #Specifying file path to the .txt file containing the query
  base_url <- "https://sparql.wikipathways.org/sparql/?default-graph-uri=&query="
  #Defining the base URL preceding all SPARQL URLs for the endpoint
  } else if (tolower(endpoint) %in% c("AOP-Wiki", "aopwiki","aop-wiki","AOPWiki")) {
    file_path <- paste0(getwd(),sprintf("/Data/AOP-Wiki/%s",queryfile))
    #Specifying file path to the .txt file containing the query
    base_url <- "https://aopwiki.rdf.bigcat-bioinformatics.org/sparql/?default-graph-uri=&query="
    #Defining the base URL preceding all SPARQL URLs for the endpoint
  } else if (tolower(endpoint) %in% c("DisGeNET","DGN","disgenet","Disgenet")) {
    file_path <- paste0(getwd(),sprintf("/Data/DisGeNET/%s",queryfile))
      #Specifying path to the .txt file containing the query
    base_url <- "http://rdf.disgenet.org/sparql/?default-graph-uri=&query="
      #Defining the base URL preceding all SPARQL URLs for the endpoint 
  } else
    print("Error: Please specify WikiPathways, DisGeNET or AOP-Wiki as endpoint.")
  querybody <- paste(readLines(file_path), collapse = "")
  #Reading a text file containing a SPARQL query stored in the repo
  encoded_query <- URLencode(querybody)
  #Encoding the query as URL
  full_url <- paste0(base_url, encoded_query, "&format=text/html&timeout=0&signal_void=on")
  #Joining the query from the text file and the base URL and adding that output is desired as HTML
  html <- read_html(full_url)
  #Sending the query to the SPARQL endpoint and extracting as HTML
  if(tolower(endpoint) %in% c("DisGeNET","DGN","disgenet","Disgenet")) {
    tablebody <- html %>% 
      html_element("body") %>%
      html_element("table") } 
    #DisGeNET has a slightly different HTML structure than AOP-Wiki and WikiPathways, so navigating to the table is done accordingly
  else
  tablebody <- html %>% 
    html_element("body") %>%
    html_element("div") %>%
    html_element("table")
  #Navigating to the table output by the SPARQL query
  assign(output, html_table(tablebody), envir=.GlobalEnv)
  #Getting the output as tibble
}
  #Function to send a SPARQL query defined in a local text file to the endpoint and extract to desired dataframe
  #Will not work if query includes comments ('# this is a comment') due to HTML conversion

createNodeSource <- function(source,doi=NULL) {
  if (source == "fromDisGeNET") {
  networkname <- getNetworkName()
  nodetable <- paste0(networkname," default  node") 
  } 
    #Networks imported from WikiPathways have a type in the node table designations, as they have 2 spaces between "default" and "node" instead of one
    #This check determines which node table name format is to be applied depending on the source (WikiPathways or other)
  else {
    networkname <- getNetworkName()
    nodetable <- paste0(networkname," default node") 
    }
  commandsRun(sprintf("table create column columnName=fromWikiPathways table=%s type=string",nodetable))
  commandsRun(sprintf("table create column columnName=fromDisGeNET table=%s type=string",nodetable))
  commandsRun(sprintf("table create column columnName=fromPublication table=%s type=string",nodetable))
  commandsRun(sprintf("table create column columnName=Publication.doi table=%s type=string",nodetable))
  commandsRun(sprintf("table create column columnName=fromSTRING table=%s type=string",nodetable))
    #Creating a new column for each source used for all networks
  if ( source == "STRINGnode") {
    commandsRun(sprintf('table set values columnName=%1$s handleEquations=false rowList="selected:true" table=%2$s value=1',source,nodetable))
  }
  else {
  commandsRun(sprintf("table set values columnName=%1$s handleEquations=false rowList=all table=%2$s value=1",source,nodetable))
    #Filling the new column of the corresponding source with 1 to indicate which source the node is imported from 
  }
  if (!is.null(doi)) {
  commandsRun(sprintf("table set values columnName=Publication.doi handleEquations=false rowList=all table=%1$s value=%2$s",nodetable,doi))
    #Adding doi for literature used if provided
  }
}
  #Function to create new column in node table specifying origin of network/node

# SCHIZOPHRENIA =======================================================================================================================
## IMPORTING AND MERGING ---------------------------------------------------------------------------------------------------------------
start_section("Importing and merging")

sparqlquery("DisGeNET","disgenet-query.txt","gda")
#Querying the DisGeNET SPARQL endpoint for genes associated to schizophrenia from curated sources
gda$disgenet_curated <- str_extract(gda$source, "(?<=/)[^/]*$")
gda$Entrez_gene <- str_extract(gda$gene, "(?<=/)[^/]*$")
gda$HGNC_symbol <- str_extract(gda$symbol, "(?<=/)[^/]*$")
gda <- subset(gda, select=c(disgenet_curated,Entrez_gene,HGNC_symbol,gdascore))
#cleaning data
gda <- gda %>%
  group_by(Entrez_gene, HGNC_symbol, gdascore) %>%
  mutate(disgenet_curated = paste(disgenet_curated, collapse = "; ")) %>%
  distinct()
gda <- gda[!duplicated(gda$Entrez_gene),]
#Concatenating to avoid duplicate gene rows if they are confirmed by multiple sources
mapper <- loadDatabase(bridgedb_dir)
#Loading bridgedb database
input <- data.frame(
  source = rep("H", length(gda[, 3])),
  identifier = gda[, 3]
)
#Making a new df to be used as input for bridgedb
#Map HGNC symbol
input <- input %>%
  rename(source=source,
         identifier=HGNC_symbol)
#Renaming cols for maps function compability
gda_map <- maps(mapper,input,"En")
#Mapping from HGNC to Ensembl
gda <- merge(gda,gda_map,by.x="HGNC_symbol",by.y="identifier",all.x=TRUE)
#Merging the GDA and mapping tables; some HGNC symbols can't be matched to Ensembl IDs but are still retained
gda <- subset(gda, select=c(HGNC_symbol,mapping,Entrez_gene,disgenet_curated,gdascore))
#Cleaning df
gda <- gda %>%
  rename(Ensembl=mapping)
man_map <- read.delim(paste0(getwd(),"/Data/DisGeNET/manual-maps.txt"),sep="\t")
#Reading a file containing manual mappings for some of the missing Ensembl ID
gda <- merge(gda, man_map, by="HGNC_symbol",all.x=TRUE)
#Merging the manual map and the gda df based on HGNC symbol as key column
gda$Ensembl.x[is.na(gda$Ensembl.x)] <- gda$Ensembl.y[is.na(gda$Ensembl.x)]
#Merging the Ensembl cols
gda <- select(gda, -Ensembl.y)
#Removing superfluous Ensembl col from manual mapping df
gda <- gda %>%
  rename(Ensembl = Ensembl.x)
gda$HGNC_symbol_source <- gda$HGNC_symbol
#Creating a duplicated Ensembl column for Cytoscape import
#Cleaning and renaming df
gda <- mutate_all(gda, ~ifelse(is.na(.),"",.))
#Replacing NA with empty strings for Cytoscape compatibility
write.table(gda,file=paste0(other_savepath,"DisGeNET/gda.tsv"),quote=FALSE,sep="\t",row.names=FALSE)
commandsRun(sprintf('network import file columnTypeList=sa,sa,sa,sa,sa,s delimiters=\\t file=%s firstRowAsColumnNames=true startLoadRow=1',paste0(other_savepath,"DisGeNET/gda.tsv")))
Sys.sleep(0.5)
renameNetwork("DisGeNET network")
createNodeSource("fromDisGeNET")
Sys.sleep(0.5)
metadata.add("DisGeNET")
metadata.add("DisGeNET SPARQL endpoint metadata:")
metadata.add(paste0("DisGeNET nodes: ",getNodeCount()))
metadata.add("")

sparqlquery("wp","metadataquery.txt","WikiPathways-SPARQL-metadata")
  #Getting the metadata of the endpoint used for the WikiPathways SPARQL queries
metadata.add("WikiPathways")
metadata.add("WikiPathways SPARQL endpoint metadata:")
metadata.add(`WikiPathways-SPARQL-metadata`)
  #Adding the fetched metadata to the metadata file for the session
  #It is technically possible that the metadata would describe an earlier version of the RDF if it is updated while the script runs but this is unlikely

sparqlquery("wp","pathwayquery.txt","wp_pathwaylist")
  #Getting a list of pathways corresponding to a keyword as per defined in the query
writeLines(wp_pathwaylist[["PWID"]], con=paste0(other_savepath,"WikiPathways/automaticpathways.txt"))
  #Saving the output pathway list to file
manualpathways <- readLines("Data/WikiPathways/Pathwaylists/manualpathways.txt")
  #Reading a file containing a list of manually selected pathways
allpathways <- c(wp_pathwaylist[["PWID"]],manualpathways)
  #Joining the list of manually and automatically selected pathways together
allpathways_URL <- paste0("<",allpathways,">")
  #Adding <> around all entries for easier use in SPARQL queries
  #URLs need to be surrounded by <> to be recognised as such
writeLines(allpathways_URL, con=paste0(other_savepath,"WikiPathways/allpathways.txt"))
  #Writing list of all pathways in SPARQL URL format to file




sparqlquery("wp","nodequery.txt","wp_nodelist")
  #Making a SPARQL query to the endpoint to get all nodes associated with a list of pathways
if (any(grepl("identifiers\\.org", wp_nodelist$Identifier))) {
  # Checking whether the 'Identifier' column contains the identifiers.org URL
  #This is to avoid issues later when the identifiers.org part is removed and the code is reran
  wp_nodelist$WPNodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
  #If 'identifiers.org' is still in the column, extract part of the string into a new column to see what type the identifier is
} else {
  # If 'identifiers.org' is not found, do nothing
}
wp_nodelist[] <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
  #Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV | deletion",wp_nodelist$PathwayTitle), 1, NA)
  #Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$WPNodeID <- wp_nodelist$Identifier
  #Generating a duplicate node identifier column since the original column will be lost during Cytoscape import due to it being selected as source column
write.table(wp_nodelist, file=paste0(other_savepath,"WikiPathways/nodelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
  #Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(other_savepath,"WikiPathways/nodelist.tsv")))
  #Importing a list of nodes from the output of a WikiPathways SPARQL query (get all nodes in pathways matching the keyword 'Schizophrenia' and some manually selected pathways)
Sys.sleep(0.5)
  #Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways nodes")

sparqlquery("wp","edgequery.txt","wp_edgelist")
  #Making a SPARQL query to the endpoint to get a list of source-target pairs from selected pathways
wp_edgelist[] <- lapply(wp_edgelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
  #Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
edge_df <- wp_edgelist[grepl("Interaction",wp_edgelist$source) | grepl("Interaction",wp_edgelist$target),]
  #Extracting rows containing "Interaction" in either the source or target column
  #Interaction nodes represent phosphorylation and the like and are not suitable for the network
  #They can still provide information about the connection of gene or other nodes so they can't just be deleted either
  #If an Interaction node is connected to two or more non-interaction nodes, these nodes should be connected to each other, and the interaction node can be deleted
interaction_freq <- table(edge_df$target)
edge_df_filtered <- edge_df[edge_df$target %in% names(interaction_freq[interaction_freq > 1]),]
  #Counting if a certain interaction occurs more than once; this implies that it is connected to more than one non-interaction node
unique_targets <- unique(edge_df_filtered$target)
for (target_val in unique_targets) {
  # Identify rows with duplicate target values
  rows_with_duplicate_target <- which(edge_df_filtered$target == target_val)
  
  if (length(rows_with_duplicate_target) > 1) {
    # Select one of the source values
    source_val_to_transpose <- edge_df_filtered$source[rows_with_duplicate_target[1]]
    
    # Transpose the source value to the target column in the row of the remaining source value
    edge_df_filtered$target[rows_with_duplicate_target[-1]] <- source_val_to_transpose
    
    # Remove duplicate rows
    edge_df_filtered <- edge_df_filtered[-rows_with_duplicate_target[1], ]
  }
}
  #Transposing the non-identifier nodes for source-target pairs; if two nodes are associated with the same interaction, they become source-target pairs
wp_edgelist <- wp_edgelist <- wp_edgelist[!grepl(".*interaction.*", wp_edgelist$source, ignore.case = TRUE) & 
                                            !grepl(".*interaction.*", wp_edgelist$target, ignore.case = TRUE), ]
  #Removing any row containing "Interaction"
wp_edgelist <- rbind(wp_edgelist,edge_df_filtered)
  #Appending the new source-target pairs to the original edge list

write.table(wp_edgelist, file=paste0(other_savepath,"WikiPathways/edgelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
  #Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,s,t" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(other_savepath,"WikiPathways/edgelist.tsv")))
  #Importing a list of source-target pairs from selected pathways from the ouput of a WikiPathways SPARQL query 
Sys.sleep(0.5)
  #Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways edges")

altmergeNetworks(sources = c("WikiPathways nodes","WikiPathways edges"),
                 title = "WikiPathways networks",
                 operation = "union",
                 nodeKeys=c("WPNodeID","name"))
  #Union merging the node and edge networks to extend the node list with corresponding edges
Sys.sleep(0.5)
createNodeSource("fromWikiPathways")
metadata.add(paste0("WikiPathways nodes: ",getNodeCount()))
metadata.add("")
deleteNetwork('WikiPathways nodes')
deleteNetwork('WikiPathways edges')

Sys.sleep(1)
  #Pausing the script for 1 second - when letting the script run without this, the publication source creation fails

commandsRun(sprintf("network import file columnTypeList='sa,sa,source,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(getwd(),"/Data/Publications/Trubetskoy.txt")))
  #Importing network from file
  #List of 120 genes implicated in Trubetskoy et al., doi: 10.1038/s41586-022-04434-5
commandsRun("table rename column columnName=Ensembl.ID newColumnName=Ensembl table=Trubetskoy.txt default node")
  #Renaming the Ensembl.ID column from the dataset to Ensembl for coherence with networks from other sources
commandsRun("table rename column columnName=Index.SNP newColumnName=snpID table=Trubetskoy.txt default node")
createNodeSource("fromPublication","10.1038/s41586-022-04434-5")
  #Adding literature as  source to all imported nodes and adding the doi of the corresponding paper
renameNetwork("Trubetskoy risk genes")
  #Renaming the newly imported network
metadata.add("Publications")
metadata.add("Trubetskoy et al. doi: 10.1038/s41586-022-04434-5")
metadata.add(paste0("Publication nodes: ",getNodeCount()))
metadata.add("")

sparqlquery("AOP-Wiki","metadataquery.txt","aopwikimetadata")
aopwikimetadata <- paste(aopwikimetadata$dataset, aopwikimetadata$date, sep ="\t")
metadata.add("AOP-Wiki")
metadata.add("AOP-Wiki SPARQL endpoint metadata:")
metadata.add(paste("Dataset","Date",sep="\t"))
metadata.add(aopwikimetadata)
metadata.add("")

networklist <- getNetworkList()
setCurrentNetwork(networklist[[1]])
for(i in 1:length(networklist)) {
  current <- getNetworkName()
  altmergeNetworks(c(current,networklist[[i]]), paste(current,networklist[[i]]),"union",inNetworkMerge = TRUE,nodeKeys=c("Ensembl","Ensembl"))
}
  #Looping through the network list to merge all currently open networks with each other, creating one large unified network
renameNetwork("Schizophrenia supernetwork")
networklist <- getNetworkList()
snw_scz <- getNetworkName()
  #Getting the name of the unified network to preserve it from deletion
lapply(networklist[networklist != snw_scz],deleteNetwork)
  #Deleting all networks besides newly generated unified network
snw_ensembl <- getTableColumns("node","Ensembl")
  #Getting all values in the Ensembl column of the supernetwork
input <- data.frame(
  source = rep("En", length(snw_ensembl[, 1])),
  identifier = snw_ensembl[, 1]
)
  #Making a new df to be used as input for bridgedb
  #Map Ensembl ID
snw_map <- maps(mapper,input,"H")
  #Mapping from Ensembl to HGNC
snw_map <- select(snw_map, c("identifier", "mapping"))
snw_map <- rename(snw_map,
                  Ensembl = identifier,
                  HGNCsymbol = mapping)
  #Selecting and renaming relevant columns from bridgeDb mapping output
loadTableData(snw_map,
              data.key.column = "Ensembl",
              table = "node",
              table.key.column = "Ensembl")
  #loading HGNC names for Ensembl IDs in supernetwork back to node table
snw_nostring_edges <- getEdgeCount()
metadata.add(paste0("Total nodes in supernetwork: ",getNodeCount()))
metadata.add("")
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW"),"CX", network = snw_scz, overwriteFile=TRUE)
  #Exporting the supernetwork as cx file

end_section("Importing and merging")


# stable <- getTableColumns("node",c("fromDisGeNET","fromPublication","fromWikiPathways"))
# stable$count_ones <- rowSums(!is.na(stable))
# combination_counts <- table(stable$count_ones)
# 
# sourcenames <- c("One source","Two sources","Three sources")
# visframe <- data.frame(sourcenames,combination_counts)
# visframe <- select(visframe, -Var1)
# visframe <- visframe %>%
#   mutate(relative_freq = Freq / sum(Freq))
# 
# ggplot(visframe,aes(x=factor(sourcenames,levels=c("One source","Two sources","Three sources")),y=Freq)) +
#   geom_bar(stat="identity", fill = 'darkorange2', width=0.5) +
#   labs(x=NULL,  y = "Counts", title = "Node counts by source") +
#   scale_y_continuous(trans="log10", breaks=c(1,10,100,1000,2000)) +
#   theme_minimal()


## STRING --------------------------------------------------------------------------------------------------------------------------
start_section("STRING")
commandsRun('string stringify colDisplayName=name column=Ensembl compoundQuery=true cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
  #Adding protein-protein interactions from STRING to the supernetwork
  #Interactions between nodes are poorly preserved during importing and merging, and really only WikiPathways provides edge information while DisGeNET and the publication only provide gene lists
metadata.add("STRING")
metadata.add("STRINGify parameters:")
metadata.add("- Perform STRINGification on: Ensembl")
metadata.add("- Query compounds: true")
metadata.add("- Cutoff: 0.9")
snw_string_edges <- getEdgeCount()
metadata.add(paste0("STRING-added edges: ",snw_string_edges - snw_nostring_edges))
metadata.add(paste0("Total edges in supernetwork: ",snw_string_edges))
metadata.add("")

marked_cols <- as.list(getTableColumnNames()[!(getTableColumnNames() %in% c("selected","name.copy" ,"SUID","shared name","name","fromDisGeNET","fromWikiPathways","Ensembl","fromPublication","Publication.doi","CNVassociated","PathwayID","WPNodeID","WPNodeIDType","snpID","HGNCsymbol","DisGeNETname","disgenet_curated","gdascore","Entrez_gene"))])
lapply(marked_cols, function(column) {
  deleteTableColumn(column=column)
})
  #Filtering columns
renameNetwork("SCZ_SNW_STRING")
scz_snw_string <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING"),"CX",network=scz_snw_string,overwriteFile=TRUE)
  #Exporting the filtered, stringified supernetwork as cx file and tagging it with the time and data to match with the metadata file
end_section("STRING")

## CLUSTERING ----------------------------------------------------------------------------------------------------------------------
start_section("Clustering")
createColumnFilter(filter.name="delete.noensembl", column="Ensembl","ENSG","DOES_NOT_CONTAIN")
deleteSelectedNodes()
metadata.add(paste0("Ensembl nodes in supernetwork: ",getNodeCount()))
metadata.add("")
metadata.add("GLay Clustering")
metadata.add(capture.output(commandsRun('cluster glay clusterAttribute=__glayCluster createGroups=false network=current restoreEdges=true showUI=true undirectedEdges=true')))
  #Clustering the network using the GLay community cluster from the clusterMaker Cytoscape app and recording outcome to metadata
renameNetwork("SCZ_SNW_STRING_clustered")
renameTableColumn('__glayCluster','gLayCluster') 
  #Renaming the newly generated gLayCluster column as the original name with two underscores is not recognized during gene ontology
snw_scz_string_clustered <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered"),"CX",network=snw_scz_string_clustered,overwriteFile=TRUE)
  #Exporting the filtered, stringified, clustered supernetwork as cx file and tagging it with the time and data to match with the metadata file


read_clustered_nodetable <- getTableColumns("node")
  #Reading the exported csv
split_df <- split(read_clustered_nodetable$Ensembl,read_clustered_nodetable$gLayCluster)
  #Splitting the node table by cluster
nodecount <- sapply(split_df, length)
  #Counting how many nodes are in each cluster
countmatrix <- matrix(seq(1,length(nodecount)), ncol=1)
countmatrix <- cbind(countmatrix,as.numeric(nodecount))
  #Construcing a matrix showing how many nodes are in each cluster
invalidclusters <- as.list(countmatrix[countmatrix[, 2] < 5, 1])
  #Getting which clusters have fewer than 5 nodes associated with them 
valid_clustered_nodetable <- read_clustered_nodetable[!read_clustered_nodetable$gLayCluster %in% invalidclusters, ]
  #Generating a new df containing only nodes associated with clusters that had 5 or more nodes
split_tbl <- split(valid_clustered_nodetable, valid_clustered_nodetable$gLayCluster)

# test <- split_tbl[[1]]
# test2 <- test[, c("fromWikiPathways", "fromDisGeNET", "fromPublication")]
# colnames(test2) <- c("fromWikiPathways", "fromDisGeNET", "fromPublication")
# 
# column_combinations_3 <- combn(colnames(test2),3,FUN=function(x) paste(x, collapse="_and_"))
# column_combinations_2 <- combn(colnames(test2),2,FUN=function(x) paste(x, collapse="_and_"))
# for (combination in column_combinations_2) {
#   test2[paste(combination,collapse="_and_")] <- test2[[combination[1]]] & test2[[combination[2]]]
# }
# for (combination in column_combinations_3) {
#   test2[paste(combination, collapse = "_")] <- test2[[combination[1]]] & test2[[combination[2]]] & test2[[combination[3]]]
# }
# 




sourcecount <- function(cluster) {
  wpcount <- sum(split_tbl[[cluster]][["fromWikiPathways"]] == 1, na.rm = TRUE)
  dgcount <- sum(split_tbl[[cluster]][["fromDisGeNET"]] == 1, na.rm = TRUE)
  litcount <- sum(split_tbl[[cluster]][["fromPublication"]] == 1, na.rm = TRUE)
  result_df <- data.frame(
    gLayCluster = split_tbl[[cluster]][["gLayCluster"]][1],
    WikiPathways_source = wpcount,
    DisGeNET_source = dgcount, 
    Publication_source = litcount
  )
}
sources_count <- do.call(rbind, lapply(seq_along(split_tbl),sourcecount))
  #For each cluster, counting how many nodes are associated with which sources
cnvassociatedcount <- function(cluster) {
  cnvcount <- sum(split_tbl[[cluster]][["CNVassociated"]] == 1,na.rm=TRUE)
  total_wp_nodes <- sources_count[sources_count$gLayCluster == split_tbl[[cluster]][["gLayCluster"]][1], "WikiPathways_source"]
  non_cnv_count <- total_wp_nodes - cnvcount
  result_df <- data.frame(
    gLayCluster = split_tbl[[cluster]][["gLayCluster"]][1],
    WikiPathways_CNV = cnvcount,
    WikiPathways_noCNV = non_cnv_count
  )
}
cnvassociated_count <- do.call(rbind,lapply(seq_along(split_tbl),cnvassociatedcount))
  #For each cluster, count how many nodes originally come from CNV-associated pathways which pathways they come from 

end_section("Clustering")

## GO ANALYSIS ------------------------------------------------------------------------------------------------------------------------
start_section("GO Analysis")

split_df <- split(valid_clustered_nodetable$Ensembl,valid_clustered_nodetable$gLayCluster)
split_list <- lapply(split_df, as.vector)
  #Splitting the node table by cluster number, i.e. lists of Ensembl IDs are created per cluster
go <- function(cluster) {
  gost(
    query = cluster,
    organism = "hsapiens",
    ordered_query = FALSE,
    multi_query = TRUE,
    significant = TRUE,
    exclude_iea = FALSE,
    measure_underrepresentation = FALSE,
    evcodes = FALSE,
    user_threshold = 0.05,
    correction_method = "g_SCS",
    domain_scope ="annotated",
    custom_bg = NULL,
    numeric_ns = "",
    sources = NULL,
    as_short_link = FALSE,
    highlight = TRUE
  )
}
go_list <- lapply(split_list,go)
  #Iterating the gost GO function over all clusters
get_top_terms <- function(cluster) {
  terms <- toString(go_list[[cluster]][["result"]][["term_name"]][1:5])
    #Extracting the top 5 term names associated with each cluster
  pval <- toString(go_list[[cluster]][["result"]][["p_values"]][1:5])
    #Extracting the p-values for the corresponding top 5 term names
  nodes <- paste(go_list[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]],collapse=",")
  nnodes <- str_count(toString(go_list[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]]),"\\S+")
    #Extracing the number of nodes/genes contained in each cluster
  result_df <- data.frame(
    gLayCluster = cluster, 
    GO_Terms = terms, 
    GO_Pvals = pval,
    Nodes = nodes, 
    N_nodes = nnodes
    )
}
topterms_df <- do.call(rbind, lapply(names(go_list),get_top_terms))
  #Getting top 5 term names and corresponding p-values for each cluster and storing in topterms_df
topterms_df <- cbind(topterms_df,sources_count,cnvassociated_count)
  #joining the cluster table and the table detailing the amount of sources per cluster
write.table(topterms_df, file=paste0(other_savepath,"Clustering/GO-clusters-vis.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
  #Writing the table to file for Cytoscape import during visualisation
loadTableData(topterms_df,data.key.column="gLayCluster",table.key.column="gLayCluster")
  #Loading the generated top terms and p-values back to the supernetwork; every gene belonging to cluster x is now associated with the top terms of cluster x
deleteTableColumn('gLayCluster.1')
  #Deleting duplicate gLayCluster column that appears after importing top terms data back to network 
renameNetwork(title=paste0(getNetworkName(),"_GO"))
snw_scz_filtered_string_clustered_go <- getNetworkName()
  #Renaming and saving the network name to indicate addition of GO information

compare_term_id_lists <- function(list1, list2) {
  common_elements <- intersect(list1, list2)
  return(length(common_elements))
}
  #Setting up a function to get intersections between cluster term IDs
match_df <- data.frame(Cluster1 = character(),
                        Cluster2 = character(),
                        Matches = numeric(),
                        stringsAsFactors = FALSE)
  #Setting up a df to store output in 
for (i in 1:(length(go_list) - 1)) {
  for (j in (i + 1):length(go_list)) {
    term_id_i <- go_list[[i]][["result"]][["term_id"]]
    term_id_j <- go_list[[j]][["result"]][["term_id"]]
    
    matches <- compare_term_id_lists(term_id_i, term_id_j)
    
    match_df <- rbind(match_df, data.frame(Cluster1 = names(go_list)[i],
                                             Cluster2 = names(go_list)[j],
                                             Matches = matches))
    #Iterating over go_list to compare GO term IDs between every cluster and store number of overlaps
  }
}
colnames(match_df) <- c("source","target","GO_term_matches")
  #Renaming columns
write.table(match_df, file=paste0(other_savepath,"Clustering/match_df.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO"),"CX",network=snw_scz_filtered_string_clustered_go,overwriteFile=TRUE)
  #Exporting the filtered, stringified, clustered supernetwork after GO as cx file and tagging it with the time and data to match with the metadata file

end_section("GO Analysis")

##AOP-Wiki extension ---------------------------------------------------------------------------------------------------------------------------
start_section("AOP-Wiki extension")

aopprocess <- function(input,keep,tag) {
  if (!"SCZ_SNW_STRING_clustered_GO" %in% getNetworkList()) {
    importNetworkFromFile(file=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO.cx"))
    commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
    createColumnFilter(
      filter.name = "has_GO_result",
      column = "N_nodes",
      criterion = 0,
      predicate = "GREATER_THAN",
      anyMatch = TRUE,
      apply = TRUE
    )
    #Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
    #N_nodes is only generated for 'valid' clusters, so good column to filter by
    invertNodeSelection()
    deleteSelectedNodes()
    #Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
    #Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way 
    #The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
  }
  else {
    commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
    createColumnFilter(
      filter.name = "has_GO_result",
      column = "N_nodes",
      criterion = 0,
      predicate = "GREATER_THAN",
      anyMatch = TRUE,
      apply = TRUE
    )
    #Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
    #N_nodes is only generated for 'valid' clusters, so good column to filter by
    invertNodeSelection()
    deleteSelectedNodes()
    #Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
    #Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way 
    #The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
    
  }
  
  #Reimporting the network with GO information back to Cytoscape if needed
  #Running aopprocess causes all changes to be applied to the GO network
  #Running aopprocess a second time with other parameters would thus compound changes into the same network which is undesired
  
  sparqlquery("AOP-Wiki",input,"keensgpairs")
  #Querying AOP-Wiki for a list of all KEs and associated genes
  for (i in 1:ncol(keensgpairs)) {
    for (j in 1:nrow(keensgpairs)) {
      keensgpairs[j, i] <- gsub('"', '', keensgpairs[j, i])
    }
  }
  #Removing quotation marks from the df
  
  separate_keensgpairs <- separate_rows(keensgpairs,Ensembl,sep="; ")
  #Dividing comma-separated Ensembl IDs into distinct rows
  keensgpairs_byensg <- separate_keensgpairs %>%
    group_by(Ensembl) %>%
    summarise(KEid = paste(KEid, collapse="; "),
              AOPid = paste(AOPid, collapse="; "))
  #Concatenating other variables based on unique Ensembl ID to get list of associated KEs and AOPs per gene
  keensgpairs_byensg_save <- paste0(other_savepath,sprintf("AOP-Wiki/keensgpairs_byensg_%s.tsv",tag))
  #Defining savepath for newly generated df
  write.table(keensgpairs_byensg, file=keensgpairs_byensg_save,quote=FALSE, sep="\t", row.names=FALSE)
  #Saving df containing gene-KE-AO-AOP associations to file as tsv for Cytoscape import
  commandsRun(sprintf('table import file dataTypeTargetforNetworkCollection="Node Table Columns" delimiters=\\t file=%s firstRowAsColumnNames=true keyColumnForMapping="Ensembl" keyColumnIndex=1 startLoadRow=1',keensgpairs_byensg_save))
  #Importing the gene-KE-AO-AOP table to Cytoscape as table add AOP-Wiki info as node attributes
  renameNetwork(paste0(getNetworkName(),"_AOP"))
  scz_snw_string_go_aop <- getNetworkName()
  scz_snw_string_go_aop_node <- getTableColumns("node")
  #Reading the exported table as Cytoscape object
  aop_associated_genes <- scz_snw_string_go_aop_node[!is.na(scz_snw_string_go_aop_node$KEid), , drop=FALSE]
  #Getting which rows (=gene nodes) have info from AOP-Wiki associated to them
  renameNetwork(paste0(getNetworkName(),"_",tag))
  
  summary_go_terms <- read.delim(paste0(getwd(),"/Data/summary_go_terms.txt"),header=TRUE,sep="\t",quote="")
  #Loading cluster titles based on GO terms
  
  if(keep == TRUE) {
    aop_associated_genes <- scz_snw_string_go_aop_node }
  aop_associated_genes <- merge(aop_associated_genes,summary_go_terms,"gLayCluster")
Sys.sleep(1)
  separate_ketitles <- separate_rows(aop_associated_genes,KEid,sep="; ")
  ke_freq_table <- table(separate_ketitles$KEid) 
  ke_freq_df <- as.data.frame(ke_freq_table)
  add_attributes <- separate_ketitles %>%
    group_by(KEid) %>%
    summarise (KEEnsembl = paste(Ensembl,collapse="; "),
               KEgenename = paste(HGNCsymbol, collapse="; "),
               KEsummary_go_term = paste(summary_term, collapse="; "))
  names(ke_freq_df) <- c("KEid","KE_frequency")
  ke_freq_df_full <- merge(ke_freq_df, add_attributes,"KEid",all.y=TRUE)
  #Counting how often which KEs are associated with all genes
  
  ke_associated_genes_freq <- ke_freq_df_full
  
  aop_link <- list()
  
  variables <- ls()
  #Getting a list of variables defined within the aopprocess function
  #append_suffix <- function(variable, suffix) {
  #assign(paste0(variable,"_",suffix), get(variable), envir = .GlobalEnv)
  #}
  #Defining a function to add a suffix to the variables created within the aopprocess function
  for (variable in variables) {
    aop_link[[variable]] <- get(variable)
  }
  return(aop_link)
  #Appending the given tag to every produced variable within the aopprocess function
  #Saving the resulting network
}


aoplink_all <- aopprocess("all_AO_KE_Ensembl_query.txt",TRUE,"all")
  #Second function argument specifies whether to save all (gene) rows from the network (=true) or only rows that have AOP-Wiki data ssociated with them 
  #Matching AOP information to risk genes in the network from all AOs available in AOP-Wiki
snw_scz_string_clustered_GO_AOP_all <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO_AOP_all"),"CX",network=snw_scz_string_clustered_GO_AOP_all,overwriteFile=TRUE)
#Exporting network


nclusters <- as.character(count(unique(getTableColumns("node","gLayCluster"))))
  #Counting how many valid clusters remain
metadata.add(paste0("Valid (>= 5 nodes) clusters: ",nclusters))
metadata.add(paste0("Nodes associated with valid clusters: ",getNodeCount()))
metadata.add("")



gettop <- function(input) {
  freq_df <- input$ke_freq_df_full
  #cutoff_ke <- quantile(freq_df$KE_frequency, probs=0.75,na.rm = TRUE)
  #Defining cutoff for KE frequency (top 25% most frequent)
  #topquarter_ke <- freq_df[freq_df$KE_frequency >= cutoff_ke & !is.na(freq_df$KE_frequency),,drop=FALSE]
  #Selecting the top 25% most frequently matched with KEs and associated information
  topquarter_ke <- freq_df
}

top_all <- gettop(aoplink_all)



getkegenepairs <- function(input) {
  topquarter_ke <- input
  topquarter_ke_sep <- separate_rows(topquarter_ke,KEEnsembl,sep="; ")
  mergedkeensg <- union(topquarter_ke_sep$KEid,topquarter_ke_sep$KEEnsembl)
  #topquarter_ke_node <- data.frame(combined=mergedkeensg)
  topquarter_ke<- topquarter_ke_sep[,c("KEid","KEEnsembl")]
  topquarter_ke <- topquarter_ke %>%
    rename(KEid_source = KEid,
           KEEnsembl_target = KEEnsembl)
    #Renaming columns to source and target for Cytoscape import
  topquarter_ke$KEid <- topquarter_ke$KEid_source
  topquarter_ke$Ensembl <- topquarter_ke$KEEnsembl_target
    #Creating duplicate columns of KEid and KEEnsembl to be used as source and target attributes
    #This allows new columns in the network to easily select Ensembl and KE nodes separately etc.
    #Without this, both KE and Ensembl nodes are stored in the 'names' column due to how Cytoscape import works
  sparqlquery("AOP-Wiki","kemap.txt","kemap")
  #Running query to get KEid-title mappings
  for (i in 1:ncol(kemap)) {
    for (j in 1:nrow(kemap)) {
      kemap[j, i] <- gsub('"', '', kemap[j, i])
    }
  }
  #Removing quotation marks from df
  topquarter_ke <- merge(topquarter_ke,kemap,by="KEid",all.x=TRUE)
  #Merging the mapping and node tables to extend node table with KE titles
  topquarter_ke <- topquarter_ke[,c("KEid_source","KEEnsembl_target","KEid","KEtitle","Ensembl")]
  #Reordering table columns
  #write.table(topquarter_ke_node, file=paste0(getwd(),"/topquarter_ke_node.tsv"),sep="\t",quote=FALSE,row.names=FALSE)
  write.table(topquarter_ke, file=paste0(other_savepath,sprintf("AOP-Wiki/topquarter_ke_edge%s.tsv",sub("top","",deparse(substitute(input))))),sep="\t",quote=FALSE,row.names=FALSE)
  #Writing the KE-gene table to file for Cytoscape import
  commandsRun(sprintf('network import file columnTypeList=s,t,sa,sa,ta delimiters=\\t file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1',paste0(other_savepath,sprintf("AOP-Wiki/topquarter_ke_edge%s.tsv",sub("top","",deparse(substitute(input)))))))
  #Importing as network
  Sys.sleep(0.5)
  renameNetwork(sprintf("Top quarter key events - risk genes%s",sub("top","",deparse(substitute(input)))))
}


getkegenepairs(top_all)
kegenenetwork_all <- getNetworkName()
selectNodes("NA","KEid")
deleteSelectedNodes()
  #Selecting and deleting a 'NA' node that results from all the genes not associated to any AOP data 

# commandsRun('string stringify colDisplayName=label column=Ensembl compoundQuery=false cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
# altmergeNetworks(sources = c("Top quarter key events - risk genes_all", "STRING network - Top quarter key events - risk genes_all"),
#                  title = "Top quarter key events - risk genes_all STRINGified",
#                  operation = "union",
#                  nodeKeys = c("shared name","shared name"))

getkeaoppairs <- function(input) {
keaoppairs <- keensgpairs[keensgpairs$KEid %in% input$KEid,c("KEid","AOPid")]
  #For top quarter KEs, get which AOPs these are taken from from result of initial AOP-Wiki query
keaoppairs <- separate_rows(keaoppairs,AOPid,sep="; ")
sparqlquery("AOP-Wiki","aopmap.txt","aopmap")
  #Running query to get AOPid-title mappings
for (i in 1:ncol(aopmap)) {
  for (j in 1:nrow(aopmap)) {
    aopmap[j, i] <- gsub('"', '', aopmap[j, i])
  }
}
  #Removing quotation marks from df
keaoppairs <- merge(keaoppairs,aopmap,by="AOPid",all.x=FALSE)
  #Mapping AOPids to AOPtitles using mapping file
keaoppairs <- keaoppairs %>%
  rename(KEid_target = KEid,
         AOPid_source = AOPid)
  #Renaming columns in preparation for import
keaoppairs$KEid <- keaoppairs$KEid_target
keaoppairs$AOPid <- keaoppairs$AOPid_source
  #Creating duplicate columns of KEid and AOPid to be used as source and target attributes
  #This allows new columns in the network to easily select AOP and KE nodes separately etc.
  #Without this, both KE and AOP nodes are stored in the 'names' column due to how Cytoscape import works
keaoppairs <- keaoppairs[,c("KEid_target","KEid","AOPid_source","AOPid","AOPtitle")]
  #Reordering columns
write.table(keaoppairs,file=paste0(other_savepath,sprintf("AOP-Wiki/keaoppairs%s.tsv",sub("top","",deparse(substitute(input))))),sep="\t",quote=FALSE,row.names=FALSE)
  #Writing modified table to file
commandsRun(sprintf('network import file columnTypeList=t,ta,s,sa,sa delimiters=\\t file=%s firstRowAsColumnNames=true rootNetworkList= -- Create new network collection -- startLoadRow=1',paste0(other_savepath,sprintf("AOP-Wiki/keaoppairs%s.tsv",sub("top","",deparse(substitute(input)))))))
  #Importing as network
Sys.sleep(0.5)
renameNetwork(sprintf("Top quarter key events - AOPs%s",sub("top","",deparse(substitute(input)))))
}


getkeaoppairs(top_all)
keaopnetwork_all <- getNetworkName()


getaopaopairs <- function(input) {
keaoppairs <- keensgpairs[keensgpairs$KEid %in% input$KEid,"AOPid"]
keaoppairs <- unique(separate_rows(keaoppairs,AOPid,sep="; "))
  #For top quarter KEs, get which unique AOPs these are taken from
sparqlquery("AOP-Wiki","aopao.txt","aopao")
  #Getting full list of which AOs are associated to which AOPs
aopaopairs <- aopao[aopao$AOPid %in% keaoppairs$AOPid,]
  #Filtering AOP-AO list by AOPs associated with top quarter KEs
sparqlquery("AOP-Wiki","aopmap.txt","aopmap")
#Running query to get AOPid-title mappings
for (i in 1:ncol(aopmap)) {
  for (j in 1:nrow(aopmap)) {
    aopmap[j, i] <- gsub('"', '', aopmap[j, i])
  }
}
#Removing quotation marks from df
aopaopairs <- merge(aopaopairs,aopmap,by="AOPid",all.x=FALSE)
#Mapping AOPids to AOPtitles using mapping file
sparqlquery("AOP-Wiki","aomap.txt","aomap")
for (i in 1:ncol(aomap)) {
  for (j in 1:nrow(aomap)) {
    aomap[j, i] <- gsub('"', '', aomap[j, i])
  }
}
#Removing quotation marks from df
aopaopairs <- merge(aopaopairs,aomap,by="AOid",all.x=FALSE)
  #Mapping AOids to AOtitles using mapping file
aopaopairs <- aopaopairs %>%
  rename(AOPid_target = AOPid,
         AOid_source = AOid)
  #Renaming columns in preparation for import
aopaopairs$AOid <- aopaopairs$AOid_source
aopaopairs$AOPid <- aopaopairs$AOPid_target
  #Creating duplicate columns of AOid and AOPid to be used as source and target attributes
  #This allows new columns in the network to easily select AOid and AOPid nodes separately etc.
  #Without this, both AO and AOP nodes are stored in the 'names' column due to how Cytoscape import works
aopaopairs$index <- NA
  #Creating an empty placeholder column that is to be filled with copies of row values from the SUID column; explained more in mergeaop function later
  #Must be created in df that then becomes a network, since creating a column using the Cytoscape command line will result in an 'invisible' column that cannot be used as key for merging tables
aopaopairs <- aopaopairs[,c("AOid_source","AOPid_target","AOid","AOtitle","AOPid","AOPtitle","index")]
  #Reordering columns
write.table(aopaopairs,file=paste0(other_savepath,sprintf("AOP-Wiki/aopaopairs%s.tsv",sub("top","",deparse(substitute(input))))),sep="\t",quote=FALSE,row.names=FALSE)
  #Writing modified table to file
commandsRun(sprintf('network import file columnTypeList=s,t,sa,sa,ta,ta,ta delimiters=\\t file=%s firstRowAsColumnNames=true rootNetworkList= -- Create new network collection -- startLoadRow=1',paste0(other_savepath,sprintf("AOP-Wiki/aopaopairs%s.tsv",sub("top","",deparse(substitute(input)))))))
  #Importing table as network
Sys.sleep(0.5)
renameNetwork(sprintf("AOP-AO pairs for top AOPs in top quarter KEs%s",sub("top","",deparse(substitute(input)))))
}
# getaopaopairs(top_selected)
# aopaonetwork_selected <- getNetworkName()

getaopaopairs(top_all)
aopaonetwork_all <- getNetworkName()



mergeaop <- function (input){
aopaonetwork <- get(paste0("aopaonetwork_",input))
keaopnetwork <- get(paste0("keaopnetwork_", input))
kegenenetwork <- get(paste0("kegenenetwork_",input))
  #Renaming variables to contain type of selection to correctly select previously generated objects
  
altmergeNetworks(sources=c(aopaonetwork,keaopnetwork),
                 title = "KE-AOP-AO merged network",
                 operation="union",
                 nodeKeys=c("AOPid","AOPid"))
renameNetwork(paste0("KE-AOP-AO merged network_",input))
  #Merging the AOP-AO network to the KE-AOP network to extend KE-AOP associations with AOs
keaopaomerged <- getNetworkName()

altmergeNetworks(sources=c(keaopaomerged,kegenenetwork),
                 title="gene-KE-AOP-AO merged network",
                 operation="union",
                 nodeKeys=c("KEid","KEid"))
  #Merging KE-AOP-AO associations with the KE-gene network to extend KE-gene associations with AOPs and AOs
renameNetwork(paste0("gene-KE-AOP-AO merged network_",input))

mergedaopnode <- getTableColumns("node","Ensembl")
#Getting values in the Ensembl column of AOP network
input <- data.frame(
  source = rep("En", length(mergedaopnode[, 1])),
  identifier = mergedaopnode[, 1]
)
#Making a new df to be used as input for bridgedb
#Map Ensembl ID
mergedaopnode_map <- maps(mapper,input,"H")
#Mapping from Ensembl to HGNC
mergedaopnode_map <- select(mergedaopnode_map, c("identifier", "mapping"))
mergedaopnode_map <- rename(mergedaopnode_map,
                            Ensembl = identifier,
                            HGNCsymbol = mapping)
#Selecting and renaming relevant columns from bridgeDb mapping output
loadTableData(mergedaopnode_map,
              data.key.column = "Ensembl",
              table = "node",
              table.key.column = "Ensembl")
#loading HGNC names for Ensembl IDs in AOP network back to node table

nodetable <- getTableColumns("node",c("KEtitle","AOPtitle","AOtitle","HGNCsymbol","SUID"))
nodetable <- nodetable %>%
  rowwise() %>%
  mutate(label=paste(na.omit(c_across(all_of(c("KEtitle","AOPtitle","AOtitle","HGNCsymbol")))), collapse=""))
#Generating a new 'label' column that combines KEtitle, AOPtitle, AOtitle, and HGNC into one columns
#Since each node represents a different type of data (KE, AOP, AO, or gene), titles will never overlap
#Cytoscape visualisation is based on one column, thus labels need to all be stored in a single column for visualisation
nodetable <- nodetable %>%
  rowwise() %>%
  mutate(type = case_when(
    str_detect(AOPtitle, "\\S") ~ "AOP",
    str_detect(AOtitle, "\\S") ~ "AO",
    str_detect(KEtitle, "\\S") ~ "KE",
    str_detect(HGNCsymbol, "\\S") ~ "gene",
    TRUE ~ NA_character_
  ))
#Generating a new 'type' column indicating of which type (KE, AOP, AO, or gene) a node is 
#Again for visualsation purposes - later used to determine color mapping of node based on type
loadTableData(nodetable,"SUID","node","SUID")
lapply(c(aopaonetwork,keaopnetwork,kegenenetwork,keaopaomerged),deleteNetwork)
  #Deleting intermediary networks used to generate full gene-KE-AOP-AO network
} 

mergeaop("all")
  #Creating the full gene-KE-AOP-AO network with data from all AOs and associated AOPs and KEs in AOP-Wiki
aopmerged_node <- getTableColumns("node")
sparqlquery("AOP-Wiki","miemap.txt","miemap")
  #Getting a list of all data points in AOP-Wiki tagged as molecular initiating events and the AOPs for which they are MIEs 
aopmerged_node_KEid <- as.data.frame(aopmerged_node$KEid)
  #Getting list of key event nodes in the merged network
names(aopmerged_node_KEid) = "KEid"
aopmerged_node_KEid <- na.omit(aopmerged_node_KEid)
  #Df cleanup
KEid_mie <- merge(aopmerged_node_KEid, miemap, by="KEid", all.x=TRUE)
  #Mapping in which AOPs the KEs in the network appear as MIEs
loadTableData(KEid_mie,"KEid","node","KEid")
  #Loading MIE mapping back to the network
KEid_mie <- na.omit(KEid_mie[!is.na(KEid_mie[["KEisMIEin"]]), ])
  #Removing non-MIE rows
KEid_mie <- separate_rows(KEid_mie, KEisMIEin, sep = "; ")
  #Separating rows to show one KE being an MIE in a specific AOP per row
KEid_mie$interaction <- paste(KEid_mie$KEisMIEin, "(interacts with)", KEid_mie$KEid)
  #Generating a new column that follows Cytoscape edge nomenclature to be used as key column
KEid_mie$isMIEedge <- 1
  #Adding column showing whether the edge is related to a MIE or not, used in visualisation 
loadTableData(KEid_mie, "interaction","edge","name")
  #Loading edge info back to network

exportNetwork(paste0(nw_savepath,"gene-KE-AOP-AO merged network_all"),"CX", overwriteFile=TRUE,network="gene-KE-AOP-AO merged network_all")
#Exporting the network

end_section("AOP-Wiki extension")

##Cluster/pathway extesion -----------------------------------------------------------------------------------------------------------------------------------------
start_section("Cluster/pathway extension")

importNetworkFromFile(paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO.cx"))
  #Reimporting clustered supernetwork with GO results added
commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
  #Deleting duplicate gLayCluster column
createColumnFilter(
  filter.name = "has_GO_result",
  column = "N_nodes",
  criterion = 0,
  predicate = "GREATER_THAN",
  anyMatch = TRUE,
  apply = TRUE
)
  #Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
  #N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
  #Inverting selection and deleting nodes that don't have GO results

snw_node <- getTableColumns("node")
deleteNetwork("SCZ_SNW_STRING_clustered_GO")
  #Deleting the SNW again, was only imported to get node table

snw_node_aop <- snw_node[snw_node$Ensembl %in% aopmerged_node$Ensembl,]
  #Selecting rows from snw_node_aop that have the same genes that are also found in the AOP network 

remove_duplicates <- function(pathway_string) {
  pathway_string %>%
    str_split(";|, ") %>%     # Split the string by commas or semicolons
    unlist() %>%              # Unlist the resulting list
    unique() %>%              # Remove duplicates
    paste(collapse = ", ")    # Collapse the unique elements back into a single string
}
  #When merging WikiPathways node and edge networks, it's possible that there are semi-colon separated duplicates in PathwayID
  #This function splits strings and removes duplicates for a more consistent and clean look 
snw_node_aop$PathwayID <- sapply(snw_node_aop$PathwayID, remove_duplicates)

snw_node_aop_valid <- select(snw_node_aop,Ensembl, fromPublication,fromWikiPathways,fromDisGeNET,gLayCluster,snpID,CNVassociated,PathwayID)
  #Getting relevant columns for network construction
snw_node_aop_valid <- separate_rows(snw_node_aop_valid,PathwayID,sep=", ")
  #Separating PathwayID rows to have one or multiple PathwayIDs per gene; one PathwayID per row
sparqlquery("WikiPathways","pathwaymap.txt","pathwaymap")
  #Querying WikiPathways for all Pathway IDs and Pathway titles for mapping
pathwaymap$PathwayTitle <- sub("@en$","",pathwaymap$PathwayTitle)
pathwaymap$PathwayTitle <- gsub('"','',pathwaymap$PathwayTitle)
  #Cleaning up mapping file by removing quotation marks and "@en" appendix of all rows
snw_node_aop_valid <- merge(snw_node_aop_valid,pathwaymap,by="PathwayID",all.x=TRUE)
  #Adding PathwayTitle to the df to map pathway IDs to titles
snw_node_aop_valid[is.na(snw_node_aop_valid)] <- ""
  #Replacing NA with empty for nicer look in Cytoscape
snw_node_aop_valid <- snw_node_aop_valid %>%
  rename(Ensembl_source = Ensembl,
         PathwayID_target = PathwayID)
  #Renaming source and target cols for import
snw_node_aop_valid$Ensembl <- snw_node_aop_valid$Ensembl_source
snw_node_aop_valid$PathwayID <- snw_node_aop_valid$PathwayID_target
  #Duplicating source and target cols for import
snw_node_aop_valid <- snw_node_aop_valid[,c("Ensembl_source","Ensembl","fromPublication","fromDisGeNET","fromWikiPathways","gLayCluster","snpID","CNVassociated","PathwayID_target","PathwayID","PathwayTitle")]
  #Reordering columns
snw_node_aop_valid <- lapply(snw_node_aop_valid, function(x) gsub("NA","",x))
  #At some point during processing, literal 'NA' is added to the df which is incorrectly interpreted during Cytoscape import
  #We simply replace all occurrences of 'NA' with an empty string
write.table(snw_node_aop_valid, file=paste0(other_savepath,"AOP-Wiki/snw_node_aop.tsv"), sep="\t", quote=FALSE, row.names=FALSE)
  #Writing to file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList=s,sa,sa,sa,sa,sa,sa,sa,t,ta,ta delimiters=\\t file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1',paste0(other_savepath,"AOP-Wiki/snw_node_aop.tsv")))
  #Importing network to Cytoscape
Sys.sleep(1)
renameNetwork("Genes from AOP network with SNW attributes")

snw_node_aop_valid_node <- getTableColumns("node")
  #Reading node table as R object
snw_node_aop_valid_node <- snw_node_aop_valid_node %>%
  rowwise() %>%
  mutate(label=paste(na.omit(c_across(all_of(c("PathwayTitle")))), collapse=""))
  #Adding 'label' column for pathway nodes in preparation for merge with gene-AOP network
snw_node_aop_valid_node <- snw_node_aop_valid_node %>%
  rowwise() %>%
  mutate(type = case_when(
    str_detect(PathwayID, "\\S") ~ "Pathway",
    str_detect(Ensembl, "\\S") ~ "gene",
    TRUE ~ NA_character_
  ))
  #Adding 'type' column in preparation for merge with gene-AOP network
loadTableData(snw_node_aop_valid_node,data.key.column='name',table.key.column = 'name',table='node')
  #Loading modified node table back to network


snw_node_aop_cluster <- select(snw_node_aop, Ensembl, CNVassociated, gLayCluster, GO_Pvals,GO_Terms,N_nodes,Nodes,Publication_source,DisGeNET_source,WikiPathways_source,WikiPathways_CNV,WikiPathways_noCNV)
  #Getting relevant columns for gene-cluster associations
summary_terms <- read.delim(file=paste0(getwd(),"/Data/summary_go_terms.txt"),sep="\t",header=TRUE,quote="")
  #Loading summary GO terms
snw_node_aop_cluster <- merge(snw_node_aop_cluster,summary_terms,by="gLayCluster")
  #Adding summary terms per cluster
snw_node_aop_cluster[is.na(snw_node_aop_cluster)] <- ""
  #Replacing NA with empty for nicer look in Cytoscape
snw_node_aop_cluster <- snw_node_aop_cluster %>%
  rename(Ensembl_source = Ensembl,
         gLayCluster_target = gLayCluster)
  #Renaming source and target columns for import
snw_node_aop_cluster$Ensembl <- snw_node_aop_cluster$Ensembl_source
snw_node_aop_cluster$gLayCluster <- snw_node_aop_cluster$gLayCluster
  #Duplicating source and target columns for import
snw_node_aop_cluster <- select(snw_node_aop_cluster, Ensembl,Ensembl_source, CNVassociated, gLayCluster,gLayCluster_target,N_nodes,Publication_source,DisGeNET_source,WikiPathways_source,WikiPathways_CNV,WikiPathways_noCNV,summary_term)
snw_node_aop_cluster <- snw_node_aop_cluster[,c("Ensembl_source","Ensembl","CNVassociated","gLayCluster_target","gLayCluster","N_nodes","Publication_source","DisGeNET_source","WikiPathways_source","WikiPathways_CNV","WikiPathways_noCNV","summary_term")]
  #Reordering columns
write.table(snw_node_aop_cluster, file=paste0(other_savepath,"AOP-Wiki/snw_node_aop_cluster.tsv"), sep="\t", quote=FALSE, row.names=FALSE)
  #Writing to file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="s,sa,sa,t,ta,ta,ta,ta,ta,ta,ta,ta,ta" delimiters=\\t decimalSeparator="." file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1',paste0(other_savepath,"AOP-Wiki/snw_node_aop_cluster.tsv")))
#Importing network to Cytoscape
Sys.sleep(1)
renameNetwork("Genes from AOP network with clusters")
snw_node_aop_cluster_node <- getTableColumns("node")
#Reading node table as R object
snw_node_aop_cluster_node <- snw_node_aop_cluster_node %>%
  rowwise() %>%
  mutate(label=paste(na.omit(c_across(all_of(c("summary_term")))), collapse=""))
#Adding 'label' column for pathway nodes in preparation for merge with gene-AOP network
snw_node_aop_cluster_node <- snw_node_aop_cluster_node %>%
  rowwise() %>%
  mutate(type = case_when(
    str_detect(gLayCluster, "\\S") ~ "Cluster",
    str_detect(Ensembl, "\\S") ~ "gene",
    TRUE ~ NA_character_
  ))
#Adding 'type' column in preparation for merge with gene-AOP network
loadTableData(snw_node_aop_cluster_node,data.key.column='name',table.key.column = 'name',table='node')
#Loading modified node table back to network

altmergeNetworks(sources=c("Genes from AOP network with clusters","Genes from AOP network with SNW attributes"),
                 title="Genes from AOP network with pathways and clusters",
                 operation="union",
                 nodeKeys=c("name","name"))


altmergeNetworks(sources=c("gene-KE-AOP-AO merged network_all","Genes from AOP network with pathways and clusters"),
                 title="gene-KE-AOP-AO merged network with pathways",
                 operation="union",
                 nodeKeys=c("Ensembl","name"))
  #Merging gene-KE-AOP-AO network with gene-pathway network
deleteTableColumn("shared.name")
lapply(c("Genes from AOP network with SNW attributes","Genes from AOP network with clusters","Genes from AOP network with pathways and clusters"),deleteNetwork)
#Deleting intermediary networks used to generate full gene-KE-AOP-AO network
genenames <- getTableColumns("node",c("SUID","label","type")) %>%
  filter(grepl("gene",type)) %>%
  #First selecting gene labels to avoid removing semicolons that should occur in other node labels
  mutate(label = str_replace(label, ";",""))
  #Removing ";" from gene names caused by Cytoscape merging
  #Row values are merged if they are the same and are separated by semicolons if they are not
  #Gene names in the 'label' column are not generated in every network since it is not necessary, but this means that after merging, one row will have an empty string and the other the gene name
  #This leads to gene names being preceded by an empty character and a semicolon
loadTableData(genenames,"SUID","node","SUID")
  #Loading corrected names back to the network

exportNetwork(filename=paste0(nw_savepath,"gene-KE-AO merged network with pathways"), type="CX", overwriteFile = TRUE)

end_section("Cluster/pathway extension")

## ChEBI EXTENSION --------------------------------------------------------------------------------------------------------------------------------
start_section("ChEBI extension")

getlinkset <- function(url,dest) {
  if (!file.exists(dest)) {
    dir.create(dest)
  }
  file <- "chembl_23_hsa_20180126.zip"
  curl_download(url, destfile=file.path(dest,file))
  unzip(zipfile=file.path(dest,file),exdir=dest)
}
  #Setting up directory creation, file download and unzip for chembl linkset from CyTargetLinker website

linkset_url <- "https://ndownloader.figshare.com/files/21623691?private_link=6cf358aaaaf5adeecce9"
linkset_dir <- paste0(getwd(),"/Data/CyTargetLinker")


if (!file.exists(file.path(linkset_dir, "chembl_23_hsa_20180126.xgmml"))) {
  getlinkset(linkset_url,linkset_dir)
  print("Linkset downloaded and unzipped.")
  file.remove(paste0(getwd(),"/Data/CyTargetLinker/chembl_23_hsa_20180126.zip"))
    #Deleting the zip file after extracting the desired xgmml file from it
} else {
  print("Linkset already exists.")
}
  #Downloading and unzipping if necessary
chembl_path <- paste0(getwd(),"/Data/CyTargetLinker/chembl_23_hsa_20180126.xgmml")
  #Defining path to chembl linkset for easy access
commandsRun(sprintf('cytargetlinker extend direction=SOURCES idAttribute=Ensembl  linkSetFiles=%s network=current',chembl_path))
  #Extending the pathway-gene-AOP network with chemicals from the linkset
mapped_chembls <- getTableColumns("node","CTL.ChEMBL")
mapped_chembls <- na.omit(mapped_chembls)
  #Getting mapped chemicals and removing NA from df for further processing

# metabolitedb_dir <- paste0(getwd(),"/BridgeDb/metabolites_20240416.bridge")
# getmetabolitemap <- function(dir = metabolitedb_dir, confirmation = "Metabolite BridgeDb mapping file not detected. Download metabolite BridgeDb mapping file (2.65 GB)? (yes/no): ") {
#   if(file.exists(dir)) {
#     message("File already present at ", dir, " No files downloaded.")
#   } else {
#     confirm <- readline(prompt = confirmation)
#     if (tolower(confirm) == "yes") {
#       bridgedb_hs <- getDatabase("Homo sapiens",location=paste0(getwd(),"/BridgeDb"))
#       message("BridgeDb mapping file downloaded to ",dir)
#     } else {
#       message("File download cancelled.")
#     }
#   }
# }
# getmetabolitemap()

metabolite_bridge_dir <- paste0(getwd(),"/BridgeDb/metabolites_20240416.bridge")
metabolite_mapper <- loadDatabase(metabolite_bridge_dir)
metabolite_input <- data.frame(
  source = rep("Cl", length(mapped_chembls[, 1])),
  identifier = mapped_chembls[, 1]
)
  #Making a new df to be used as input for bridgedb
chembl_map <- maps(metabolite_mapper,metabolite_input,"Ce")
  #Mapping from ChEMBL to ChEBI
chembl_map <- chembl_map %>%
  select(identifier,mapping) %>%
  filter(grepl("CHEBI", mapping, fixed=TRUE)) %>%
  rename(ChEMBLid = identifier,
         ChEBIid = mapping)

chebimap <- read.delim(paste0(getwd(),"/Data/CyTargetLinker/chebimap.tsv"), sep = "\t")
  #Loading .tsv containing ChEBI IDs with associated ontology IDs and names
chebimap <- chebimap %>%
  rename(ChEBIid = chemical,
         ChEBIrole = role,
         ChEBIrolename = rolename) %>%
    #Renaming cols
  mutate(ChEBIid = str_replace(ChEBIid, ".*/",""),
         ChEBIrole = str_replace(ChEBIrole, ".*/","")) %>%
  #Removing URL to get ChEBI IDs 
  mutate(ChEBIid = str_replace(ChEBIid, "_",":"),
         ChEBIrole = str_replace(ChEBIrole,"_",":"))
  #Replacing underscores with colons 
chembl_chebi <- merge(chembl_map, chebimap, by="ChEBIid",all.x=TRUE) 
  #Mapping ChEBI ontology terms to ChEBI IDs available from network mapping



chembl_chebi <- chembl_chebi %>%
  group_by(ChEBIid,ChEMBLid) %>%
  summarise(ChEBIrole = paste(ChEBIrole, collapse = "; "),
            ChEBIrolename = paste(ChEBIrolename, collapse = "; "))
chembl_chebi <- chembl_chebi %>%
  mutate_all(~str_replace_all(.,"NA",""))
  #Replacing literal 'NA' with empty string

chembl_map <- read.delim(paste0(getwd(),"/Data/chembl_name.tsv"),sep="\t")
  #Loading a file containing ChEMBL IDs mapped to compound names retrieved through the WikiData SPARQL endpoint
chembl_chebi <- merge(chembl_chebi, chembl_map, by = "ChEMBLid",all=TRUE)
  #Adding compound names to the df

chembl_chebi$type <- "ChEBI node"
chembl_chebi$label <- chembl_chebi$compound_name
  #Adding type and label attributes for visualisation
loadTableData(chembl_chebi, data.key.column = "ChEMBLid", "node",table.key.column = "CTL.ChEMBL")
  #loading data back to network
chebi_node <- getTableColumns("node",c("SUID","CTL.ChEMBL","ChEBIid"))
  #Getting SUID, ChEMBL, and ChEBI columns of all nodes to filter
chemblnochebi <- chebi_node %>%
  filter(!is.na(CTL.ChEMBL) & is.na(ChEBIid))
  #Filtering for nodes that have a ChEMBL ID but no ChEBI ID
  #Desired to remove all CTL-added nodes that couldn't be mapped to a ChEBI ID
selectNodes(nodes = chemblnochebi$SUID, by.col = "SUID")
  #Selecting these nodes in Cytoscape
deleteSelectedNodes()
  #Deleting selected nodes
  #This process could also be done by using Cytoscape filters (createcolumnFilter), but is much slower
  #Removing ChEMBL nodes added by CyTargetLinker that do not have ChEBI IDs
deleteTableColumn("CTL.ChEMBL")
renameNetwork("gene-KE-AOP network with pathways and chemicals")
exportNetwork(filename=paste0(nw_savepath,"gene-AOP merged network with pathways and chemicals"), type="CX", overwriteFile = TRUE)

end_section("ChEBI extension")

## ChEBI ROLE SUBSETTING --------------------------------------------------------------------------------------------------------------------------------
start_section("ChEBI role subsetting")

rolecount <- chembl_chebi$ChEBIrolename %>%
 strsplit("; ") %>%
  unlist() %>%
  data.frame(role = .) %>%
  group_by(role) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
  #Counting how frequently which ChEBI roles can be mapped to a chemical in the network 
  #Can be used to select roles of interest based on frequency\

#write.table(rolecount, "C:/users/klemm/Desktop/rolecount-all.tsv",sep="\t",quote=FALSE,row.names=FALSE)


filter_chebi <- function(keyword) {
  chems <- chembl_chebi %>%
  separate_rows(ChEBIrolename, sep = "; ") %>%
  filter(grepl(paste0("\\b(", paste(keyword, collapse = "|"), ")\\b"),ChEBIrolename)) %>%
  pull(ChEBIid) %>%
  as.list() %>%
  selectNodes( ,by.col="ChEBIid")
  chems_list <- chems$nodes
  
  #Defining a simple function to filter ChEBI nodes by associated role name

  #Getting nodes matching the given ChEBI role
chems_genes <- selectFirstNeighbors(direction="outgoing")
  #Getting first neighbors of ChEBI nodes, which will be gene nodes
clearSelection()
genes <- setdiff(chems_genes$nodes, chems$nodes)
  #Getting the SUIDs of the gene nodes associated with a given ChEBI role
  #Done by getting the intersection between ChEBI nodes and the selection of both ChEBI and gene nodes 
  #This is because gene nodes are selected as being first neighbors, so the set of selected nodes will contain both the ChEBI and gene nodes
selectNodes(genes)
  #Selecting gene nodes associated with given ChEBI role
genes_pws <- selectFirstNeighbors(direction="outgoing")
  #Getting outgoing first neighbors of gene nodes which are pathway and cluster nodes 
pws <- setdiff(genes_pws$nodes,genes)
  #Again getting the intersection of gene and pathway/cluster nodes due to neighbor selection including both the source and neighbor nodes
clearSelection()
selectNodes(genes)
allngbrs <- selectFirstNeighbors(direction="incoming")
  #Selecting incoming first neighbors of gene nodes
  #This will select all chemical nodes rather than the chemical nodes with the relevant ChEBI role
suidtype <- getTableColumns("node",columns=c("SUID","type"))
kengbrs <- setdiff(allngbrs$nodes, suidtype[suidtype$type == "ChEBI node","SUID"])
  #Therefore, KE nodes are filtered out using the 'type' attribute
kengbrs <- setdiff(kengbrs, genes)
  #Filtering out gene nodes
if (length(kengbrs) > 0) {
clearSelection()
selectNodes(kengbrs)
aop_kes <- selectFirstNeighbors(direction="incoming")
  #Selecting AOP nodes related to KE nodes
aopngbrs <- setdiff(aop_kes$nodes, kengbrs)
  #Filtering out KE nodes
clearSelection()
selectNodes(aopngbrs)
aop_aos <- selectFirstNeighbors(direction="incoming")
  #Selecting AO nodes related to AOP nodes
aongbrs <- setdiff(aop_aos$nodes, aopngbrs)
clearSelection()
} else { 
  aongbrs <- c()
  aopngbrs <- c()
  }
connectednodes <- c(chems_list, genes, pws, kengbrs,aopngbrs, aongbrs)
selectNodes(connectednodes)
createSubnetwork(nodes = connectednodes, subnetwork.name = paste0("Role ", paste(keyword, collapse = ", "), " subnetwork "))
Sys.sleep(0.5)
setCurrentNetwork("gene-KE-AOP network with pathways and chemicals")
setCurrentView("gene-KE-AOP network with pathways and chemicals")
clearSelection()
}


filter_chebi(c("toxin","neurotoxin","genotoxin"))
filter_chebi(c("agrochemical","piscicide","rodenticide","fungicide","herbicide","insecticide","nematicide"))
# filter_chebi("orphan drug")
# filter_chebi("hallucinogen")
# filter_chebi("fuel")
# filter_chebi(c("CB2 receptor agonist","CB2 receptor antagonist","CB1 receptor antagonist"))

end_section("ChEBI role subsetting") 


##AOP VISUALISATION -------------------------------------------------------------------------------------------------------------------------------
createVisualStyle("AOP_vis")
setVisualStyle("AOP_vis")
#Creating and setting a new visual style for the AOP network
setNodeLabelMapping(
  table.column="label",
  style.name="AOP_vis"
)
#Setting node labels using dedicated node label column
setNodeColorMapping(
  table.column = "type",
  mapping.type="d",
  table.column.values = c("AO","AOP","KE","gene","Pathway","Cluster","ChEBI node"),
  colors=c("#FB6a4A","#FEB24C","#FA9FB5","#74C476","#1DEFF2","#b48fff","#bfcdf5"),
  style.name="AOP_vis"
)
#Setting node colors using dedicated type column
createColumnFilter(
  filter.name = "KE-MIE",
  column = "KEisMIEin",
  criterion = "h",
  predicate = "CONTAINS",
  anyMatch = TRUE,
  apply = TRUE
)
  #Selecting which KEs are tagged as MIEs
kemienode <- getSelectedNodes()
setNodeBorderColorBypass(
  node.names = kemienode, 
  new.colors = "#3030f0"
)
setNodeBorderWidthBypass(
  node.names = kemienode,
  new.sizes = 20  
)
setNodeShapeDefault(
  new.shape="ROUND_RECTANGLE",
  style.name="AOP_vis"
)
setNodeFontSizeDefault (
  new.size = "25",
  style.name = "AOP_vis"
)
setEdgeSourceArrowShapeDefault(
  new.shape = "DELTA",
  style.name="AOP_vis"
)
setEdgeColorDefault(
  new.color="#BCBCBC",
  style.name="AOP_vis"
) 
setEdgeColorMapping(
  table.column = "isMIEedge",
  table.column.values = c(0,1),
  colors = c("#BCBCBC", "#3030f0"),
  style.name= "AOP_vis"
)
setEdgeLineWidthMapping(
  table.column = "isMIEedge",
  table.column.values = c(0,1),
  widths = c(1,3),
  style.name = "AOP_vis"
)
commandsRun('analyzer analyze directed=true selectedOnly=false')
  #Running analyzer for topoligcal information
setNodeSizeMapping(
  table.column = "Indegree",
  sizes=c(50,250),
  mapping.type='c',
  style.name="AOP_vis"
 )
  #Setting node size relative to indegree (in this graph: edges going from bottom to top)
setNodeHeightMapping(
  table.column="name",
  table.column.values = NULL,
  heights = c(0,100),
  mapping.type ="d",
  style.name="AOP_vis"
)
fitContent()
exportImage(
  filename=paste0(getwd(),"/Visualisations/SNW-AOP-pathways-clusters-chemicals"),
  type="SVG"
)
  #Fitting and exporting visualisation
##RAW SNW VISUALISATION --------------------------------------------------------------------------------------------------------------------------- 
importNetworkFromFile(paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO.cx"))
#Reimporting clustered supernetwork with GO results added
setCurrentNetwork(snw_scz_filtered_string_clustered_go)
createColumnFilter(
  filter.name = "has_GO_result",
  column = "N_nodes",
  criterion = 0,
  predicate = "GREATER_THAN",
  anyMatch = TRUE,
  apply = TRUE
)
  #Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
  #N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
  #Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
  #Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way 
  #The idea is to link GO terms (formed by clusters/genes) 


#These changes to the visualization are essentially only visible when Cytoscape is set to always render details
#The network is big and not really organized besides clusters, the pie chart visualization that follows gives a much better impression

createVisualStyle("SNW_vis")
  #Creating a new visual style that is subsequently customized
setVisualStyle("SNW_vis")
  #Applying the new visual style
clusters <- as.character(unique(getTableColumns("node","gLayCluster"))$gLayCluster)
  #gLayCluster column has many repeats of the clusters but a list of unique clusters is needed for table.column.values
clustercolors <- as.list(paletteColorRandom(length(clusters)))
  #Generating a set of random colors based on the number of clusters in the SNW
  #Make this constant, generate 100 colors or so once 
  #Then just select first N where N=Nclusters, so it stays flexible when more/fewer clusters are generated
  #Much easier for legend too
setNodeColorMapping(table.column = "gLayCluster",
                    table.column.values=clusters,
                    colors=clustercolors,
                    mapping.type="d",
                    default.color="#FF5555",
                    style.name = "SNW_vis"
                    )
  #table.column values must be defined like this as the gLayCluster column has many repeats of cluster numbers
  #Random colors are generated per cluster based on the number of different clusters in the SNW
setEdgeLineWidthDefault(new.width = 0.5,
                        style.name = "SNW_vis")
  #Reducing edge width to decrease hairball effect
setNodeLabelMapping(table.column = "HGNCsymbol",
                    style.name="SNW_vis")
  #Changing node labels to show HGNC name
fitContent()
exportImage(
  filename=paste0(getwd(),"/Visualisations/hairball-SNW"),
  type="SVG"
)
##PIE CHART VISUALISATION -----------------------------------------------------------------------------------------------------------------------
commandsRun(sprintf("network import file columnTypeList='s,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true delimiters=\\t rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(other_savepath,"Clustering/GO-clusters-vis.tsv")))
#Importing the previoulsy generated table 'GO-clusters-vis' back to Cytoscape as new network
#Essential to use .tsv and importing as such to avoid conflicts generated by .csv - commas separating terms in a string are interpreted as different columns by Cytoscape
Sys.sleep(1)
renameNetwork("GO_Visualisation_SCZ_SNW")
loadTableData(
  data = read.table(file=paste0(getwd(),"/Data/summary_go_terms.txt"),header=TRUE, sep ="\t"),
  data.key.column = "gLayCluster",
  table.key.column = "gLayCluster"
)
#Loading an additional column into the network containing manually created summaries of GO terms based on biological knowledge
commandsRun(sprintf("network import file columnTypeList='s,t,ea' file=%s firstRowAsColumnNames=true delimiters=\\t startLoadRow=1", paste0(other_savepath,"Clustering/match_df.tsv")))
#Loading edge information (i.e. intersections between GO terms for each cluster)
createVisualStyle(style.name = 'GO_vis')
#Creating a new visual style that is subsequently customized
setVisualStyle("GO_vis")
#Applying a basic visual style to the network 
setNodeSizeMapping(
  table.column = "N_nodes",
  sizes = c(50,200),
  mapping.type = "c",
  style.name= "GO_vis"
)
#Setting the node size proportional to the number of nodes making up a cluster, e.g. a cluster containing more nodes is bigger
setNodeCustomPieChart(
  columns = c("DisGeNET_source","Publication_source","WikiPathways_CNV","WikiPathways_noCNV"),
  colors = paletteColorBrewerPaired(value.count = 8),
  style.name= "GO_vis"
)
#Turning nodes into pie charts showing which sources make up the proportions of the nodes in them
setNodeShapeDefault("ellipse",
                    style.name= "GO_vis")
setNodeFillOpacityDefault(
  new.opacity = 0,
  style.name= "GO_vis"
)
#Removing node background
setNodeBorderWidthDefault(
  new.width=0.1,
  style.name= "GO_vis"
)
setNodeBorderColorDefault (
  style.name="GO_vis",
  new.color = "#FFFFFF"
)
setNodeLabelMapping(
  table.column = "summary_term",
  style.name= "GO_vis"
)
#Changing node label to the processes/terms the nodes represent
setNodeFontSizeDefault(
  new.size = 20,
  style.name= "GO_vis"
)
#Setting node font size
setNodeLabelPositionDefault(
  new.nodeAnchor = "S",
  new.graphicAnchor = "N",
  new.justification = "c",
  new.xOffset = "0",
  new.yOffset = "0",
  style.name= "GO_vis"
)
#Moving label
setEdgeLineWidthMapping(
  table.column = "GO_term_matches",
  table.column.values = c(0,861),
  widths = c(0,50),
  mapping.type = "c",
  style.name= "GO_vis"
)
#Setting edge width proportional to number of shared GO terms 
setEdgeOpacityDefault(
  new.opacity = 70,
  style.name= "GO_vis"
)
#Decreasing edge opacity
setEdgeColorDefault('#DD3497',
                    style.name= "GO_vis")
#Changing edge color
commandsRun('layout force-directed defaultEdgeWeight=0.5 defaultNodeMass=3 defaultSpringCoefficient=1e-4 edgeAttribute="GO_term_matches" defaultSpringLength=300 isDeterministic=true maxWeightCutoff=1.79769E308 minWeightCutoff=0E0 numIterations=200 type=Heuristic')
layoutNetwork('force-directed')  
#Adding network layout
#scaleLayout(axis="Both Axes", scaleFactor = 0.95)
#Not working as requires Cytoscape v.3.10.2 which does not seem available yet?
renameNetwork("Supernetwork functional analysis")
deleteNetwork(network="GO_Visualisation_SCZ_SNW")
go_vis_nw <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"GO_Visualisation_SCZ_SNW"),"CX",network=go_vis_nw,overwriteFile=TRUE)
fitContent()
exportImage(filename = paste0(getwd(),"/Visualisations/SNW_functional_analysis_demo"),type="SVG", overwriteFile=TRUE, zoom="200")
#Exporting the visualisation as network and as svg

##DEPRECATED==========================================================================================================================================

#storing code that has been replaced by other methods 


# disgenetRestUrl<-function(netType,host="127.0.0.1",port=1234,version="v7"){
#   if(is.null(netType)){
#     print("Network type not specified.")
#   }else{
#     disgeneturl<-sprintf("http://%s:%i/disgenet/%s/%s",host,port,version,netType)
#   }
#   return (disgeneturl)
# }
# net <- "gene-disease-net"
# disgenetRestUrl(netType = net)
#   #Defining object for REST to call DisGeNET automation module; defining that we will be using gene-disease associations (GDA)
# disgenetRestCall<-function(netType,netParams){
#   disgeneturl<-disgenetRestUrl(netType)
#   restCall<-POST(disgeneturl, body = netParams, encode = "json")
#   result<-content(restCall,"parsed")
#   return(result)
# }
#   #Object that executes REST calls to DisGeNET module in Cytoscape 
# geneDisParams <- function(source,dis,min) {list(
#   source = source,
#   assocType = "Any",
#   diseaseClass = "Any",
#   diseaseSearch = dis,
#   geneSearch = " ",
#   initialScoreValue = min,
#   finalScoreValue = "1.0"
# )}
#   #Specifying parameters of the GDA network to be imported


# genedisparams.scz.df <- read.table("Data/DisGeNET/disgenetparams-scz.txt",header=TRUE,sep = "\t")
#   #Loading relevant gene-disease networks from DisGeNET
#   #Networks of interest manually added into tsv where it is easier to adjust filters
# disgeneturl <- c()
#   #Preparing container for DisGeNET URL to be saved for addition to metadata file
# apply(genedisparams.scz.df,1,function(row) {
#   gdp <- geneDisParams(row["source"],row["dis"],row["min"])
#   disgeneturl <<- disgenetRestUrl(net)
#     #Fetching the DisGeNET URL used to make this call 
#   geneDisResult <- disgenetRestCall(net,gdp)
#     #Executing the DisGeNET query
#   createNodeSource("fromDisGeNET")
#     #Adding information about data source to each node
#   #mapTableColumn("geneId","Human","Entrez Gene","Ensembl",force.single=TRUE,table="node")
#   commandsRun('bridgedb id mapping network=current sourceColumn=geneId sourceIdType="Entrez Gene" targetColumn=Ensembl targetIdType=Ensembl' )  
#   #Mapping Entrez Gene IDs to Ensembl IDs
#   renameTableColumn("geneName","DisGeNETname")
# })  
#   #Importing networks from DisGeNET
# 
# metadata.add(paste("DisGeNET URL:",disgeneturl))
# metadata.add(paste("DisGeNET net type:",net))
# metadata.add("")
#   #Adding the DisGeNET URL and net type used to add networks to the metadata file


#queryspecies.wp <- c("Homo sapiens","Rattus norvegicus","Mus musculus")
#getPathways.wp <- function(i) {
#pw <- findPathwaysByText(i)
#pw <- pw %>%
#dplyr::filter(species %in% queryspecies.wp)
#Filtering by species
# pw.ids <- paste0(i, "_wpids")
# assign(pw.ids, as.character(pw$id),envir = .GlobalEnv)
#Extracting WP IDs
#}
#Function to query WikiPathways using keyword and to extract WP IDs for the import function

#import <- function(j) {
#commandsRun(paste0('wikipathways import-as-network id=', j))
#Pasting WikiPathways IDs into a Cytoscape command line prompt to import as networks
#createNodeSource("WikiPathways")
#Filling the 'WikiPathways' column with 1 to indicate the source
#}
#Importing pathways from WikiPathways by pathway ID

# networklist.dup <- getNetworkList()
# dup.filter <- function(input,suffix) {
#   filtered_list <- input[substr(input, nchar(input) - 1,nchar(input))==suffix]}
# duplicates <- dup.filter(networklist.dup,"_1") 
#   #Getting duplicate networks (Cytoscape marks duplicate networks with a "_1" suffix to the network name)
# delete.dupes <- function(nw) {
#  setCurrentNetwork(nw)
#   deleteNetwork()
# }
# lapply(duplicates,delete.dupes)
#Selecting and deleting duplicate networks

#wpids <- c("4875","5412","4222","4942","5408","5402","5346","5405","5406","5407","4940","4905","5398","5399","4906","4657","4932")
#sczcnv <- sapply(wpids, function(k) paste0("WP",k))
#Manually adding relevant SCZ CNV pathways from WikiPathways

#keyword.wp <- "Schizophrenia"
#getPathways.wp(keyword.wp)
#lapply(c(Schizophrenia_wpids,sczcnv), import)
#Importing WP pathways (both manually added and by keyword). Also adds "WikiPathways" as NodeSource column to node table
#metadata.add(paste("WikiPathways keywords:",keyword.wp))
#metadata.add(paste("WikiPathways manually by ID:",paste(wpids,collapse =", ")))
#metadata.add(paste("WikiPathways queried species:",paste(queryspecies.wp,collapse = ", ")))
#Adding the keyword and species used to filter the WikiPathways query to the metadata file
#metadata.add("")

# createColumnFilter(filter.name="type.label",column="Type","Label","IS",apply=FALSE)
# createColumnFilter(filter.name="type.anchor",column="Type","Anchor","IS",apply=FALSE)
# createColumnFilter(filter.name="type.group",column="Type","Group","IS",apply=FALSE)
# createColumnFilter(filter.name="disease.name",column="diseaseName","Schizophrenia","IS")
# createCompositeFilter(filter.name="type.label.anchor.group",c("type.label","type.anchor","type.group","disease.name"),"ANY")
#deleteSelectedNodes()
#Creating filters and deleting columns in the node table that are not relevant to the supernetwork (leftovers from import sources)
#renameNetwork("SCZ_SNW_filtered")
#snw_scz_filtered <- getNetworkName()
#exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered"),"CX", network = snw_scz_filtered, overwriteFile=TRUE)
#Exporting the filtered supernetwork as cx file and tagging it with the time and date made to match with metadata file

# commandsRun('string expand additionalNodes=1000 network=current nodeTypes="Homo sapiens" selectivityAlpha=0.9')
#   #STRINGifying and expanding the network with a 0.9 confidence cutoff (curated information)
# createNodeSource("fromSTRING")
#   #Tagging the newly added nodes as having been sourced from STRING
# mapTableColumn("stringdb::canonical name","Human","Uniprot-TrEMBL","Ensembl",force.single=TRUE)
#   #Mapping stringdb canonical names (Uniprot-TrEMBL identifiers) to Ensembl gene identifiers
#   #This step generates a second Ensembl column ('Ensembl (1)') with ENSG identifiers for the STRING-imported nodes
# renameTableColumn("Ensembl (1)","Ensembldup")
#   #Renaming the duplicate Ensembl column for easier handling
# renameNetwork("SCZ_SNW_filtered_STRING")
# snw_scz_filtered_string <- getNetworkName()
# stringified_nodetable <- paste0(nw_savepath,sprintf("%s node table.csv",snw_scz_filtered_string))
#   #Saving the file path to the node table for easier reading
# commandsRun(sprintf('table export options=CSV outputFile=%1$s table="%2$s default  node"',stringified_nodetable,snw_scz_filtered_string))
#   #Exporting the node table as .csv file to the current session's "Network" folder
# read_stringified_nodetable <- read.csv(stringified_nodetable)
#   #saving the node table as object
# read_stringified_nodetable$Ensembl <- ifelse(read_stringified_nodetable$Ensembl == read_stringified_nodetable$Ensembldup, as.character(read_stringified_nodetable$Ensembl),
#                                ifelse(is.na(read_stringified_nodetable$Ensembl) | read_stringified_nodetable$Ensembl =="",as.character(read_stringified_nodetable$Ensembldup),
#                                       ifelse(is.na(read_stringified_nodetable$Ensembldup) | read_stringified_nodetable$Ensembldup=="",as.character(read_stringified_nodetable$Ensembl),"No Match")))
#   #As the identifier mapping from STRING ENSP to ENSG identifiers generates a second Ensembl column, they are merged into the originial Ensembl column if the contents of the cell match or either is blank
# read_stringified_nodetable = subset(read_stringified_nodetable,select= -Ensembldup)
#   #Removing the duplicate Ensembl column from the table
# write.csv(read_stringified_nodetable, file=stringified_nodetable)
#   #Overwriting the previously exported table with the version containing the merged Ensembl column
# renameTableColumn("@id","X.id")
#   #Renaming the '@id' column in the Cytoscape table to avoid issues when reimporting the .csv (@id is automatically converted to X.id in the CSV)
# loadTableData(read_stringified_nodetable,data.key.column="X.id",table.key.column="X.id")
#   #Reimporting the .csv with the merged Ensembl column to the network as to have ENSG identifiers for almost all nodes 

# sparqlquery("AOP-Wiki","KERKEquery.txt","KERList")
#   #Sending a query to AOP-Wiki as specified in the query file to get KERs and corresponding KEs for selected AOs
# write.table(KERList, file=paste0(getwd(),"/Data/AOP-Wiki/KERList.tsv"),quote=FALSE,row.names=FALSE,sep="\t")
#   #Writing to file
# 
# sparqlquery("AOP-Wiki","KEtitlequery.txt","KEMap")
#   #Sending a query to AOP-Wiki to get KE and corresponding titles
# write.table(KEMap,file=paste0(getwd(),"/Data/AOP-Wiki/KEMap.tsv"))
#   #Writing to file
# 
# sparqlquery("AOP-Wiki","KEensemblquery.txt","KEEnsembl")
#   #Sending a query to AOP-Wiki to get all KE-Ensembl ID pairings available
# allKEsFromList <- data.frame(allKEs = c(KERList$KEup,KERList$KEdown))
#   #Combining both up- and downregulated KEs into a single column 
# filtered_KEEnsembl <- subset(KEEnsembl, KE %in% allKEsFromList$allKEs)
#   #Removing KE-Ensembl rows that are not found in the selected KEs
# write.table(filtered_KEEnsembl, file=paste0(getwd(),"/Data/AOP-Wiki/KEEnsembl_filtered.tsv"), quote=FALSE,row.names=FALSE,sep="\t" )
#   #Writing the filtered KE-ENSG list to file for Cytoscape loading
# 
# commandsRun(sprintf('network import file columnTypeList="ea,s,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList=-- Create new network collection --',paste0(getwd(),"/Data/AOP-Wiki/KERList.tsv")))
#   #Loading selected KERs into Cytoscape as new network
# commandsRun(sprintf('table import file dataTypeTargetForNetworkCollection="Node Table Columns" delimiters=\\t file=%s firstRowAsColumnNames=true keyColumnForMapping="shared name" keyColumnIndex=1 startLoadRow=1',paste0(getwd(),"/Data/AOP-Wiki/KEMap.tsv")))
#   #Loading a KE mapping file generated from a second SPARQL query that fetches all KE URIs and their titles from AOPwiki into the KER network
#   #This file also had quotation marks removed using a text editor
# commandsRun(sprintf('network import file columnTypeList="s,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList=-- Create new network collection --',paste0(getwd(),"/Data/AOP-Wiki/KEEnsembl_filtered.tsv")))
#   #Loading the filtered KE-ENSG list as new network into Cytoscape
# altmergeNetworks(sources = c('KERList.tsv','KEEnsembl_filtered.tsv'),
#               title='KERs',
#               operation='union'
#               )
#   #Merging the manually curated KERList network and the KE-ENSG list to extend the selected KEs with associated genes
# deleteNetwork(network='KERList.tsv')
# deleteNetwork(network='KEEnsembl_filtered.tsv')
#   #Deleting networks used to make merged network 
# mapTableColumn(
#   column = 'name',
#   species= 'Human',
#   map.from = 'Ensembl',
#   map.to = 'HGNC',
#   force.single = 'true'
# )
# renameTableColumn('HGNC','Name2')
# commandsRun(sprintf('table export options=CSV outputFile=%s table="KERs default node"', paste0(getwd(),"/Data/AOP-Wiki/KE_table.csv")))
#   #Exporting the node table for manipulation via R
# KE_table <- read.csv(paste0(getwd(),"/Data/AOP-Wiki/KE_table.csv"))
#   #Loading the previously exported node table as R object
# KE_table <- KE_table %>%
#   mutate(Ensembl=ifelse(grepl("ENSG",name),name,NA))
#   #Getting and transposing ENSG IDs from the name col to a new 'Ensembl' col to be used as key
# KE_table <- KE_table %>%
#   mutate(KE_URI=ifelse(!grepl("ENSG",name),name,NA))
#   #Getting and transposing KE URIs (all rows not containing 'ENSG') from the name col to a new 'KE_URI' col
#   #These two steps are done as the 'name' and 'shared name' columns will be difficult to work with since they mix both ENSG and other data types
# KE_table <- KE_table %>%
#   mutate(fromAOPwiki=1)
#   #Adding a new column to the node table indicating that the gene nodes in the KE network are imported from AOPwiki
# KE_table <- KE_table %>%
#   select(-shared.name)
#   #Loading the node table in R changes the name the 'shared name' column to 'shared.name' to avoid a space, this results in a duplicate 'shared.name' column when importing the table back to Cytoscape
#   #For this reason, 'shared.name'/'shared name' is simply removed from the df as 'names' can also be used for mapping and contains the same information anyways
# write.csv(KE_table, file=paste0(getwd(),"/Data/AOP-Wiki/KE_table.csv"), row.names=FALSE)
#   #Overwriting the previously exported node table with the updated version
# loadTableData(
#   data = read.table(file=paste0(getwd(),"/Data/AOP-Wiki/KE_table.csv"),header=TRUE, sep =","),
#   data.key.column = "name",
#   table.key.column = "name"
# )
#   #Loading the updated node table back to the network
# Sys.sleep(0.5)
# altmergeNetworks(sources = c('SCZ_SNW_filtered_STRING_clustered_GO','KERs'),
#                  title='SCZ_SNW_filtered_STRING_clustered_GO_KER',
#                  operation='union',
#                  nodeKeys = c('Ensembl','Ensembl')
# )
#   #Merging the KER network with the supernetwork based on Ensembl ID
#   #As this is an union merge, all nodes from the KER network are introduced to the SNW, but the goal was simply to annotate existing genes in the SNW with KEs
#   #Therefore, some filtering is needed
# 
# commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_filtered_STRING_clustered_GO_KER default node"', paste0(getwd(),"/Data/AOP-Wiki/SNW_KER_node.csv")))
# SNW_KER_node <- read.csv(paste0(getwd(),"/Data/AOP-Wiki/SNW_KER_node.csv"))
#   #Saving the SNW node table to file and loading it as R object
# KE_only_nodes <- SNW_KER_node %>%
#   filter(fromAOPwiki == 1 & is.na(fromDisGeNET) & is.na(fromWikiPathways) & is.na(fromPublication) & is.na(fromSTRING)) %>%
#   pull(Ensembl)
#   #Getting a list of nodes that only have AOPwiki as source
#   #This implies that these nodes were not already present in the network since they would've been merged to existing nodes that already had at least one source prior
#   #It is not desired to add new gene nodes to the network from the KER network; gene nodes serve only as references for connecting KEs to already existing genes in the supernetwork
# selectNodes(nodes=KE_only_nodes,
#             by.col="Ensembl")
# deleteSelectedNodes()
#   #Selecting and deleting nodes based on the prior criteria
# 
# commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_filtered_STRING_clustered_GO_KER default edge"', paste0(getwd(),"/Data/AOP-Wiki/SNW_KER_edge.csv")))
# SNW_KER_edge <- read.csv(paste0(getwd(),"/Data/AOP-Wiki/SNW_KER_edge.csv"))
#   #Exporting the SNW edge table to file and loading it as R object
# valid_KE_ensg <- SNW_KER_edge[grepl("ENSG", SNW_KER_edge$name) & grepl("aop.events", SNW_KER_edge$name),]
#   #Getting a list of KEs that do have interactions with genes
# valid_KE <- str_extract(valid_KE_ensg$name, "https://identifiers.org/aop.events/\\S+")
# valid_KE <- unique(valid_KE)
#   #Getting the URIs of the KEs that have interactions with genes
# bad_KE_df <- SNW_KER_edge %>%
#   filter(
#     grepl("aop\\.events", name, ignore.case=TRUE) &
#       !grepl(paste(valid_KE, collapse="|"), name)
#   )
#   #Getting a list of the remaining KEs that are not associated with a gene or with a KE that is associated with a gene (to preserve KERs)
# bad_KE_list <- str_extract_all(bad_KE_df$name, "https://identifiers\\.org/aop\\.events/\\d+")
# bad_KE <- unique(unlist(bad_KE_list))
#   #Getting a list of unique bad KEs
# selectNodes(nodes=bad_KE, by.col="name")
# deleteSelectedNodes()
# 
# sparqlquery("AOP-Wiki","AOPAOquery.txt","AOPs_AOs_for_selected_KEs")
# write.table(AOPs_AOs_for_selected_KEs,file=paste0(getwd(),"/Data/AOP-Wiki/AOPs_AOs_for_selected_KEs.tsv"))
# commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/Data/AOP-Wiki/AOPs_AOs_for_selected_KEs.tsv")))
#   #Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW  
#   #The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
# Sys.sleep(1)
# commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#   #Removing duplicate edges from current network
#   #RCy3 has a deleteDuplicateEdges function but it seems bugged since it always just removes 1 duplicate edge at a time
#   #Using the command line function removes all duplicate edges right away and avoids having to run a filter to select duplicate edges which is much slower
# renameNetwork("KE-AOP")
# commandsRun(sprintf('network import file columnTypeList="x,sa,s,ta,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t',paste0(getwd(), "/Data/AOP-Wiki/AOPs_AOs_for_selected_KEs.tsv")))
# commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#   #Removing duplicate edges from current network
# renameNetwork("AOP-AO")
# altmergeNetworks(sources=c("KE-AOP","AOP-AO"),
#                  title='KE-AOP-AO',
#                  operation='union',
#                  nodeKeys=c('name','name'))
#   #Merging the AO and AOP networks 
#   #Necessary to first import as separate networks and then merge as only one source and target col can be selected during network import
# altmergeNetworks(sources=c('KE-AOP-AO','SCZ_SNW_filtered_STRING_clustered_GO_KER'),
#                  title='SCZ_SNW_filtered_STRING_clustered_GO_AOP',
#                  operation='union',
#                  nodeKeys=c('name','name'))
#   #Merging the AOP-AO network to the SNW-KE network to extend KEs connected to risk genes with corresponding AOPs/AOs
# deleteNetwork(network='KE-AOP-AO')
# deleteNetwork(network='KERs')
# deleteNetwork(network='SCZ_SNW_filtered_STRING_clustered_GO_KER')
# deleteNetwork(network='KE-AOP')
# deleteNetwork(network='AOP-AO')
#   #Deleting networks that are no longer needed, used to generate SNW-AOP network
# SNW_AOP <- getNetworkName()
# exportNetwork(filename=paste0(nw_savepath,SNW_AOP),"CX",network=SNW_AOP)
#   #Exporting the SNW containing the AOP extension







# aopprocess <- function(input,tag) {
#   if (!"SCZ_SNW_STRING_clustered_GO" %in% getNetworkList()) {
#     importNetworkFromFile(file=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO.cx"))
#     commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
#     createColumnFilter(
#       filter.name = "has_GO_result",
#       column = "N_nodes",
#       criterion = 0,
#       predicate = "GREATER_THAN",
#       anyMatch = TRUE,
#       apply = TRUE
#     )
#     #Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#     #N_nodes is only generated for 'valid' clusters, so good column to filter by
#     invertNodeSelection()
#     deleteSelectedNodes()
#     #Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#     #Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way 
#     #The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
#   }
#   else {
#     commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
#     createColumnFilter(
#       filter.name = "has_GO_result",
#       column = "N_nodes",
#       criterion = 0,
#       predicate = "GREATER_THAN",
#       anyMatch = TRUE,
#       apply = TRUE
#     )
#     #Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#     #N_nodes is only generated for 'valid' clusters, so good column to filter by
#     invertNodeSelection()
#     deleteSelectedNodes()
#     #Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#     #Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way 
#     #The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
#     
#   }
#   
#   #Reimporting the network with GO information back to Cytoscape if needed
#   #Running aopprocess causes all changes to be applied to the GO network
#   #Running aopprocess a second time with other parameters would thus compound changes into the same network which is undesired
#   
#   sparqlquery("AOP-Wiki",input,"keensgpairs")
#   #Querying AOP-Wiki for a list of all KEs and associated genes. KEs must be contained in an AOP that has an AO from a list of selected AOs
#   #Explicity listing keensgpairs so that it is caught by ls()
#   for (i in 1:ncol(keensgpairs)) {
#     for (j in 1:nrow(keensgpairs)) {
#       keensgpairs[j, i] <- gsub('"', '', keensgpairs[j, i])
#     }
#   }
#   #Removing quotation marks from the df
#   
#   separate_keensgpairs <- separate_rows(keensgpairs,Ensembl,sep="; ")
#   #Dividing comma-separated Ensembl IDs into distinct rows
#   keensgpairs_byensg <- separate_keensgpairs %>%
#     group_by(Ensembl) %>%
#     summarise(KEid = paste(KEid, collapse="; "),
#               KE_title = paste(KEtitle, collapse="; "),
#               AOid = paste(AOid, collapse="; "),
#               AO_title = paste(AOtitle, collapse = "; "),
#               AOPid = paste(AOPid, collapse="; "),
#               AOP_title =paste(AOPtitle, collapse="; "))
#   #Concateinating other variables based on unique Ensembl ID to get list of associated KEs, AOs, and AOPs per gene
#   keensgpairs_byensg_save <- paste0(getwd(),sprintf("/Data/AOP-Wiki/keensgpairs_byensg_%s.tsv",tag))
#   #Defining savepath for newly generated df
#   write.table(keensgpairs_byensg, file=keensgpairs_byensg_save,quote=FALSE, sep="\t", row.names=FALSE)
#   #Saving df containing gene-KE-AO-AOP associations to file as tsv for Cytoscape import
#   commandsRun(sprintf('table import file dataTypeTargetforNetworkCollection="Node Table Columns" delimiters=\\t file=%s firstRowAsColumnNames=true keyColumnForMapping="Ensembl" keyColumnIndex=1 startLoadRow=1',keensgpairs_byensg_save))
#   #Importing the gene-KE-AO-AOP table to Cytoscape as table add AOP-Wiki info as node attributes
#   renameNetwork(paste0(getNetworkName(),"_AOP"))
#   scz_snw_string_go_aop <- getNetworkName()
#   
#   commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_STRING_clustered_GO_AOP default  node"',paste0(other_savepath,"SCZ_SNW_STRING_GO_AOP default node","_",tag)))
#   #Exporting the network table
#   scz_snw_string_go_aop_node <- read.csv(file=paste0(other_savepath,"SCZ_SNW_STRING_GO_AOP default node","_",tag,".csv"),header=TRUE)
#   #Reading the exported table as Cytoscape object
#   aop_associated_genes <- scz_snw_string_go_aop_node[!(scz_snw_string_go_aop_node$KEid == ""), , drop=FALSE]
#   #Getting which rows (=gene nodes) have info from AOP-Wiki associated to them
#   renameNetwork(paste0(getNetworkName(),"_",tag))
#   
#   summary_go_terms <- read.delim(paste0(getwd(),"/Data/summary_go_terms.txt"),header=TRUE,sep="\t",quote="")
#   #Loading cluster titles based on GO terms
#   aop_associated_genes <- merge(aop_associated_genes,summary_go_terms,"gLayCluster")
#   
#   separate_aoptitles <- separate_rows(aop_associated_genes,AOP_title,sep="; ")
#   aop_freq_table <- table(separate_aoptitles$AOP_title) 
#   aop_freq_df <- as.data.frame(aop_freq_table)
#   add_attributes <- separate_aoptitles %>%
#     group_by(AOP_title) %>%
#     summarise (AOPEnsembl = paste(Ensembl,collapse="; "),
#                AOPgenename = paste(Name2, collapse="; "),
#                AOPsummary_go_term = paste(summary_term, collapse="; "))
#   names(aop_freq_df) <- c("AOP_title","AOP_frequency")
#   aop_freq_df_full <- merge(aop_freq_df, add_attributes,"AOP_title")
#   #Counting how often which AOPs are associated with all genes
#   
#   separate_aotitles <- separate_rows(aop_associated_genes,AO_title,sep="; ")
#   ao_freq_table <- table(separate_aotitles$AO_title) 
#   ao_freq_df <- as.data.frame(ao_freq_table)
#   add_attributes <- separate_aotitles %>%
#     group_by(AO_title) %>%
#     summarise (AOEnsembl = paste(Ensembl,collapse="; "),
#                AOgenename = paste(Name2, collapse="; "),
#                AOsummary_go_term = paste(summary_term, collapse="; "))
#   names(ao_freq_df) <- c("AO_title","AO_frequency")
#   ao_freq_df_full <- merge(ao_freq_df, add_attributes,"AO_title")
#   #Counting how often which AOs are associated with all genes
#   
#   separate_ketitles <- separate_rows(aop_associated_genes,KE_title,sep="; ")
#   ke_freq_table <- table(separate_ketitles$KE_title) 
#   ke_freq_df <- as.data.frame(ke_freq_table)
#   add_attributes <- separate_ketitles %>%
#     group_by(KE_title) %>%
#     summarise (KEEnsembl = paste(Ensembl,collapse="; "),
#                KEgenename = paste(Name2, collapse="; "),
#                KEsummary_go_term = paste(summary_term, collapse="; "))
#   names(ke_freq_df) <- c("KE_title","KE_frequency")
#   ke_freq_df_full <- merge(ke_freq_df, add_attributes,"KE_title")
#   #Counting how often which KEs are associated with all genes
#   
#   aop_associated_genes_freq <- bind_rows(aop_freq_df_full,ao_freq_df_full,ke_freq_df_full)
#   
#   aop_link <- list()
#   
#   variables <- ls()
#   #Getting a list of variables defined within the aopprocess function
#   #append_suffix <- function(variable, suffix) {
#   #assign(paste0(variable,"_",suffix), get(variable), envir = .GlobalEnv)
#   #}
#   #Defining a function to add a suffix to the variables created within the aopprocess function
#   for (variable in variables) {
#     aop_link[[variable]] <- get(variable)
#   }
#   return(aop_link)
#   #Appending the given tag to every produced variable within the aopprocess function
#   #Saving the resulting network
# }
# #Because a comparison should be made between selection criteria of the AOP-Wiki query,
# #the aopprocess function is used to be more flexible in defining the query file
# #as well as the suffix that is to be added so that the type of filter/query can be traced back
# 
# aoplink_selected <- aopprocess("AO_KE_Ensembl_query.txt","selected")
# #Matching AOP information to risk genes in the network from selected adverse outcomes relating to neuronal development and psychiatric outcomes
# snw_scz_string_clustered_GO_AOP_selected <- getNetworkName()
# exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO_AOP_selected"),"CX",network=snw_scz_string_clustered_GO_AOP_selected,overwriteFile=TRUE)
# #Exporting network
# 
# 
# aoplink_all <- aopprocess("all_AO_KE_Ensembl_query.txt","all")
# #Matching AOP information to risk genes in the network from all AOs available in AOP-Wiki
# snw_scz_string_clustered_GO_AOP_all <- getNetworkName()
# exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO_AOP_all"),"CX",network=snw_scz_string_clustered_GO_AOP_all,overwriteFile=TRUE)
# #Exporting network
# 
# gettop <- function(input) {
#   freq_df <- input$aop_associated_genes_freq
#   
#   cutoff_aop <- quantile(freq_df$AOP_frequency, probs=0.75,na.rm = TRUE)
#   #Defining cutoff for AOP frequency (top 25% most frequent)
#   topquarter_aop <- freq_df[freq_df$AOP_frequency >= cutoff_aop & !is.na(freq_df$AOP_frequency),1:5,drop=FALSE]
#   #Selecting the top 25% most frequently matched with AOPs and associated information
#   
#   cutoff_ao <- quantile(freq_df$AO_frequency, probs=0.75,na.rm = TRUE)
#   #Defining cutoff for AO frequency (top 25% most frequent)
#   topquarter_ao <- freq_df[freq_df$AO_frequency >= cutoff_ao & !is.na(freq_df$AO_frequency),6:10,drop=FALSE]
#   #Selecting the top 25% most frequently matched with AOs and associated information
#   
#   cutoff_ke <- quantile(freq_df$KE_frequency, probs=0.75,na.rm = TRUE)
#   #Defining cutoff for KE frequency (top 25% most frequent)
#   topquarter_ke <- freq_df[freq_df$KE_frequency >= cutoff_ke & !is.na(freq_df$KE_frequency),11:15,drop=FALSE]
#   #Selecting the top 25% most frequently matched with KEs and associated information
#   
#   top_aopwiki <- list(topquarter_aop=topquarter_aop,topquarter_ao=topquarter_ao,topquarter_ke=topquarter_ke)
# }
# 
# top_selected <- gettop(aoplink_selected)
# top_all <- gettop(aoplink_all)
# 
# makecytable <- function(input) {
#   topquarter_ke <- input$topquarter_ke
#   topquarter_ke_sep <- separate_rows(topquarter_ke,KEEnsembl,sep="; ")
#   mergedkeensg <- union(topquarter_ke_sep$KE_title,topquarter_ke_sep$KEEnsembl)
#   #topquarter_ke_node <- data.frame(combined=mergedkeensg)
#   topquarter_ke<- topquarter_ke_sep[,c("KE_title","KEEnsembl")]
#   
#   #write.table(topquarter_ke_node, file=paste0(getwd(),"/topquarter_ke_node.tsv"),sep="\t",quote=FALSE,row.names=FALSE)
#   write.table(topquarter_ke, file=paste0(other_savepath,sprintf("/topquarter_ke_edge%s.tsv",sub("top","",deparse(substitute(input))))),sep="\t",quote=FALSE,row.names=FALSE)
#   #Writing the KE-gene table to file for Cytoscape import
#   commandsRun(sprintf('network import file columnTypeList=s,t delimiters=\\t file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1',paste0(other_savepath,sprintf("/topquarter_ke_edge%s.tsv",sub("top","",deparse(substitute(input)))))))
#   Sys.sleep(0.5)
#   renameNetwork(sprintf("Top quarter key events - risk genes%s",sub("top","",deparse(substitute(input)))))
# }
# 
# makecytable(top_all)
# makecytable(top_selected)
# 
# 
# 
# topquarter_ke <- top_selected$topquarter_ke
# for (i in 1:ncol(keensgpairs)) {
#   for (j in 1:nrow(keensgpairs)) {
#     keensgpairs[j, i] <- gsub('"', '', keensgpairs[j, i])
#   }
# }
# assoc_aop <- keensgpairs[keensgpairs$KEtitle %in% topquarter_ke$KE_title,c("KEtitle","AOPtitle")]
# assoc_aop <- separate_rows(assoc_aop,AOPtitle, sep="; " )
# write.table(assoc_aop, file=paste0(other_savepath,"/assoc_aop.tsv"),sep="\t",quote=FALSE,row.names=FALSE)
# 
# 
# uniqueaops <- data.frame(AOPtitle = unique(assoc_aop$AOPtitle))
# assoc_ao <- keensgpairs[keensgpairs$AOtitle %in% uniqueaops$AOPtitle, c("AOtitle","AOPtitle")]
