#Adding literature as  source to all imported nodes and adding the doi of the corresponding paper
renameNetwork("Trubetskoy risk genes")
#Renaming the newly imported network
metadata.add("Publications")
metadata.add("Trubetskoy et al. doi: 10.1038/s41586-022-04434-5")
metadata.add("")
networklist.dup <- getNetworkList()
dup.filter <- function(input,suffix) {
filtered_list <- input[substr(input, nchar(input) - 1,nchar(input))==suffix]
}
duplicates <- dup.filter(networklist.dup,"_1")
#Getting duplicate networks (Cytoscape marks duplicate networks with a "_1" suffix to the network name)
delete.dupes <- function(nw) {
setCurrentNetwork(nw)
deleteNetwork()
}
lapply(duplicates,delete.dupes)
#Selecting and deleting duplicate networks
networklist <- getNetworkList()
setCurrentNetwork(networklist[[1]])
for(i in 1:length(networklist)) {
current <- getNetworkName()
altmergeNetworks(c(current,networklist[[i]]), paste(current,networklist[[i]]),"union",inNetworkMerge = TRUE,nodeKeys=c("Ensembl","Ensembl"))
}
#Looping through the network list to merge all currently open networks with each other, creating one large unified network
renameNetwork("Schizophrenia supernetwork")
networklist <- getNetworkList()
snw_scz <- getNetworkName()
#Getting the name of the unified network to preserve it from deletion
lapply(networklist[networklist != snw_scz],deleteNetwork)
#Deleting all networks besides newly generated unified network
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW"),"CX", network = snw_scz, overwriteFile=TRUE)
#Exporting the supernetwork as cx file
## FILTERING NETWORK ------------------------------------------------------------------------------------------------------------------
createColumnFilter(filter.name="type.label",column="Type","Label","IS",apply=FALSE)
createColumnFilter(filter.name="type.anchor",column="Type","Anchor","IS",apply=FALSE)
createColumnFilter(filter.name="type.group",column="Type","Group","IS",apply=FALSE)
createColumnFilter(filter.name="disease.name",column="diseaseName","Schizophrenia","IS")
createCompositeFilter(filter.name="type.label.anchor.group",c("type.label","type.anchor","type.group","disease.name"),"ANY")
deleteSelectedNodes()
#Creating filters and deleting columns in the node table that are not relevant to the supernetwork (leftovers from import sources)
renameNetwork("SCZ_SNW_filtered")
snw_scz_filtered <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered"),"CX", network = snw_scz_filtered, overwriteFile=TRUE)
#Exporting the filtered supernetwork as cx file and tagging it with the time and date made to match with metadata file
## STRING --------------------------------------------------------------------------------------------------------------------------
commandsRun('string stringify colDisplayName=name column=Ensembl compoundQuery=true cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
commandsRun('string expand additionalNodes=1000 network=current nodeTypes="Homo sapiens" selectivityAlpha=0.9')
#STRINGifying and expanding the network with a 0.9 confidence cutoff (curated information)
createNodeSource("STRINGnode")
#Tagging the newly added nodes as having been sourced from STRING
mapTableColumn("stringdb::canonical name","Human","Uniprot-TrEMBL","Ensembl",force.single=TRUE)
#Mapping stringdb canonical names (Uniprot-TrEMBL identifiers) to Ensembl gene identifiers
#This step generates a second Ensembl column ('Ensembl (1)') with ENSG identifiers for the STRING-imported nodes
renameTableColumn("Ensembl (1)","Ensembldup")
#Renaming the duplicate Ensembl column for easier handling
renameNetwork("SCZ_SNW_filtered_STRING")
snw_scz_filtered_string <- getNetworkName()
stringified_nodetable <- paste0(nw_savepath,sprintf("%s node table.csv",snw_scz_filtered_string))
#Saving the file path to the node table for easier reading
commandsRun(sprintf('table export options=CSV outputFile=%1$s table="%2$s default  node"',stringified_nodetable,snw_scz_filtered_string))
#Exporting the node table as .csv file to the current session's "Network" folder
read_stringified_nodetable <- read.csv(stringified_nodetable)
#saving the node table as object
read_stringified_nodetable$Ensembl <- ifelse(read_stringified_nodetable$Ensembl == read_stringified_nodetable$Ensembldup, as.character(read_stringified_nodetable$Ensembl),
ifelse(is.na(read_stringified_nodetable$Ensembl) | read_stringified_nodetable$Ensembl =="",as.character(read_stringified_nodetable$Ensembldup),
ifelse(is.na(read_stringified_nodetable$Ensembldup) | read_stringified_nodetable$Ensembldup=="",as.character(read_stringified_nodetable$Ensembl),"No Match")))
#As the identifier mapping from STRING ENSP to ENSG identifiers generates a second Ensembl column, they are merged into the originial Ensembl column if the contents of the cell match or either is blank
read_stringified_nodetable = subset(read_stringified_nodetable,select= -Ensembldup)
#Removing the duplicate Ensembl column from the table
write.csv(read_stringified_nodetable, file=stringified_nodetable)
#Overwriting the previously exported table with the version containing the merged Ensembl column
renameTableColumn("@id","X.id")
#Renaming the '@id' column in the Cytoscape table to avoid issues when reimporting the .csv (@id is automatically converted to X.id in the CSV)
loadTableData(read_stringified_nodetable,data.key.column="X.id",table.key.column="X.id")
#Reimporting the .csv with the merged Ensembl column to the network as to have ENSG identifiers for almost all nodes
mapTableColumn("Ensembl","Human","Ensembl","HGNC")
#Generating a new column 'HGNC' from Ensembl identifiers - easier and less error-prone than merging various name columns from different import sources
renameTableColumn("HGNC","Name2")
#Renaming the new 'HGNC' column to 'Name2', which is now to be used as default name column. ('shared name' and 'name' columns are immutable and cannot be deleted or renamed)
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered_STRING"),"CX",network=snw_scz_filtered_string,overwriteFile=TRUE)
#Exporting the filtered, stringified supernetwork as cx file and tagging it with the time and data to match with the metadata file
## CLUSTERING ----------------------------------------------------------------------------------------------------------------------
createColumnFilter(filter.name="delete.noensembl", column="Ensembl","ENSG","DOES_NOT_CONTAIN")
deleteSelectedNodes()
#Filtering out nodes that do not have an ENSG Ensembl identifier mapped to them
marked_cols <- as.list(getTableColumnNames()[!(getTableColumnNames() %in% c("selected","name.copy" ,"SUID","shared name","name","Name2","DisGeNET","WikiPathways","Ensembl","Publication","Publication.doi","STRINGnode"))])
lapply(marked_cols, function(column) {
deleteTableColumn(column=column)
})
#Deleting all the columns besides immutable columns, Ensembl, name, and source columns
metadata.add("GLay Clustering")
metadata.add(capture.output(commandsRun('cluster glay clusterAttribute=__glayCluster createGroups=false network=current restoreEdges=true showUI=true undirectedEdges=true')))
#Clustering the network using the GLay community cluster from the clusterMaker Cytoscape app and recording outcome to metadata
renameNetwork("SCZ_SNW_filtered_STRING_clustered")
renameTableColumn('__glayCluster','gLayCluster')
#Renaming the newly generated gLayCluster column as the original name with two underscores is not recognized during gene ontology
snw_scz_filtered_string_clustered <- getNetworkName()
clustered_nodetable <- paste0(nw_savepath,sprintf("/%s node table.csv",snw_scz_filtered_string_clustered))
#Saving the file path to the node table for easier reading (note the double space between node and table)
commandsRun(sprintf('table export options=CSV outputFile=%1$s table="%2$s default  node"',clustered_nodetable,snw_scz_filtered_string_clustered))
#Exporting the node table as .csv file to the current session's "Network" folder
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered_STRING_clustered"),"CX",network=snw_scz_filtered_string_clustered,overwriteFile=TRUE)
#Exporting the filtered, stringified, clustered supernetwork as cx file and tagging it with the time and data to match with the metadata file
read_clustered_nodetable <- read.csv(clustered_nodetable)
#Reading the exported csv
split_df <- split(read_clustered_nodetable$Ensembl,read_clustered_nodetable$gLayCluster)
#Splitting the node table by cluster
nodecount <- sapply(split_df, length)
#Counting how many nodes are in each cluster
countmatrix <- matrix(seq(1,length(nodecount)), ncol=1)
countmatrix <- cbind(countmatrix,as.numeric(nodecount))
#Construcing a matrix showing how many nodes are in each cluster
invalidclusters <- as.list(countmatrix[countmatrix[, 2] < 5, 1])
#Getting which clusters have fewer than 5 nodes associated with them
valid_clustered_nodetable <- read_clustered_nodetable[!read_clustered_nodetable$gLayCluster %in% invalidclusters, ]
#Generating a new df containing only nodes associated with clusters that had 5 or more nodes
split_tbl <- split(valid_clustered_nodetable, valid_clustered_nodetable$gLayCluster)
sourcecount <- function(cluster) {
wpcount <- sum(split_tbl[[cluster]][["WikiPathways"]] == 1, na.rm = TRUE)
dgcount <- sum(split_tbl[[cluster]][["DisGeNET"]] == 1, na.rm = TRUE)
litcount <- sum(split_tbl[[cluster]][["Publication"]] == 1, na.rm = TRUE)
stringcount <- sum(split_tbl[[cluster]][["STRINGnode"]] == 1, na.rm = TRUE)
result_df <- data.frame(
gLayCluster = split_tbl[[cluster]][["gLayCluster"]][1],
WikiPathways_source = wpcount,
DisGeNET_source = dgcount,
Publication_source = litcount,
STRING_source = stringcount
)
}
sources_count <- do.call(rbind, lapply(seq_along(split_tbl),sourcecount))
#For each cluster, counting how many nodes are associated with which sources
## GO ANALYSIS ------------------------------------------------------------------------------------------------------------------------
split_df <- split(valid_clustered_nodetable$Ensembl,valid_clustered_nodetable$gLayCluster)
split_list <- lapply(split_df, as.vector)
#Splitting the node table by cluster number, i.e. lists of Ensembl IDs are created per cluster
go <- function(cluster) {
gost(
query = cluster,
organism = "hsapiens",
ordered_query = FALSE,
multi_query = TRUE,
significant = TRUE,
exclude_iea = FALSE,
measure_underrepresentation = FALSE,
evcodes = FALSE,
user_threshold = 0.05,
correction_method = "g_SCS",
domain_scope ="annotated",
custom_bg = NULL,
numeric_ns = "",
sources = NULL,
as_short_link = FALSE,
highlight = TRUE
)
}
go_list <- lapply(split_list,go)
#Iterating the gost GO function over all clusters
saveRDS(go_list, file=paste0(nw_savepath,"/go_list.rds"))
#Saving the entire generated GO analysis as R object locally
get_top_terms <- function(cluster) {
terms <- toString(go_list[[cluster]][["result"]][["term_name"]][1:5])
#Extracting the top 5 term names associated with each cluster
pval <- toString(go_list[[cluster]][["result"]][["p_values"]][1:5])
#Extracting the p-values for the corresponding top 5 term names
nodes <- paste(go_list[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]],collapse=",")
nnodes <- str_count(toString(go_list[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]]),"\\S+")
#Extracing the number of nodes/genes contained in each cluster
result_df <- data.frame(
gLayCluster = cluster,
GO_Terms = terms,
GO_Pvals = pval,
Nodes = nodes,
N_nodes = nnodes
)
}
topterms_df <- do.call(rbind, lapply(names(go_list),get_top_terms))
#Getting top 5 term names and corresponding p-values for each cluster and storing in topterms_df
topterms_df <- cbind(topterms_df,sources_count)
#joining the cluster table and the table detailing the amount of sources per cluster
write.table(topterms_df, file=paste0(getwd(),"/CSVs/GO-clusters-vis.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
#Writing the table to file for Cytoscape import during visualisation
loadTableData(topterms_df,data.key.column="gLayCluster",table.key.column="gLayCluster")
#Loading the generated top terms and p-values back to the supernetwork; every gene belonging to cluster x is now associated with the top terms of cluster x
deleteTableColumn('gLayCluster.1')
#Deleting duplicate gLayCluster column that appears after importing top terms data back to network
renameNetwork(title=paste0(getNetworkName(),"_GO"))
snw_scz_filtered_string_clustered_go <- getNetworkName()
#Renaming and saving the network name to indicate addition of GO information
compare_term_id_lists <- function(list1, list2) {
common_elements <- intersect(list1, list2)
return(length(common_elements))
}
#Setting up a function to get intersections between cluster term IDs
match_df <- data.frame(Cluster1 = character(),
Cluster2 = character(),
Matches = numeric(),
stringsAsFactors = FALSE)
#Setting up a df to store output in
for (i in 1:(length(go_list) - 1)) {
for (j in (i + 1):length(go_list)) {
term_id_i <- go_list[[i]][["result"]][["term_id"]]
term_id_j <- go_list[[j]][["result"]][["term_id"]]
matches <- compare_term_id_lists(term_id_i, term_id_j)
match_df <- rbind(match_df, data.frame(Cluster1 = names(go_list)[i],
Cluster2 = names(go_list)[j],
Matches = matches))
#Iterating over go_list to compare GO term IDs between every cluster and store number of overlaps
}
}
colnames(match_df) <- c("source","target","GO_term_matches")
#Renaming columns
write.table(match_df, file=paste0(getwd(),"/CSVs/match_df.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered_STRING_clustered_GO"),"CX",network=snw_scz_filtered_string_clustered_go,overwriteFile=TRUE)
#Exporting the filtered, stringified, clustered supernetwork after GO as cx file and tagging it with the time and data to match with the metadata file
##AOP ---------------------------------------------------------------------------------------------------------------------------
createColumnFilter(
filter.name = "has_GO_result",
column = "N_nodes",
criterion = 0,
predicate = "GREATER_THAN",
anyMatch = TRUE,
apply = TRUE
)
#Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
#Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way
#The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
KERList <-  read.table(file=paste0(getwd(),"/CSVs/AOP/KERList.tsv"),header=TRUE, sep ="\t")
#Reading a tsv obtained from AOPwiki through a SPARQL query
#The tsv contains key-event relationships from AOPs containing AOs relating to manually selected neural/psychological outcomes
#The exported tsv from the AOPwiki SPARQL endpoint has quotation marks around each element, hindering mapping
#The quotation marks are removed using a text editor (Notepad++ here)
KEEnsembl <- read.table(file=paste0(getwd(),"/CSVs/AOP/KEEnsembl.tsv"),header=TRUE, sep ="\t")
#Reading a tsv from AOPWiki SPARQL endpoint containing all KEs and the ENSG IDs they are associated with
#For easier merging of ENSG IDs to the manually selected KEs contained in KERList, this file needs to be filtered
allKEsFromList <- data.frame(allKEs = c(KERList$KEup,KERList$KEdown))
#Combining both up- and downregulated KEs into a single column
filtered_KEEnsembl <- subset(KEEnsembl, ke %in% allKEsFromList$allKEs)
#Removing KE-Ensembl rows that are not found in the selected KEs
write.table(filtered_KEEnsembl, file=paste0(getwd(),"/CSVs/AOP/KEEnsembl_filtered.tsv"), quote=FALSE,row.names=FALSE,sep="\t" )
#Writing the filtered KE-ENSG list to file for Cytoscape loading
commandsRun(sprintf('network import file columnTypeList="ea,s,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList=-- Create new network collection --',paste0(getwd(),"/CSVs/AOP/KERList.tsv")))
#Loading selected KERs into Cytoscape as new network
commandsRun(sprintf('table import file dataTypeTargetForNetworkCollection="Node Table Columns" delimiters=\\t file=%s firstRowAsColumnNames=true keyColumnForMapping="shared name" keyColumnIndex=1 startLoadRow=1',paste0(getwd(),"/CSVs/AOP/KEMap.tsv")))
#Loading a KE mapping file generated from a second SPARQL query that fetches all KE URIs and their titles from AOPwiki into the KER network
#This file also had quotation marks removed using a text editor
commandsRun(sprintf('network import file columnTypeList="s,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList=-- Create new network collection --',paste0(getwd(),"/CSVs/AOP/KEEnsembl_filtered.tsv")))
#Loading the filtered KE-ENSG list as new network into Cytoscape
altmergeNetworks(sources = c('KERList.tsv','KEEnsembl_filtered.tsv'),
title='KERs',
operation='union'
)
#Merging the manually curated KERList network and the KE-ENSG list to extend the selected KEs with associated genes
deleteNetwork(network='KERList.tsv')
deleteNetwork(network='KEEnsembl_filtered.tsv')
#Deleting networks used to make merged network
mapTableColumn(
column = 'name',
species= 'Human',
map.from = 'Ensembl',
map.to = 'HGNC',
force.single = 'true'
)
renameTableColumn('HGNC','Name2')
commandsRun(sprintf('table export options=CSV outputFile=%s table="KERs default node"', paste0(getwd(),"/CSVs/AOP/KE_table.csv")))
#Exporting the node table for manipulation via R
KE_table <- read.csv(paste0(getwd(),"/CSVs/AOP/KE_table.csv"))
#Loading the previously exported node table as R object
KE_table <- KE_table %>%
mutate(Ensembl=ifelse(grepl("ENSG",name),name,NA))
#Getting and transposing ENSG IDs from the name col to a new 'Ensembl' col to be used as key
KE_table <- KE_table %>%
mutate(KE_URI=ifelse(!grepl("ENSG",name),name,NA))
#Getting and transposing KE URIs (all rows not containing 'ENSG') from the name col to a new 'KE_URI' col
#These two steps are done as the 'name' and 'shared name' columns will be difficult to work with since they mix both ENSG and other data types
KE_table <- KE_table %>%
mutate(AOPwiki=1)
#Adding a new column to the node table indicating that the gene nodes in the KE network are imported from AOPwiki
KE_table <- KE_table %>%
select(-shared.name)
#Loading the node table in R changes the name the 'shared name' column to 'shared.name' to avoid a space, this results in a duplicate 'shared.name' column when importing the table back to Cytoscape
#For this reason, 'shared.name'/'shared name' is simply removed from the df as 'names' can also be used for mapping and contains the same information anyways
write.csv(KE_table, file=paste0(getwd(),"/CSVs/AOP/KE_table.csv"), row.names=FALSE)
#Overwriting the previously exported node table with the updated version
loadTableData(
data = read.table(file=paste0(getwd(),"/CSVs/AOP/KE_table.csv"),header=TRUE, sep =","),
data.key.column = "name",
table.key.column = "name"
)
#Loading the updated node table back to the network
altmergeNetworks(sources = c('SCZ_SNW_filtered_STRING_clustered_GO','KERs'),
title='SCZ_SNW_filtered_STRING_clustered_GO_KER',
operation='union',
nodeKeys = c('Ensembl','Ensembl')
)
#Merging the KER network with the supernetwork based on Ensembl ID
#As this is an union merge, all nodes from the KER network are introduced to the SNW, but the goal was simply to annotate existing genes in the SNW with KEs
#Therefore, some filtering is needed
commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_filtered_STRING_clustered_GO_KER default node"', paste0(getwd(),"/CSVs/AOP/SNW_KER_node.csv")))
SNW_KER_node <- read.csv(paste0(getwd(),"/CSVs/AOP/SNW_KER_node.csv"))
#Saving the SNW node table to file and loading it as R object
KE_only_nodes <- SNW_KER_node %>%
filter(AOPwiki == 1 & is.na(DisGeNET) & is.na(WikiPathways) & is.na(Publication) & is.na(STRINGnode)) %>%
pull(Ensembl)
#Getting a list of nodes that only have AOPwiki as source
#This implies that these nodes were not already present in the network since they would've been merged to existing nodes that already had at least one source prior
#It is not desired to add new gene nodes to the network from the KER network; gene nodes serve only as references for connecting KEs to already existing genes in the supernetwork
selectNodes(nodes=KE_only_nodes,
by.col="Ensembl")
deleteSelectedNodes()
#Selecting and deleting nodes based on the prior criteria
commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_filtered_STRING_clustered_GO_KER default edge"', paste0(getwd(),"/CSVs/AOP/SNW_KER_edge.csv")))
SNW_KER_edge <- read.csv(paste0(getwd(),"/CSVs/AOP/SNW_KER_edge.csv"))
#Exporting the SNW edge table to file and loading it as R object
valid_KE_ensg <- SNW_KER_edge[grepl("ENSG", SNW_KER_edge$name) & grepl("aop.events", SNW_KER_edge$name),]
#Getting a list of KEs that do have interactions with genes
valid_KE <- str_extract(valid_KE_ensg$name, "https://identifiers.org/aop.events/\\S+")
valid_KE <- unique(valid_KE)
#Getting the URIs of the KEs that have interactions with genes
bad_KE_df <- SNW_KER_edge %>%
filter(
grepl("aop\\.events", name, ignore.case=TRUE) &
!grepl(paste(valid_KE, collapse="|"), name)
)
#Getting a list of the remaining KEs that are not associated with a gene or with a KE that is associated with a gene (to preserve KERs)
bad_KE_list <- str_extract_all(bad_KE_df$name, "https://identifiers\\.org/aop\\.events/\\d+")
bad_KE <- unique(unlist(bad_KE_list))
#Getting a list of unique bad KEs
selectNodes(nodes=bad_KE, by.col="name")
deleteSelectedNodes()
commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
Sys.sleep(1)
commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#Removing duplicate edges from current network
#RCy3 has a deleteDuplicateEdges function but it seems bugged since it always just removes 1 duplicate edge at a time
#Using the command line function removes all duplicate edges right away and avoids having to run a filter to select duplicate edges which is much slower
renameNetwork("KE-AOP")
commandsRun(sprintf('network import file columnTypeList="x,sa,s,ta,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t',paste0(getwd(), "/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#Removing duplicate edges from current network
renameNetwork("AOP-AO")
altmergeNetworks(sources=c("KE-AOP","AOP-AO"),
title='KE-AOP-AO',
operation='union',
nodeKeys=c('name','name'))
#Merging the AO and AOP networks
#Necessary to first import as separate networks and then merge as only one source and target col can be selected during network import
altmergeNetworks(sources=c('KE-AOP-AO','SCZ_SNW_filtered_STRING_clustered_GO_KER'),
title='SCZ_SNW_filtered_STRING_clustered_GO_AOP',
operation='union',
nodeKeys=c('name','name'))
#Merging the AOP-AO network to the SNW-KE network to extend KEs connected to risk genes with corresponding AOPs/AOs
deleteNetwork(network='KE-AOP-AO')
deleteNetwork(network='KERs')
deleteNetwork(network='SCZ_SNW_filtered_STRING_clustered_GO_KER')
deleteNetwork(network='KE-AOP')
deleteNetwork(network='AOP-AO')
#Deleting networks that are no longer needed, used to generate SNW-AOP network
SNW_AOP <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,SNW_AOP),"CX",network=SNW_AOP)
#Exporting the SNW containing the AOP extension
##RAW SNW VISUALISATION ---------------------------------------------------------------------------------------------------------------------------
setCurrentNetwork(snw_scz_filtered_string_clustered_go)
createColumnFilter(
filter.name = "has_GO_result",
column = "N_nodes",
criterion = 0,
predicate = "GREATER_THAN",
anyMatch = TRUE,
apply = TRUE
)
#Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
#Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way
#The idea is to link GO terms (formed by clusters/genes)
#These changes to the visualization are essentially only visible when Cytoscape is set to always render details
#The network is big and not really organized besides clusters, the pie chart visualization that follows gives a much better impression
createVisualStyle("SNW_vis")
#Creating a new visual style that is subsequently customized
setVisualStyle("SNW_vis")
#Applying the new visual style
clusters <- as.character(unique(getTableColumns("node","gLayCluster"))$gLayCluster)
#gLayCluster column has many repeats of the clusters but a list of unique clusters is needed for table.column.values
clustercolors <- as.list(paletteColorRandom(length(clusters)))
#Generating a set of random colors based on the number of clusters in the SNW
#Make this constant, generate 100 colors or so once
#Then just select first N where N=Nclusters, so it stays flexible when more/fewer clusters are generated
#Much easier for legend too
setNodeColorMapping(table.column = "gLayCluster",
table.column.values=clusters,
colors=clustercolors,
mapping.type="d",
default.color="#FF5555",
style.name = "SNW_vis"
)
#table.column values must be defined like this as the gLayCluster column has many repeats of cluster numbers
#Random colors are generated per cluster based on the number of different clusters in the SNW
setEdgeLineWidthDefault(new.width = 0.5,
style.name = "SNW_vis")
#Reducing edge width to decrease hairball effect
setNodeLabelMapping(table.column = "Name2",
style.name="SNW_vis")
#Changing node labels to show HGNC name
##PIE CHART VISUALISATION -----------------------------------------------------------------------------------------------------------------------
commandsRun(sprintf("network import file columnTypeList='s,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true delimiters=\\t rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(getwd(),"/CSVs/GO-clusters-vis.tsv")))
#Importing the previoulsy generated table 'GO-clusters-vis' back to Cytoscape as new network
#Essential to use .tsv and importing as such to avoid conflicts generated by .csv - commas separating terms in a string are interpreted as different columns by Cytoscape
Sys.sleep(1)
renameNetwork("GO_Visualisation_SCZ_SNW")
loadTableData(
data = read.table(file=paste0(getwd(),"/CSVs/summary_go_terms.txt"),header=TRUE, sep ="\t"),
data.key.column = "gLayCluster",
table.key.column = "gLayCluster"
)
#Loading an additional column into the network containing manually created summaries of GO terms based on biological knowledge
commandsRun(sprintf("network import file columnTypeList='s,t,ea' file=%s firstRowAsColumnNames=true delimiters=\\t startLoadRow=1", paste0(getwd(),"/CSVs/match_df.tsv")))
#Loading edge information (i.e. intersections between GO terms for each cluster)
createVisualStyle(style.name = 'GO_vis')
#Creating a new visual style that is subsequently customized
setVisualStyle("GO_vis")
#Applying a basic visual style to the network
setNodeSizeMapping(
table.column = "N_nodes",
sizes = c(50,200),
mapping.type = "c",
style.name= "GO_vis"
)
#Setting the node size proportional to the number of nodes making up a cluster, e.g. a cluster containing more nodes is bigger
setNodeCustomPieChart(
columns = c("DisGeNET_source","Publication_source","WikiPathways_source","STRING_source"),
colors = paletteColorBrewerPaired(value.count = 8),
style.name= "GO_vis"
)
#Turning nodes into pie charts showing which sources make up the proportions of the nodes in them
setNodeShapeDefault("ellipse",
style.name= "GO_vis")
setNodeFillOpacityDefault(
new.opacity = 0,
style.name= "GO_vis"
)
#Removing node background
setNodeBorderWidthDefault(
new.width=0,
style.name= "GO_vis"
)
setNodeLabelMapping(
table.column = "summary_term",
style.name= "GO_vis"
)
#Changing node label to the processes/terms the nodes represent
setNodeFontSizeDefault(
new.size = 20,
style.name= "GO_vis"
)
#Setting node font size
setNodeLabelPositionDefault(
new.nodeAnchor = "S",
new.graphicAnchor = "N",
new.justification = "c",
new.xOffset = "0",
new.yOffset = "0",
style.name= "GO_vis"
)
#Moving label
setEdgeLineWidthMapping(
table.column = "GO_term_matches",
table.column.values = c(0,861),
widths = c(0,50),
mapping.type = "c",
style.name= "GO_vis"
)
#Setting edge width proportional to number of shared GO terms
setEdgeOpacityDefault(
new.opacity = 70,
style.name= "GO_vis"
)
#Decreasing edge opacity
setEdgeColorDefault('#DD3497',
style.name= "GO_vis")
#Changing edge color
commandsRun('layout force-directed defaultEdgeWeight=0.5 defaultNodeMass=3 defaultSpringCoefficient=1e-4 edgeAttribute="GO_term_matches" defaultSpringLength=300 isDeterministic=true maxWeightCutoff=1.79769E308 minWeightCutoff=0E0 numIterations=200 type=Heuristic')
layoutNetwork('force-directed')
#Adding network layout
#scaleLayout(axis="Both Axes", scaleFactor = 0.95)
#Not working as requires Cytoscape v.3.10.2 which does not seem available yet?
renameNetwork("Supernetwork functional analysis")
deleteNetwork(network="GO_Visualisation_SCZ_SNW")
go_vis_nw <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"GO_Visualisation_SCZ_SNW"),"CX",network=go_vis_nw,overwriteFile=TRUE)
fitContent()
exportImage(filename = paste0(getwd(),"/Visualisations/SNW_functional_analysis"),type="SVG", overwriteFile=TRUE, zoom="200")
#Exporting the visualisation as network and as svg
citation()
RStudio.Version()
citation("RCy3")
citation("stringr")
citation("httr")
citation("rWikiPathways")
citation("gprofiler2")
citation("dplyr")
citation("BiocManager")
citation("RColorBrewer")
