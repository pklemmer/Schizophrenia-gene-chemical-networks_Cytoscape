install.packages("devtools")
library(devtools)
install_github("egonw/rrdf", subdir="rrdflibs")
install_github("egonw/rrdf", subdir="rrdf", build_vignettes = FALSE)
?rrdf
library(rrdf)
?rrdf
sparql.remote(
"https://sparql.wikipathways.org/",
paste("SELECT (?o as ?pwOntologyTerm) (str(?titleLit) as ?title) ?pathway",
"WHERE {
?pathwayRDF wp:ontologyTag ?o ;
foaf:page ?pathway ;
dc:title ?titleLit ;
dcterms:identifier "WP1560" . #Replace "WP1560" with WP ID of interest
sparql.remote
sparql.remote("http://rdf.farmbio.uu.se/chembl/sparql",
paste(
"SELECT DISTINCT ?predicate",
"WHERE { [] ?predicate [] }"
),
user="user", password="password"
)
setwd("~/GitHub/SCZ-CNV")
#Setting working directory
rm(list=ls())
#Cleaning up workspace
packages <- c("dplyr","httr","stringr","gprofiler2")
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
if(!"rWikiPathways" %in% installed.packages()){
if (!requireNamespace("BiocManager", quietly=TRUE))
install.packages("BiocManager")
BiocManager::install("rWikiPathways")
}
if(!"RCy3" %in% installed.packages()){
if (!requireNamespace("BiocManager", quietly=TRUE))
install.packages("BiocManager")
BiocManager::install("RCy3")
}
#Checking if required packages are installed and installing if not
#Different structure for rWikiPathways and RCy3 packages as these are not installed directly but via the BiocManager package
invisible(lapply(c(packages,"rWikiPathways","RCy3"), require, character.only = TRUE))
#Loading libraries
sysdatetime <- Sys.time()
datetime <- format(sysdatetime, format = "%Y-%m-%d_%Hh%M")
dir.create("Outputs")
dir.create(sprintf("Outputs/Session-%s",datetime))
dir.create(sprintf("Outputs/Session-%s/Networks",datetime))
#Creating directories for outputs generated by this script to be saved in; new "Session" folder created each time the script is ran (contains generated networks, metadata, and sessionInfo)
nw_savepath <- sprintf("%1$s/Outputs/Session-%2$s/Networks/",getwd(),datetime)
file.create(sprintf("Outputs/Session-%s/metadata.txt",datetime))
#Creating a new metadata file with the current date and time as suffix for easier organisation
#Such a metadata file should be generated every time this script is ran to record parameters and versions of functions or databases, including the time avoids files being overwritten if the script is run multiple times a day (can even include seconds if script is ran multiple times per minute)
metadata.add <- function(info) {
write(sapply(info, as.character), sprintf("Outputs/Session-%s/metadata.txt",datetime),append=TRUE, sep = "\n")
}
metadata.add(sysdatetime)
metadata.add(Sys.timezone())
metadata.add("")
#Adding the timezone, date, and time to the metadata
invisible(file.create(sprintf("Outputs/Session-%s/sessioninfo-%s.txt",datetime,datetime)))
writeLines(capture.output(sessionInfo()),sprintf("Outputs/Session-%s/sessioninfo-%s.txt",datetime,datetime))
#Generating and adding a sessionInfo file to the current session output folder
cytoscapePing()
cytoscapeVersionInfo()
#Checking if Cytoscape is running and version info
metadata.add(capture.output(cytoscapeVersionInfo()))
checkinstall.app <- function(app) {
status_string <- getAppStatus(app)
#Getting install status of app
words <- strsplit(status_string, " ")[[1]]
last_word <- tail(words, 1)
#getAppStatus returns a character string instead of a logical value, so the last word (usually either "Installed" or "Uninstalled") from the output is checked
if (last_word == "Installed") {
print(sprintf("App %s is already installed.",app))
} else {
installApp(app)
print(sprintf("Installed app %s.",app))
}
}
#Function to check whether required Cytoscape apps are installed and installing them if not
applist <- c("Wikipathways", "DisGeNET-app", "CyTargetLinker","stringApp","BridgeDb","clusterMaker2")
#WikiPathways v.3.3.10
#DisGeNET-app v.7.3.0
#CyTargetLinker v. 4.1.0
#stringApp v. 2.0.2
#BridgeDb v.1.2.0
#clusterMaker2 v.2.3.4
lapply(applist,checkinstall.app)
#Checking and installing (if required) necessary Cytoscape apps
lapply(applist,getAppInformation)
metadata.add("Required Cytoscape apps and versions:")
invisible(metadata.add(print(lapply(applist,getAppInformation))))
metadata.add("")
# FUNCTION DICTIONARY-------------------------------------------------------------------------------------------------------------------
.defaultBaseUrl <- 'http://127.0.0.1:1234/v1'
#Defining the default base URL found in the RCy3 source as R object for altmergeNetworks
altmergeNetworks <- function(               sources = NULL,
title = NULL,
operation = "union",
nodeKeys = NULL,
nodeMergeMap = NULL,
nodesOnly = FALSE,
edgeKeys = NULL,
edgeMergeMap = NULL,
networkMergeMap = NULL,
inNetworkMerge = TRUE,
base.url = .defaultBaseUrl) {
cmd.string <- 'network merge' # a good start
# sources must be suppled
if(is.null(sources)) {
message("Missing sources!")
return(NULL)
} else {
sources.str <- paste(sources, collapse = ",")
cmd.string <- paste0(cmd.string,' sources="',sources.str,'"')
}
# defaults
cmd.string <- paste0(cmd.string,' operation=',operation)
cmd.string <- paste0(cmd.string,' nodesOnly=',nodesOnly)
cmd.string <- paste0(cmd.string,' inNetworkMerge=',inNetworkMerge)
# optional args
if(!is.null(title))
cmd.string <- paste0(cmd.string,' netName="',title,'"')
if(!is.null(nodeKeys))
cmd.string <- paste0(cmd.string,' nodeKeys="',paste(nodeKeys, collapse = ","),'"')
if(!is.null(edgeKeys))
cmd.string <- paste0(cmd.string,' edgeKeys="',paste(edgeKeys, collapse = ","),'"')
if(!is.null(nodeMergeMap)){
nodeMergeMap.str <- paste(nodeMergeMap, collapse = ",")
nodeMergeMap.str <- gsub("c\\(", "{", nodeMergeMap.str)
nodeMergeMap.str <- gsub("\\)", "}", nodeMergeMap.str)
cmd.string <- paste0(cmd.string,' nodeMergeMap="',nodeMergeMap.str,'"')
}
if(!is.null(edgeMergeMap)){
edgeMergeMap.str <- paste(edgeMergeMap, collapse = ",")
edgeMergeMap.str <- gsub("c\\(", "{", edgeMergeMap.str)
edgeMergeMap.str <- gsub("\\)", "}", edgeMergeMap.str)
cmd.string <- paste0(cmd.string,' edgeMergeMap="',edgeMergeMap.str,'"')
}
if(!is.null(networkMergeMap)){
networkMergeMap.str <- paste(networkMergeMap, collapse = ",")
networkMergeMap.str <- gsub("c\\(", "{", networkMergeMap.str)
networkMergeMap.str <- gsub("\\)", "}", networkMergeMap.str)
cmd.string <- paste0(cmd.string,' networkMergeMap="',networkMergeMap.str,'"')
}
res.data <- commandsPOST(cmd.string, base.url = base.url)
if(!is.null(res.data$SUID))
return(res.data$SUID)
else
return(res.data)
}
#Normally, RCy3's 'mergeNetworks' function would be used to unify imported networks into one supernetwork
#This function does however not work on the latest RCy3 release (v.2.22.1), but does work when running the script on RCy3 v.2.14.2
#RCy3 2.14.2 requires R v.4.1.3, requiring the entire script to run on an old version of R for one function that is used once
#Here, we redefine the function using the source code from RCy3 v.2.14.2 and simply use this alternate function to merge networks
queryspecies.wp <- c("Homo sapiens","Rattus norvegicus","Mus musculus")
getPathways.wp <- function(i) {
pw <- findPathwaysByText(i)
pw <- pw %>%
dplyr::filter(species %in% queryspecies.wp)
#Filtering by species
pw.ids <- paste0(i, "_wpids")
assign(pw.ids, as.character(pw$id),envir = .GlobalEnv)
#Extracting WP IDs
}
#Function to query WikiPathways using keyword and to extract WP IDs for the import function
createNodeSource <- function(source,doi=NULL) {
if (source == "WikiPathways") {
networkname <- getNetworkName()
nodetable <- paste0(networkname," default node")
}
#Networks imported from WikiPathways have a type in the node table designations, as they have 2 spaces between "default" and "node" instead of one
#This check determines which node table name format is to be applied depending on the source (WikiPathways or other)
else {
networkname <- getNetworkName()
nodetable <- paste0(networkname," default node")
}
commandsRun(sprintf("table create column columnName=fromWikiPathways table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=fromDisGeNET table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=fromPublication table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=Publication.doi table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=fromSTRING table=%s type=string",nodetable))
#Creating a new column for each source used for all networks
if ( source == "STRINGnode") {
commandsRun(sprintf('table set values columnName=%1$s handleEquations=false rowList="selected:true" table=%2$s value=1',source,nodetable))
}
else {
commandsRun(sprintf("table set values columnName=%1$s handleEquations=false rowList=all table=%2$s value=1",source,nodetable))
#Filling the new column of the corresponding source with 1 to indicate which source the node is imported from
}
if (!is.null(doi)) {
commandsRun(sprintf("table set values columnName=Publication.doi handleEquations=false rowList=all table=%1$s value=%2$s",nodetable,doi))
#Adding doi for literature used if provided
}
}
#Function to create new column in node table specifying origin of network/node
#import <- function(j) {
#commandsRun(paste0('wikipathways import-as-network id=', j))
#Pasting WikiPathways IDs into a Cytoscape command line prompt to import as networks
#createNodeSource("WikiPathways")
#Filling the 'WikiPathways' column with 1 to indicate the source
#}
#Importing pathways from WikiPathways by pathway ID
disgenetRestUrl<-function(netType,host="127.0.0.1",port=1234,version="v7"){
if(is.null(netType)){
print("Network type not specified.")
}else{
disgeneturl<-sprintf("http://%s:%i/disgenet/%s/%s",host,port,version,netType)
}
return (disgeneturl)
}
net <- "gene-disease-net"
disgenetRestUrl(netType = net)
#Defining object for REST to call DisGeNET automation module; defining that we will be using gene-disease associations (GDA)
disgenetRestCall<-function(netType,netParams){
disgeneturl<-disgenetRestUrl(netType)
restCall<-POST(disgeneturl, body = netParams, encode = "json")
result<-content(restCall,"parsed")
return(result)
}
#Object that executes REST calls to DisGeNET module in Cytoscape
geneDisParams <- function(source,dis,min) {list(
source = source,
assocType = "Any",
diseaseClass = "Any",
diseaseSearch = dis,
geneSearch = " ",
initialScoreValue = min,
finalScoreValue = "1.0"
)}
#Specifying parameters of the GDA network to be imported
# SCHIZOPHRENIA =======================================================================================================================
## IMPORTING AND MERGING ---------------------------------------------------------------------------------------------------------------
genedisparams.scz.df <- read.table("CSVs/disgenetparams-scz.txt",header=TRUE,sep = "\t")
#Loading relevant gene-disease networks from DisGeNET
#Networks of interest manually added into tsv where it is easier to adjust filters
disgeneturl <- c()
#Preparing container for DisGeNET URL to be saved for addition to metadata file
apply(genedisparams.scz.df,1,function(row) {
gdp <- geneDisParams(row["source"],row["dis"],row["min"])
disgeneturl <<- disgenetRestUrl(net)
#Fetching the DisGeNET URL used to make this call
geneDisResult <- disgenetRestCall(net,gdp)
#Executing the DisGeNET query
createNodeSource("fromDisGeNET")
#Adding information about data source to each node
mapTableColumn("geneName","Human","HGNC","Ensembl")
#Mapping the HGNC gene name from the geneName column in the node table to Ensembl identifiers
mapTableColumn("geneName","Human","Entrez Gene","Ensembl")
#Mapping Entrez Gene IDs to Ensembl IDs
})
#Importing networks from DisGeNET
metadata.add(paste("DisGeNET URL:",disgeneturl))
metadata.add(paste("DisGeNET net type:",net))
metadata.add("")
#Adding the DisGeNET URL and net type used to add networks to the metadata file
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$Pathwaytitle), 1, 0)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$PathwayTitle), 1, 0)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
write.table(wp_nodelist, file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=TAB', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$PathwayTitle), 1, 0)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
write.table(wp_nodelist, file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$NodeID <- wp_nodelist$Identifier
write.table(wp_nodelist, file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", df$Identifier)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
header(wp_nodelist)
head(wp_nodelist)
wp_nodelist
View(wp_nodelist)
#Defining a function to remove 'https://identifiers.org/xyz/' from every value in the df as to have the pure identifier
wp_nodelist <- apply(wp_nodelist,c(1,2), remove_identifierurl)
#Extracing and transposing the type of identifier to a new column
remove_identifierurl <- function(z) {
gsub("https://identifiers\\.org/([^/]+)/", "", x)
}
#Defining a function to remove 'https://identifiers.org/xyz/' from every value in the df as to have the pure identifier
wp_nodelist <- apply(wp_nodelist,c(1,2), remove_identifierurl)
#Extracing and transposing the type of identifier to a new column
remove_identifierurl <- function(z) {
gsub("https://identifiers\\.org/([^/]+)/", "", z)
}
#Defining a function to remove 'https://identifiers.org/xyz/' from every value in the df as to have the pure identifier
wp_nodelist <- apply(wp_nodelist,c(1,2), remove_identifierurl)
#Applying the function generates a matrix
wp_nodelist <- as.data.frame(wp_nodelist)
View(wp_nodelist)
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
View(wp_nodelist)
#Extracting and transposing the type of identifier to a new column
wp_nodelist <- mutate_all(wp_nodelist, funs(str_replace_all("https://identifiers\\.org/([^/]+)/", "")))
#Extracting and transposing the type of identifier to a new column
wp_nodelist <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
View(wp_nodelist)
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
#Extracting and transposing the type of identifier to a new column
wp_nodelist[] <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
View(wp_nodelist)
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$PathwayTitle), 1, 0)
View(wp_nodelist)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$NodeID <- wp_nodelist$Identifier
View(wp_nodelist)
#Generating a duplicate node identifier column since the original column will be lost during Cytoscape import due to it being selected as source column
write.table(wp_nodelist, file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
#Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways nodes")
commandsRun(sprintf('network import file columnTypeList="sa,s,t" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1', paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv")))
wp_edgelist <-  read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV of ource-target pairs from selected pathways from the ouput of a WikiPathways SPARQL query
wp_edgelist[] <- lapply(wp_edgelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
View(wp_edgelist)
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
write.table(wp_edgelist, file=paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
#Extracting and transposing the type of identifier to a new column
wp_nodelist[] <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$PathwayTitle), 1, 0)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$NodeID <- wp_nodelist$Identifier
#Generating a duplicate node identifier column since the original column will be lost during Cytoscape import due to it being selected as source column
write.table(wp_nodelist, file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
#Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
View(wp_nodelist)
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
View(wp_nodelist)
#Extracting and transposing the type of identifier to a new column
wp_nodelist[] <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
View(wp_nodelist)
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$PathwayTitle), 1, 0)
View(wp_nodelist)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$NodeID <- wp_nodelist$Identifier
View(wp_nodelist)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$NodeID <- wp_nodelist$Identifier
View(wp_nodelist)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
View(wp_nodelist)
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- ifelse(grepl("identifiers\\.org", wp_nodelist$Identifier),
gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier),
wp_nodelist$Identifier)
View(wp_nodelist)
#Extracting and transposing the type of identifier to a new column
#The function first checks whether "identifiers.org" is still in the "Identifier" column to avoid problems when re-running the code (identifiers.org is later removed)
wp_nodelist[] <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$PathwayTitle), 1, 0)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$NodeID <- wp_nodelist$Identifier
View(wp_nodelist)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- ifelse(grepl("identifiers\\.org", wp_nodelist$Identifier),
gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier),
wp_nodelist$Identifier)
View(wp_nodelist)
wp_nodelist <- read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- ifelse(grepl("identifiers\\.org", wp_nodelist$Identifier),
gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier),)
View(wp_nodelist)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- ifelse(grepl("identifiers\\.org", wp_nodelist$Identifier),
gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier),
wp_nodelist$NodeIDType)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- ifelse(grepl("identifiers\\.org", wp_nodelist$Identifier),
gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier),NULL)
View(wp_nodelist)
?if
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- if (grepl("identifiers\\.org", wp_nodelist$Identifier)) {
View(wp_nodelist)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
wp_nodelist$NodeIDType <- if (grepl("identifiers\\.org", wp_nodelist$Identifier)) {
gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)}
grepl("identifiers\\.org", wp_nodelist$Identifier)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
if (any(grepl("identifiers\\.org", wp_nodelist$Identifier))) {
# Extract text string using gsub and add to a new column 'NodeIDType'
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
} else {
# If 'identifiers.org' is not found, do nothing
}
View(wp_nodelist)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
if (any(grepl("identifiers\\.org", wp_nodelist$Identifier))) {
# Checking whether the 'Identifier' column contains the identifiers.org URL
#This is to avoid issues later when the identifiers.org part is removed and the code is reran
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
#If 'identifiers.org' is still in the column, extract part of the string into a new column to see what type the identifier is
} else {
# If 'identifiers.org' is not found, do nothing
}
View(wp_nodelist)
wp_nodelist[] <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
View(wp_nodelist)
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$PathwayTitle), 1, 0)
View(wp_nodelist)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$NodeID <- wp_nodelist$Identifier
View(wp_nodelist)
#Loading a TSV file resulting of a SPARQL query made to the WikiPathways endpoint
#The file contains all nodes associated with given pathway IDs relating to schizophrenia or CNVs
if (any(grepl("identifiers\\.org", wp_nodelist$Identifier))) {
# Checking whether the 'Identifier' column contains the identifiers.org URL
#This is to avoid issues later when the identifiers.org part is removed and the code is reran
wp_nodelist$NodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
#If 'identifiers.org' is still in the column, extract part of the string into a new column to see what type the identifier is
} else {
# If 'identifiers.org' is not found, do nothing
}
View(wp_nodelist)
wp_nodelist[] <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
View(wp_nodelist)
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV",wp_nodelist$PathwayTitle), 1, 0)
View(wp_nodelist)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$NodeID <- wp_nodelist$Identifier
View(wp_nodelist)
#Generating a duplicate node identifier column since the original column will be lost during Cytoscape import due to it being selected as source column
write.table(wp_nodelist, file=paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
#Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
#Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/CSVs/WikiPathways/nodelist.tsv")))
#Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways nodes")
wp_edgelist <-  read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV of ource-target pairs from selected pathways from the ouput of a WikiPathways SPARQL query
wp_edgelist[] <- lapply(wp_edgelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
write.table(wp_edgelist, file=paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
#Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,s,t" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1', paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv")))
#Importing a list of source-target pairs from selected pathways from the ouput of a WikiPathways SPARQL query
Sys.sleep(0.5)
#Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways edges")
wp_edgelist <-  read.delim(file=paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv"),header=TRUE,sep="\t",)
#Loading a TSV of ource-target pairs from selected pathways from the ouput of a WikiPathways SPARQL query
wp_edgelist[] <- lapply(wp_edgelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
write.table(wp_edgelist, file=paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
#Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,s,t" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1', paste0(getwd(),"/CSVs/WikiPathways/edgelist.tsv")))
altmergeNetworks(sources = c("WikiPathways nodes","WikiPathways edges"),
title = "WikiPathways networks",
operation = "union",
nodeKeys=c("name","name"))
altmergeNetworks(sources = c("WikiPathways nodes","WikiPathways edges"),
title = "WikiPathways networks",
operation = "union",
nodeKeys=c("NodeID","name"))
#Union merging the node and edge networks to extend the node list with corresponding edges
createNodeSource("fromWikiPathways")
