GO_Pvals = pval,
Nodes = nodes,
N_nodes = nnodes
)
}
go_vis <- do.call(rbind, lapply(seq_along(go_list_filtered),get_top_terms_filtered))
#Creating a new df containing the cluster and its corresponding GO terms, pvals, as well as the nodes and number of nodes making up the cluster
go_vis <- cbind(go_vis,sources_count)
#joining the cluster table and the table detailing the amount of sources per cluster
go_vis <- go_vis[,-6]
#Removing duplicate gLayCluster column
write.table(go_vis, file=paste0(getwd(),"/CSVs/GO-clusters-vis.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
#Writing the table to file for Cytoscape import
commandsRun(sprintf("network import file columnTypeList='s,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true delimiters=\\t rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(getwd(),"/CSVs/GO-clusters-vis.tsv")))
#Importing the previoulsy generated table 'go_vis_filered' back to Cytoscape as new network
#Essential to use .tsv and importing as such to avoid conflicts generated by .csv - commas separating terms in a string are interpreted as different columns by Cytoscape
renameNetwork("GO_Visualisation_SCZ_SNW")
View(sources_count)
View(go_vis)
#Writing the table to file for Cytoscape import
commandsRun(sprintf("network import file columnTypeList='s,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true delimiters=\\t rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(getwd(),"/CSVs/GO-clusters-vis.tsv")))
setwd("~/GitHub/SCZ-CNV")
#Setting working directory
rm(list=ls())
#Cleaning up workspace
packages <- c("dplyr","httr","stringr","gprofiler2")
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
if(!"rWikiPathways" %in% installed.packages()){
if (!requireNamespace("BiocManager", quietly=TRUE))
install.packages("BiocManager")
BiocManager::install("rWikiPathways")
}
if(!"RCy3" %in% installed.packages()){
if (!requireNamespace("BiocManager", quietly=TRUE))
install.packages("BiocManager")
BiocManager::install("RCy3")
}
#Checking if required packages are installed and installing if not
#Different structure for rWikiPathways and RCy3 packages as these are not installed directly but via the BiocManager package
invisible(lapply(c(packages,"rWikiPathways","RCy3"), require, character.only = TRUE))
#Loading libraries
sysdatetime <- Sys.time()
datetime <- format(sysdatetime, format = "%Y-%m-%d_%Hh%M")
dir.create("Outputs")
dir.create(sprintf("Outputs/Session-%s",datetime))
dir.create(sprintf("Outputs/Session-%s/Networks",datetime))
#Creating directories for outputs generated by this script to be saved in; new "Session" folder created each time the script is ran (contains generated networks, metadata, and sessionInfo)
nw_savepath <- sprintf("%1$s/Outputs/Session-%2$s/Networks/",getwd(),datetime)
file.create(sprintf("Outputs/Session-%s/metadata.txt",datetime))
#Creating a new metadata file with the current date and time as suffix for easier organisation
#Such a metadata file should be generated every time this script is ran to record parameters and versions of functions or databases, including the time avoids files being overwritten if the script is run multiple times a day (can even include seconds if script is ran multiple times per minute)
metadata.add <- function(info) {
write(sapply(info, as.character), sprintf("Outputs/Session-%s/metadata.txt",datetime),append=TRUE, sep = "\n")
}
metadata.add(sysdatetime)
metadata.add(Sys.timezone())
metadata.add("")
#Adding the timezone, date, and time to the metadata
invisible(file.create(sprintf("Outputs/Session-%s/sessioninfo-%s.txt",datetime,datetime)))
writeLines(capture.output(sessionInfo()),sprintf("Outputs/Session-%s/sessioninfo-%s.txt",datetime,datetime))
#Generating and adding a sessionInfo file to the current session output folder
cytoscapePing()
cytoscapeVersionInfo()
#Checking if Cytoscape is running and version info
metadata.add(capture.output(cytoscapeVersionInfo()))
checkinstall.app <- function(app) {
status_string <- getAppStatus(app)
#Getting install status of app
words <- strsplit(status_string, " ")[[1]]
last_word <- tail(words, 1)
#getAppStatus returns a character string instead of a logical value, so the last word (usually either "Installed" or "Uninstalled") from the output is checked
if (last_word == "Installed") {
print(sprintf("App %s is already installed.",app))
} else {
installApp(app)
print(sprintf("Installed app %s.",app))
}
}
#Function to check whether required Cytoscape apps are installed and installing them if not
applist <- c("Wikipathways", "DisGeNET-app", "CyTargetLinker","stringApp","BridgeDb","clusterMaker2")
#WikiPathways v.3.3.10
#DisGeNET-app v.7.3.0
#CyTargetLinker v. 4.1.0
#stringApp v. 2.0.1
#BridgeDb v.1.2.0
#clusterMaker2 v.2.3.4
lapply(applist,checkinstall.app)
#Checking and installing (if required) necessary Cytoscape apps
lapply(applist,getAppInformation)
metadata.add("Required Cytoscape apps and versions:")
invisible(metadata.add(print(lapply(applist,getAppInformation))))
metadata.add("")
# FUNCTION DICTIONARY-------------------------------------------------------------------------------------------------------------------
.defaultBaseUrl <- 'http://127.0.0.1:1234/v1'
#Defining the default base URL found in the RCy3 source as R object for altmergeNetworks
altmergeNetworks <- function(               sources = NULL,
title = NULL,
operation = "union",
nodeKeys = NULL,
nodeMergeMap = NULL,
nodesOnly = FALSE,
edgeKeys = NULL,
edgeMergeMap = NULL,
networkMergeMap = NULL,
inNetworkMerge = TRUE,
base.url = .defaultBaseUrl) {
cmd.string <- 'network merge' # a good start
# sources must be suppled
if(is.null(sources)) {
message("Missing sources!")
return(NULL)
} else {
sources.str <- paste(sources, collapse = ",")
cmd.string <- paste0(cmd.string,' sources="',sources.str,'"')
}
# defaults
cmd.string <- paste0(cmd.string,' operation=',operation)
cmd.string <- paste0(cmd.string,' nodesOnly=',nodesOnly)
cmd.string <- paste0(cmd.string,' inNetworkMerge=',inNetworkMerge)
# optional args
if(!is.null(title))
cmd.string <- paste0(cmd.string,' netName="',title,'"')
if(!is.null(nodeKeys))
cmd.string <- paste0(cmd.string,' nodeKeys="',paste(nodeKeys, collapse = ","),'"')
if(!is.null(edgeKeys))
cmd.string <- paste0(cmd.string,' edgeKeys="',paste(edgeKeys, collapse = ","),'"')
if(!is.null(nodeMergeMap)){
nodeMergeMap.str <- paste(nodeMergeMap, collapse = ",")
nodeMergeMap.str <- gsub("c\\(", "{", nodeMergeMap.str)
nodeMergeMap.str <- gsub("\\)", "}", nodeMergeMap.str)
cmd.string <- paste0(cmd.string,' nodeMergeMap="',nodeMergeMap.str,'"')
}
if(!is.null(edgeMergeMap)){
edgeMergeMap.str <- paste(edgeMergeMap, collapse = ",")
edgeMergeMap.str <- gsub("c\\(", "{", edgeMergeMap.str)
edgeMergeMap.str <- gsub("\\)", "}", edgeMergeMap.str)
cmd.string <- paste0(cmd.string,' edgeMergeMap="',edgeMergeMap.str,'"')
}
if(!is.null(networkMergeMap)){
networkMergeMap.str <- paste(networkMergeMap, collapse = ",")
networkMergeMap.str <- gsub("c\\(", "{", networkMergeMap.str)
networkMergeMap.str <- gsub("\\)", "}", networkMergeMap.str)
cmd.string <- paste0(cmd.string,' networkMergeMap="',networkMergeMap.str,'"')
}
res.data <- commandsPOST(cmd.string, base.url = base.url)
if(!is.null(res.data$SUID))
return(res.data$SUID)
else
return(res.data)
}
#Normally, RCy3's 'mergeNetworks' function would be used to unify imported networks into one supernetwork
#This function does however not work on the latest RCy3 release (v.2.22.1), but does work when running the script on RCy3 v.2.14.2
#RCy3 2.14.2 requires R v.4.1.3, requiring the entire script to run on an old version of R for one function that is used once
#Here, we redefine the function using the source code from RCy3 v.2.14.2 and simply use this alternate function to merge networks
queryspecies.wp <- c("Homo sapiens","Rattus norvegicus","Mus musculus")
getPathways.wp <- function(i) {
pw <- findPathwaysByText(i)
pw <- pw %>%
dplyr::filter(species %in% queryspecies.wp)
#Filtering by species
pw.ids <- paste0(i, "_wpids")
assign(pw.ids, as.character(pw$id),envir = .GlobalEnv)
#Extracting WP IDs
}
#Function to query WikiPathways using keyword and to extract WP IDs for the import function
createNodeSource <- function(source,doi=NULL) {
if (source == "WikiPathways") {
networkname <- getNetworkName()
nodetable <- paste0(networkname," default  node")
}
#Networks imported from WikiPathways have a type in the node table designations, as they have 2 spaces between "default" and "node" instead of one
#This check determines which node table name format is to be applied depending on the source (WikiPathways or other)
else {
networkname <- getNetworkName()
nodetable <- paste0(networkname," default node")
}
commandsRun(sprintf("table create column columnName=WikiPathways table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=DisGeNET table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=PharmGKB table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=Literature table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=Literature.doi table=%s type=string",nodetable))
#Creating a new column for each source used for all networks
commandsRun(sprintf("table set values columnName=%1$s handleEquations=false rowList=all table=%2$s value=1",source,nodetable))
#Filling the new column of the corresponding source with 1 to indicate which source the node is imported from
if (!is.null(doi)) {
commandsRun(sprintf("table set values columnName=Literature.doi handleEquations=false rowList=all table=%1$s value=%2$s",nodetable,doi))
#Adding doi for literature used if provided
}
}
#Function to create new column in node table specifying origin of network/node
import <- function(j) {
commandsRun(paste0('wikipathways import-as-network id=', j))
#Pasting WikiPathways IDs into a Cytoscape command line prompt to import as networks
createNodeSource("WikiPathways")
#Filling the 'WikiPathways' column with 1 to indicate the source
}
#Importing pathways from WikiPathways by pathway ID
disgenetRestUrl<-function(netType,host="127.0.0.1",port=1234,version="v7"){
if(is.null(netType)){
print("Network type not specified.")
}else{
disgeneturl<-sprintf("http://%s:%i/disgenet/%s/%s",host,port,version,netType)
}
return (disgeneturl)
}
net <- "gene-disease-net"
disgenetRestUrl(netType = net)
#Defining object for REST to call DisGeNET automation module; defining that we will be using gene-disease associations (GDA)
disgenetRestCall<-function(netType,netParams){
disgeneturl<-disgenetRestUrl(netType)
restCall<-POST(disgeneturl, body = netParams, encode = "json")
result<-content(restCall,"parsed")
return(result)
}
#Object that executes REST calls to DisGeNET module in Cytoscape
geneDisParams <- function(source,dis,min) {list(
source = source,
assocType = "Any",
diseaseClass = "Any",
diseaseSearch = dis,
geneSearch = " ",
initialScoreValue = min,
finalScoreValue = "1.0"
)}
#Specifying parameters of the GDA network to be imported
# SCHIZOPHRENIA =======================================================================================================================
## IMPORTING AND MERGING ---------------------------------------------------------------------------------------------------------------
genedisparams.scz.df <- read.table("CSVs/disgenetparams-scz.txt",header=TRUE,sep = "\t")
#Loading relevant gene-disease networks from DisGeNET
#Networks of interest manually added into tsv where it is easier to adjust filters
disgeneturl <- c()
#Preparing container for DisGeNET URL to be saved for addition to metadata file
apply(genedisparams.scz.df,1,function(row) {
gdp <- geneDisParams(row["source"],row["dis"],row["min"])
disgeneturl <<- disgenetRestUrl(net)
#Fetching the DisGeNET URL used to make this call
geneDisResult <- disgenetRestCall(net,gdp)
#Executing the DisGeNET query
createNodeSource("DisGeNET")
#Adding information about data source to each node
mapTableColumn("geneName","Human","HGNC","Ensembl")
#Mapping the HGNC gene name from the geneName column in the node table to Ensembl identifiers
mapTableColumn("geneName","Human","Entrez Gene","Ensembl")
#Mapping Entrez Gene IDs to Ensembl IDs
})
#Importing networks from DisGeNET
metadata.add(paste("DisGeNET URL:",disgeneturl))
metadata.add(paste("DisGeNET net type:",net))
metadata.add("")
#Adding the DisGeNET URL and net type used to add networks to the metadata file
wpids <- c("4875","5412","4222","4942","5408","5402","5346","5405","5406","5407","4940","4905","5398","5399","4906","4657","4932")
sczcnv <- sapply(wpids, function(k) paste0("WP",k))
#Manually adding relevant SCZ CNV pathways from WikiPathways
keyword.wp <- "Schizophrenia"
getPathways.wp(keyword.wp)
lapply(c(Schizophrenia_wpids,sczcnv), import)
#Importing WP pathways (both manually added and by keyword). Also adds "WikiPathways" as NodeSource column to node table
metadata.add(paste("WikiPathways keywords:",keyword.wp))
metadata.add(paste("WikiPathways manually by ID:",paste(wpids,collapse =", ")))
metadata.add(paste("WikiPathways queried species:",paste(queryspecies.wp,collapse = ", ")))
#Adding the keyword and species used to filter the WikiPathways query to the metadata file
metadata.add("")
Sys.sleep(2)
#Pausing the script for 2 seconds - when letting the script run without this, the literature source creation fails
commandsRun(sprintf("network import file columnTypeList='sa,sa,source,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(getwd(),"/CSVs/scz2022-Extended-Data-Table1.txt")))
#Importing network from file
#List of 120 genes implicated in Trubetskoy et al., doi: 10.1038/s41586-022-04434-5
commandsRun("table rename column columnName=Ensembl.ID newColumnName=Ensembl table=scz2022-Extended-Data-Table1.txt default node")
#Renaming the Ensembl.ID column from the dataset to Ensembl for coherence with networks from other sources
createNodeSource("Literature","10.1038/s41586-022-04434-5")
#Adding literature as  source to all imported nodes and adding the doi of the corresponding paper
renameNetwork("Trubetskoy risk genes")
#Renaming the newly imported network
metadata.add("Literature")
metadata.add("Trubetskoy et al. doi: 10.1038/s41586-022-04434-5")
metadata.add("")
networklist.dup <- getNetworkList()
dup.filter <- function(input,suffix) {
filtered_list <- input[substr(input, nchar(input) - 1,nchar(input))==suffix]
}
duplicates <- dup.filter(networklist.dup,"_1")
#Getting duplicate networks (Cytoscape marks duplicate networks with a "_1" suffix to the network name)
delete.dupes <- function(nw) {
setCurrentNetwork(nw)
deleteNetwork()
}
lapply(duplicates,delete.dupes)
#Selecting and deleting duplicate networks
networklist <- getNetworkList()
setCurrentNetwork(networklist[[1]])
for(i in 1:length(networklist)) {
current <- getNetworkName()
altmergeNetworks(c(current,networklist[[i]]), paste(current,networklist[[i]]),"union",inNetworkMerge = TRUE,nodeKeys=c("Ensembl","Ensembl"))
}
#Looping through the network list to merge all currently open networks with each other, creating one large unified network
renameNetwork("Schizophrenia supernetwork")
networklist <- getNetworkList()
snw_scz <- getNetworkName()
#Getting the name of the unified network to preserve it from deletion
lapply(networklist[networklist != snw_scz],deleteNetwork)
#Deleting all networks besides newly generated unified network
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW"),"CX", network = snw_scz, overwriteFile=TRUE)
#Exporting the supernetwork as cx file
## FILTERING NETWORK ------------------------------------------------------------------------------------------------------------------
createColumnFilter(filter.name="type.label",column="Type","Label","IS")
createColumnFilter(filter.name="type.anchor",column="Type","Anchor","IS")
createColumnFilter(filter.name="type.group",column="Type","Group","IS")
createColumnFilter(filter.name="disease.name",column="diseaseName","Schizophrenia","IS")
createCompositeFilter(filter.name="type.label.anchor.group",c("type.label","type.anchor","type.group","disease.name"),"ANY")
deleteSelectedNodes()
#Creating filters and deleting columns in the node table that are not relevant to the supernetwork (leftovers from import sources)
renameNetwork("SCZ_SNW_filtered")
snw_scz_filtered <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered"),"CX", network = snw_scz_filtered, overwriteFile=TRUE)
#Exporting the filtered supernetwork as cx file and tagging it with the time and date made to match with metadata file
## STRING --------------------------------------------------------------------------------------------------------------------------
commandsRun('string stringify colDisplayName=name column=Ensembl compoundQuery=true cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
commandsRun('string expand additionalNodes=1000 network=current nodeTypes="Homo sapiens" selectivityAlpha=0.9')
#STRINGifying and expanding the network with a 0.9 confidence cutoff (curated information)
mapTableColumn("stringdb::canonical name","Human","Uniprot-TrEMBL","Ensembl",force.single=TRUE)
#Mapping stringdb canonical names (Uniprot-TrEMBL identifiers) to Ensembl gene identifiers
#This step generates a second Ensembl column ('Ensembl (1)') with ENSG identifiers for the STRING-imported nodes
renameTableColumn("Ensembl (1)","Ensembldup")
#Renaming the duplicate Ensembl column for easier handling
renameNetwork("SCZ_SNW_filtered_STRING")
snw_scz_filtered_string <- getNetworkName()
stringified_nodetable <- paste0(nw_savepath,sprintf("%s node table.csv",snw_scz_filtered_string))
#Saving the file path to the node table for easier reading
commandsRun(sprintf('table export options=CSV outputFile=%1$s table="%2$s default  node"',stringified_nodetable,snw_scz_filtered_string))
#Exporting the node table as .csv file to the current session's "Network" folder
read_stringified_nodetable <- read.csv(stringified_nodetable)
#saving the node table as object
read_stringified_nodetable$Ensembl <- ifelse(read_stringified_nodetable$Ensembl == read_stringified_nodetable$Ensembldup, as.character(read_stringified_nodetable$Ensembl),
ifelse(is.na(read_stringified_nodetable$Ensembl) | read_stringified_nodetable$Ensembl =="",as.character(read_stringified_nodetable$Ensembldup),
ifelse(is.na(read_stringified_nodetable$Ensembldup) | read_stringified_nodetable$Ensembldup=="",as.character(read_stringified_nodetable$Ensembl),"No Match")))
#As the identifier mapping from STRING ENSP to ENSG identifiers generates a second Ensembl column, they are merged into the originial Ensembl column if the contents of the cell match or either is blank
read_stringified_nodetable = subset(read_stringified_nodetable,select= -Ensembldup)
#Removing the duplicate Ensembl column from the table
write.csv(read_stringified_nodetable, file=stringified_nodetable)
#Overwriting the previously exported table with the version containing the merged Ensembl column
renameTableColumn("@id","X.id")
#Renaming the '@id' column in the Cytoscape table to avoid issues when reimporting the .csv (@id is automatically converted to X.id in the CSV)
loadTableData(read_stringified_nodetable,data.key.column="X.id",table.key.column="X.id")
#Reimporting the .csv with the merged Ensembl column to the network as to have ENSG identifiers for almost all nodes
mapTableColumn("Ensembl","Human","Ensembl","HGNC")
#Generating a new column 'HGNC' from Ensembl identifiers - easier and less error-prone than merging various name columns from different import sources
renameTableColumn("HGNC","Name2")
#Renaming the new 'HGNC' column to 'Name2', which is now to be used as default name column. ('shared name' and 'name' columns are immutable and cannot be deleted or renamed)
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered_STRING"),"CX",network=snw_scz_filtered_string,overwriteFile=TRUE)
#Exporting the filtered, stringified supernetwork as cx file and tagging it with the time and data to match with the metadata file
## CLUSTERING ----------------------------------------------------------------------------------------------------------------------
createColumnFilter(filter.name="delete.noensembl", column="Ensembl","ENSG","DOES_NOT_CONTAIN")
deleteSelectedNodes()
#Filtering out nodes that do not have an ENSG Ensembl identifier mapped to them
marked_cols <- as.list(getTableColumnNames()[!(getTableColumnNames() %in% c("selected","name.copy" ,"SUID","shared name","name","Name2","DisGeNET","WikiPathways","Ensembl","Literature","Literature.doi"))])
lapply(marked_cols, function(column) {
deleteTableColumn(column=column)
})
#Deleting all the columns besides immutable columns, Ensembl, name, and source columns
metadata.add("GLay Clustering")
metadata.add(capture.output(commandsRun('cluster glay clusterAttribute=__glayCluster createGroups=false network=current restoreEdges=true showUI=true undirectedEdges=true')))
#Clustering the network using the GLay community cluster from the clusterMaker Cytoscape app and recording outcome to metadata
renameNetwork("SCZ_SNW_filtered_STRING_clustered")
renameTableColumn('__glayCluster','gLayCluster')
#Renaming the newly generated gLayCluster column as the original name with two underscores is not recognized during gene ontology
snw_scz_filtered_string_clustered <- getNetworkName()
clustered_nodetable <- paste0(nw_savepath,sprintf("/%s node table.csv",snw_scz_filtered_string_clustered))
#Saving the file path to the node table for easier reading (note the double space between node and table)
commandsRun(sprintf('table export options=CSV outputFile=%1$s table="%2$s default  node"',clustered_nodetable,snw_scz_filtered_string_clustered))
#Exporting the node table as .csv file to the current session's "Network" folder
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered_STRING_clustered"),"CX",network=snw_scz_filtered_string_clustered,overwriteFile=TRUE)
#Exporting the filtered, stringified, clustered supernetwork as cx file and tagging it with the time and data to match with the metadata file
read_clustered_nodetable <- read.csv(clustered_nodetable)
#Reading the exported csv
split_df <- split(read_clustered_nodetable$Ensembl,read_clustered_nodetable$gLayCluster)
#Splitting the node table by cluster
nodecount <- sapply(split_df, length)
#Counting how many nodes are in each cluster
countmatrix <- matrix(seq(1,length(nodecount)), ncol=1)
countmatrix <- cbind(countmatrix,as.numeric(nodecount))
#Construcing a matrix showing how many nodes are in each cluster
invalidclusters <- as.list(countmatrix[countmatrix[, 2] < 5, 1])
#Getting which clusters have fewer than 5 nodes associated with them
valid_clustered_nodetable <- read_clustered_nodetable[!read_clustered_nodetable$gLayCluster %in% invalidclusters, ]
#Generating a new df containing only nodes associated with clusters that had 5 or more nodes
split_tbl <- split(valid_clustered_nodetable, valid_clustered_nodetable$gLayCluster)
sourcecount <- function(cluster) {
wpcount <- sum(split_tbl[[cluster]][["WikiPathways"]] == 1, na.rm = TRUE)
dgcount <- sum(split_tbl[[cluster]][["DisGeNET"]] == 1, na.rm = TRUE)
litcount <- sum(split_tbl[[cluster]][["Literature"]] == 1, na.rm = TRUE)
wpdgcount <- sum(split_tbl[[cluster]][["WikiPathways"]] == 1 &
split_tbl[[cluster]][["DisGeNET"]] == 1,na.rm = TRUE)
wplitcount <- sum(split_tbl[[cluster]][["WikiPathways"]] == 1 &
split_tbl[[cluster]][["Literature"]] == 1, na.rm = TRUE)
dglitcount <- sum(split_tbl[[cluster]][["DisGeNET"]] == 1 &
split_tbl[[cluster]][["Literature"]] == 1, na.rm = TRUE)
wpdglitcount <- sum(split_tbl[[cluster]][["DisGeNET"]] == 1 &
split_tbl[[cluster]][["Literature"]] == 1 &
split_tbl[[cluster]][["WikiPathways"]] == 1, na.rm = TRUE)
result_df <- data.frame(
gLayCluster = split_tbl[[cluster]][["gLayCluster"]][1],
WikiPathways_source = wpcount,
DisGeNET_source = dgcount,
Literature_source = litcount,
WikiPathways_AND_DisGeNET_source = wpdgcount,
WikiPathways_AND_Literature_source = wplitcount,
DisGeNET_AND_Literature_source = dglitcount,
DisGeNET_AND_Literature_AND_WikiPathways_source = wpdglitcount
)
}
sources_count <- do.call(rbind, lapply(seq_along(split_tbl),sourcecount))
#For each cluster, counting how many nodes are associated with which sources
## GO ANALYSIS ------------------------------------------------------------------------------------------------------------------------
valid_clustered_nodetable %>% select(c('gLayCluster','Ensembl'))
#Selecting relevant columns
split_df <- split(valid_clustered_nodetable$Ensembl,valid_clustered_nodetable$gLayCluster)
split_list <- lapply(split_df, as.vector)
#Splitting the node table by cluster number, i.e. lists of Ensembl IDs are created per cluster
go <- function(cluster) {
gost(
query = cluster,
organism = "hsapiens",
ordered_query = FALSE,
multi_query = TRUE,
significant = TRUE,
exclude_iea = FALSE,
measure_underrepresentation = FALSE,
evcodes = FALSE,
user_threshold = 0.05,
correction_method = "g_SCS",
domain_scope ="annotated",
custom_bg = NULL,
numeric_ns = "",
sources = NULL,
as_short_link = FALSE,
highlight = TRUE
)
}
go_list <- lapply(split_list,go)
#Iterating the gost GO function over all clusters
saveRDS(go_list, file=paste0(nw_savepath,"/go_list.rds"))
#Saving the entire generated GO analysis as R object locally
get_top_terms <- function(cluster) {
terms <- toString(go_list[[cluster]][["result"]][["term_name"]][1:5])
#Extracting the top 5 term names associated with each cluster
pval <- toString(go_list[[cluster]][["result"]][["p_values"]][1:5])
#Extracting the p-values for the corresponding top 5 term names
result_df <- data.frame(
gLayCluster = cluster,
GO_Terms = terms,
GO_Pvals = pval
)
}
topterms_df <- do.call(rbind, lapply(seq_along(go_list),get_top_terms))
#Getting top 5 term names and corresponding p-values for each cluster and storing in topterms_df
loadTableData(topterms_df,data.key.column="gLayCluster",table.key.column="gLayCluster")
#Loading the generated top terms and p-values back to the supernetwork; every gene belonging to cluster x is now associated with the top terms of cluster x
renameNetwork(title=paste0(getNetworkName(),"-GO"))
snw_scz_filtered_string_clustered_go <- getNetworkName()
#Renaming and saving the network name to indicate addition of GO information
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_filtered_STRING_clustered_GO"),"CX",network=snw_scz_filtered_string_clustered_go,overwriteFile=TRUE)
#Exporting the filtered, stringified, clustered supernetwork after GO as cx file and tagging it with the time and data to match with the metadata file
##VISUALISATION -----------------------------------------------------------------------------------------------------------------------
go_list_filtered <- go_list[sapply(go_list, function(x) !is.null(x))]
#Removing all clusters from the list for which no GO analysis could be done
get_top_terms_filtered <- function(cluster) {
topterms <- paste(go_list_filtered[[cluster]][["result"]][["term_name"]][1:5],collapse=",")
#Extracting the top 5 term names associated with each cluster
pval <- paste(go_list_filtered[[cluster]][["result"]][["p_values"]][1:5],collapse=",")
#Extracting the p-values for the corresponding top 5 term names
nodes <- paste(go_list_filtered[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]],collapse=",")
#Extracing the number of nodes/genes contained in each cluster
nnodes <- str_count(toString(go_list_filtered[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]]),"\\S+")
result_df_filtered <- data.frame(
gLayCluster = names(go_list_filtered)[cluster],
GO_Terms = topterms,
GO_Pvals = pval,
Nodes = nodes,
N_nodes = nnodes
)
}
go_vis <- do.call(rbind, lapply(seq_along(go_list_filtered),get_top_terms_filtered))
#Creating a new df containing the cluster and its corresponding GO terms, pvals, as well as the nodes and number of nodes making up the cluster
go_vis <- cbind(go_vis,sources_count)
#joining the cluster table and the table detailing the amount of sources per cluster
go_vis <- go_vis[,-6]
#Removing duplicate gLayCluster column
write.table(go_vis, file=paste0(getwd(),"/CSVs/GO-clusters-vis.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
#Writing the table to file for Cytoscape import
commandsRun(sprintf("network import file columnTypeList='s,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true delimiters=\\t rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(getwd(),"/CSVs/GO-clusters-vis.tsv")))
#Importing the previoulsy generated table 'go_vis_filered' back to Cytoscape as new network
#Essential to use .tsv and importing as such to avoid conflicts generated by .csv - commas separating terms in a string are interpreted as different columns by Cytoscape
renameNetwork("GO_Visualisation_SCZ_SNW")
?RCy3
setNodeSizeMapping(
table.column = "N_nodes",
sizes = c(50,200),
mapping.type = "c",
default.size = 100,
style.name = "GO_Vis")
?createVisualStyle
setNodeSizeMapping(
table.column = "N_nodes",
sizes = c(50,200),
mapping.type = "c",
default.size = 100)
setVisualStyle(style.name = "GO_Vis")
go_vis_nw <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"GO_Visualisation_SCZ_SNW"),"CX",network=go_vis,overwriteFile=TRUE)
