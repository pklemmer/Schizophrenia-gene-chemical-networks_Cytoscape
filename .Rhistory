datetime <- format(sysdatetime, format = "%Y-%m-%d_%Hh%M")
dir.create("Outputs")
dir.create(sprintf("Outputs/Session-%s",datetime))
dir.create(sprintf("Outputs/Session-%s/Networks",datetime))
#Creating directories for outputs generated by this script to be saved in; new "Session" folder created each time the script is ran (contains generated networks, metadata, and sessionInfo)
nw_savepath <- sprintf("%1$s/Outputs/Session-%2$s/Networks/",getwd(),datetime)
file.create(sprintf("Outputs/Session-%s/metadata.txt",datetime))
#Creating a new metadata file with the current date and time as suffix for easier organisation
#Such a metadata file should be generated every time this script is ran to record parameters and versions of functions or databases, including the time avoids files being overwritten if the script is run multiple times a day (can even include seconds if script is ran multiple times per minute)
metadata.add <- function(info) {
write(sapply(info, as.character), sprintf("Outputs/Session-%s/metadata.txt",datetime),append=TRUE, sep = "\n")
}
metadata.add(sysdatetime)
metadata.add(Sys.timezone())
metadata.add("")
#Adding the timezone, date, and time to the metadata
invisible(file.create(sprintf("Outputs/Session-%s/sessioninfo-%s.txt",datetime,datetime)))
writeLines(capture.output(sessionInfo()),sprintf("Outputs/Session-%s/sessioninfo-%s.txt",datetime,datetime))
#Generating and adding a sessionInfo file to the current session output folder
cytoscapePing()
cytoscapeVersionInfo()
#Checking if Cytoscape is running and version info
metadata.add(capture.output(cytoscapeVersionInfo()))
checkinstall.app <- function(app) {
status_string <- getAppStatus(app)
#Getting install status of app
words <- strsplit(status_string, " ")[[1]]
last_word <- tail(words, 1)
#getAppStatus returns a character string instead of a logical value, so the last word (usually either "Installed" or "Uninstalled") from the output is checked
if (last_word == "Installed") {
print(sprintf("App %s is already installed.",app))
} else {
installApp(app)
print(sprintf("Installed app %s.",app))
}
}
#Function to check whether required Cytoscape apps are installed and installing them if not
applist <- c("Wikipathways", "DisGeNET-app", "CyTargetLinker","stringApp","BridgeDb","clusterMaker2")
#WikiPathways v.3.3.10
#DisGeNET-app v.7.3.0
#CyTargetLinker v. 4.1.0
#stringApp v. 2.0.2
#BridgeDb v.1.2.0
#clusterMaker2 v.2.3.4
lapply(applist,checkinstall.app)
#Checking and installing (if required) necessary Cytoscape apps
lapply(applist,getAppInformation)
metadata.add("Required Cytoscape apps and versions:")
invisible(metadata.add(print(lapply(applist,getAppInformation))))
metadata.add("")
# FUNCTION DICTIONARY-------------------------------------------------------------------------------------------------------------------
.defaultBaseUrl <- 'http://127.0.0.1:1234/v1'
#Defining the default base URL found in the RCy3 source as R object for altmergeNetworks
altmergeNetworks <- function(               sources = NULL,
title = NULL,
operation = "union",
nodeKeys = NULL,
nodeMergeMap = NULL,
nodesOnly = FALSE,
edgeKeys = NULL,
edgeMergeMap = NULL,
networkMergeMap = NULL,
inNetworkMerge = TRUE,
base.url = .defaultBaseUrl) {
cmd.string <- 'network merge' # a good start
# sources must be suppled
if(is.null(sources)) {
message("Missing sources!")
return(NULL)
} else {
sources.str <- paste(sources, collapse = ",")
cmd.string <- paste0(cmd.string,' sources="',sources.str,'"')
}
# defaults
cmd.string <- paste0(cmd.string,' operation=',operation)
cmd.string <- paste0(cmd.string,' nodesOnly=',nodesOnly)
cmd.string <- paste0(cmd.string,' inNetworkMerge=',inNetworkMerge)
# optional args
if(!is.null(title))
cmd.string <- paste0(cmd.string,' netName="',title,'"')
if(!is.null(nodeKeys))
cmd.string <- paste0(cmd.string,' nodeKeys="',paste(nodeKeys, collapse = ","),'"')
if(!is.null(edgeKeys))
cmd.string <- paste0(cmd.string,' edgeKeys="',paste(edgeKeys, collapse = ","),'"')
if(!is.null(nodeMergeMap)){
nodeMergeMap.str <- paste(nodeMergeMap, collapse = ",")
nodeMergeMap.str <- gsub("c\\(", "{", nodeMergeMap.str)
nodeMergeMap.str <- gsub("\\)", "}", nodeMergeMap.str)
cmd.string <- paste0(cmd.string,' nodeMergeMap="',nodeMergeMap.str,'"')
}
if(!is.null(edgeMergeMap)){
edgeMergeMap.str <- paste(edgeMergeMap, collapse = ",")
edgeMergeMap.str <- gsub("c\\(", "{", edgeMergeMap.str)
edgeMergeMap.str <- gsub("\\)", "}", edgeMergeMap.str)
cmd.string <- paste0(cmd.string,' edgeMergeMap="',edgeMergeMap.str,'"')
}
if(!is.null(networkMergeMap)){
networkMergeMap.str <- paste(networkMergeMap, collapse = ",")
networkMergeMap.str <- gsub("c\\(", "{", networkMergeMap.str)
networkMergeMap.str <- gsub("\\)", "}", networkMergeMap.str)
cmd.string <- paste0(cmd.string,' networkMergeMap="',networkMergeMap.str,'"')
}
res.data <- commandsPOST(cmd.string, base.url = base.url)
if(!is.null(res.data$SUID))
return(res.data$SUID)
else
return(res.data)
}
#Normally, RCy3's 'mergeNetworks' function would be used to unify imported networks into one supernetwork
#This function does however not work on the latest RCy3 release (v.2.22.1), but does work when running the script on RCy3 v.2.14.2
#RCy3 2.14.2 requires R v.4.1.3, requiring the entire script to run on an old version of R for one function that is used once
#Here, we redefine the function using the source code from RCy3 v.2.14.2 and simply use this alternate function to merge networks
queryspecies.wp <- c("Homo sapiens","Rattus norvegicus","Mus musculus")
getPathways.wp <- function(i) {
pw <- findPathwaysByText(i)
pw <- pw %>%
dplyr::filter(species %in% queryspecies.wp)
#Filtering by species
pw.ids <- paste0(i, "_wpids")
assign(pw.ids, as.character(pw$id),envir = .GlobalEnv)
#Extracting WP IDs
}
#Function to query WikiPathways using keyword and to extract WP IDs for the import function
createNodeSource <- function(source,doi=NULL) {
if (source == "WikiPathways") {
networkname <- getNetworkName()
nodetable <- paste0(networkname," default  node")
}
#Networks imported from WikiPathways have a type in the node table designations, as they have 2 spaces between "default" and "node" instead of one
#This check determines which node table name format is to be applied depending on the source (WikiPathways or other)
else {
networkname <- getNetworkName()
nodetable <- paste0(networkname," default node")
}
commandsRun(sprintf("table create column columnName=WikiPathways table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=DisGeNET table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=Publication table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=Publication.doi table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=STRINGnode table=%s type=string",nodetable))
#Creating a new column for each source used for all networks
if ( source == "STRINGnode") {
commandsRun(sprintf('table set values columnName=%1$s handleEquations=false rowList="selected:true" table=%2$s value=1',source,nodetable))
}
else {
commandsRun(sprintf("table set values columnName=%1$s handleEquations=false rowList=all table=%2$s value=1",source,nodetable))
#Filling the new column of the corresponding source with 1 to indicate which source the node is imported from
}
if (!is.null(doi)) {
commandsRun(sprintf("table set values columnName=Publication.doi handleEquations=false rowList=all table=%1$s value=%2$s",nodetable,doi))
#Adding doi for literature used if provided
}
}
#Function to create new column in node table specifying origin of network/node
import <- function(j) {
commandsRun(paste0('wikipathways import-as-network id=', j))
#Pasting WikiPathways IDs into a Cytoscape command line prompt to import as networks
createNodeSource("WikiPathways")
#Filling the 'WikiPathways' column with 1 to indicate the source
}
#Importing pathways from WikiPathways by pathway ID
disgenetRestUrl<-function(netType,host="127.0.0.1",port=1234,version="v7"){
if(is.null(netType)){
print("Network type not specified.")
}else{
disgeneturl<-sprintf("http://%s:%i/disgenet/%s/%s",host,port,version,netType)
}
return (disgeneturl)
}
net <- "gene-disease-net"
disgenetRestUrl(netType = net)
#Defining object for REST to call DisGeNET automation module; defining that we will be using gene-disease associations (GDA)
disgenetRestCall<-function(netType,netParams){
disgeneturl<-disgenetRestUrl(netType)
restCall<-POST(disgeneturl, body = netParams, encode = "json")
result<-content(restCall,"parsed")
return(result)
}
#Object that executes REST calls to DisGeNET module in Cytoscape
geneDisParams <- function(source,dis,min) {list(
source = source,
assocType = "Any",
diseaseClass = "Any",
diseaseSearch = dis,
geneSearch = " ",
initialScoreValue = min,
finalScoreValue = "1.0"
)}
#Specifying parameters of the GDA network to be imported
createColumnFilter(
filter.name = "has_GO_result",
column = "N_nodes",
criterion = 0,
predicate = "GREATER_THAN",
anyMatch = TRUE,
apply = TRUE
)
#Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
#Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way
#The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
KERList <-  read.table(file=paste0(getwd(),"/CSVs/AOP/KERList.tsv"),header=TRUE, sep ="\t")
#Reading a tsv obtained from AOPwiki through a SPARQL query
#The tsv contains key-event relationships from AOPs containing AOs relating to manually selected neural/psychological outcomes
#The exported tsv from the AOPwiki SPARQL endpoint has quotation marks around each element, hindering mapping
#The quotation marks are removed using a text editor (Notepad++ here)
KEEnsembl <- read.table(file=paste0(getwd(),"/CSVs/AOP/KEEnsembl.tsv"),header=TRUE, sep ="\t")
#Reading a tsv from AOPWiki SPARQL endpoint containing all KEs and the ENSG IDs they are associated with
#For easier merging of ENSG IDs to the manually selected KEs contained in KERList, this file needs to be filtered
allKEsFromList <- data.frame(allKEs = c(KERList$KEup,KERList$KEdown))
#Combining both up- and downregulated KEs into a single column
filtered_KEEnsembl <- subset(KEEnsembl, ke %in% allKEsFromList$allKEs)
#Removing KE-Ensembl rows that are not found in the selected KEs
write.table(filtered_KEEnsembl, file=paste0(getwd(),"/CSVs/AOP/KEEnsembl_filtered.tsv"), quote=FALSE,row.names=FALSE,sep="\t" )
#Writing the filtered KE-ENSG list to file for Cytoscape loading
commandsRun(sprintf('network import file columnTypeList="ea,s,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList=-- Create new network collection --',paste0(getwd(),"/CSVs/AOP/KERList.tsv")))
#Loading selected KERs into Cytoscape as new network
commandsRun(sprintf('table import file dataTypeTargetForNetworkCollection="Node Table Columns" delimiters=\\t file=%s firstRowAsColumnNames=true keyColumnForMapping="shared name" keyColumnIndex=1 startLoadRow=1',paste0(getwd(),"/CSVs/AOP/KEMap.tsv")))
#Loading a KE mapping file generated from a second SPARQL query that fetches all KE URIs and their titles from AOPwiki into the KER network
#This file also had quotation marks removed using a text editor
commandsRun(sprintf('network import file columnTypeList="s,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList=-- Create new network collection --',paste0(getwd(),"/CSVs/AOP/KEEnsembl_filtered.tsv")))
#Loading the filtered KE-ENSG list as new network into Cytoscape
altmergeNetworks(sources = c('KERList.tsv','KEEnsembl_filtered.tsv'),
title='KERs',
operation='union'
)
#Merging the manually curated KERList network and the KE-ENSG list to extend the selected KEs with associated genes
deleteNetwork(network='KERList.tsv')
deleteNetwork(network='KEEnsembl_filtered.tsv')
#Deleting networks used to make merged network
mapTableColumn(
column = 'name',
species= 'Human',
map.from = 'Ensembl',
map.to = 'HGNC',
force.single = 'true'
)
renameTableColumn('HGNC','Name2')
commandsRun(sprintf('table export options=CSV outputFile=%s table="KERs default node"', paste0(getwd(),"/CSVs/AOP/KE_table.csv")))
#Exporting the node table for manipulation via R
KE_table <- read.csv(paste0(getwd(),"/CSVs/AOP/KE_table.csv"))
#Loading the previously exported node table as R object
KE_table <- KE_table %>%
mutate(Ensembl=ifelse(grepl("ENSG",name),name,NA))
#Getting and transposing ENSG IDs from the name col to a new 'Ensembl' col to be used as key
KE_table <- KE_table %>%
mutate(KE_URI=ifelse(!grepl("ENSG",name),name,NA))
#Getting and transposing KE URIs (all rows not containing 'ENSG') from the name col to a new 'KE_URI' col
#These two steps are done as the 'name' and 'shared name' columns will be difficult to work with since they mix both ENSG and other data types
KE_table <- KE_table %>%
mutate(AOPwiki=1)
#Adding a new column to the node table indicating that the gene nodes in the KE network are imported from AOPwiki
KE_table <- KE_table %>%
select(-shared.name)
#Loading the node table in R changes the name the 'shared name' column to 'shared.name' to avoid a space, this results in a duplicate 'shared.name' column when importing the table back to Cytoscape
#For this reason, 'shared.name'/'shared name' is simply removed from the df as 'names' can also be used for mapping and contains the same information anyways
write.csv(KE_table, file=paste0(getwd(),"/CSVs/AOP/KE_table.csv"), row.names=FALSE)
#Overwriting the previously exported node table with the updated version
loadTableData(
data = read.table(file=paste0(getwd(),"/CSVs/AOP/KE_table.csv"),header=TRUE, sep =","),
data.key.column = "name",
table.key.column = "name"
)
#Loading the updated node table back to the network
altmergeNetworks(sources = c('SCZ_SNW_filtered_STRING_clustered_GO','KERs'),
title='SCZ_SNW_filtered_STRING_clustered_GO_KER',
operation='union',
nodeKeys = c('Ensembl','Ensembl')
)
#Merging the KER network with the supernetwork based on Ensembl ID
#As this is an union merge, all nodes from the KER network are introduced to the SNW, but the goal was simply to annotate existing genes in the SNW with KEs
#Therefore, some filtering is needed
commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_filtered_STRING_clustered_GO_KER default node"', paste0(getwd(),"/CSVs/AOP/SNW_KER_node.csv")))
SNW_KER_node <- read.csv(paste0(getwd(),"/CSVs/AOP/SNW_KER_node.csv"))
#Saving the SNW node table to file and loading it as R object
KE_only_nodes <- SNW_KER_node %>%
filter(AOPwiki == 1 & is.na(DisGeNET) & is.na(WikiPathways) & is.na(Publication) & is.na(STRINGnode)) %>%
pull(Ensembl)
#Getting a list of nodes that only have AOPwiki as source
#This implies that these nodes were not already present in the network since they would've been merged to existing nodes that already had at least one source prior
#It is not desired to add new gene nodes to the network from the KER network; gene nodes serve only as references for connecting KEs to already existing genes in the supernetwork
selectNodes(nodes=KE_only_nodes,
by.col="Ensembl")
deleteSelectedNodes()
#Selecting and deleting nodes based on the prior criteria
commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_filtered_STRING_clustered_GO_KER default edge"', paste0(getwd(),"/CSVs/AOP/SNW_KER_edge.csv")))
SNW_KER_edge <- read.csv(paste0(getwd(),"/CSVs/AOP/SNW_KER_edge.csv"))
#Exporting the SNW edge table to file and loading it as R object
valid_KE_ensg <- SNW_KER_edge[grepl("ENSG", SNW_KER_edge$name) & grepl("aop.events", SNW_KER_edge$name),]
#Getting a list of KEs that do have interactions with genes
valid_KE <- str_extract(valid_KE_ensg$name, "https://identifiers.org/aop.events/\\S+")
valid_KE <- unique(valid_KE)
#Getting the URIs of the KEs that have interactions with genes
bad_KE_df <- SNW_KER_edge %>%
filter(
grepl("aop\\.events", name, ignore.case=TRUE) &
!grepl(paste(valid_KE, collapse="|"), name)
)
#Getting a list of the remaining KEs that are not associated with a gene or with a KE that is associated with a gene (to preserve KERs)
bad_KE_list <- str_extract_all(bad_KE_df$name, "https://identifiers\\.org/aop\\.events/\\d+")
bad_KE <- unique(unlist(bad_KE_list))
#Getting a list of unique bad KEs
selectNodes(nodes=bad_KE, by.col="name")
deleteSelectedNodes()
commandsRun(sprintf('network import file columnTypeList="s,ta,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
commandsRun(sprintf('network import file columnTypeList="s,ta,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
deleteDuplicateEdges()
commandsRun(sprintf('network import file columnTypeList="s,ta,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
deleteDuplicateEdges()
?deleteDuplicateEdges
commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
deleteDuplicateEdges()
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
deleteDuplicateEdges()
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
deleteDuplicateEdges()
commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
View(deleteDuplicateEdges())
commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#Removing duplicate edges from current network
#RCy3 has a deleteDuplicateEdges function but it seems bugged since it always just removes 1 duplicate edge at a time
#Using the command line function removes all duplicate edges right away and avoids having to run a filter to select duplicate edges which is much slower
#Removing duplicate edges from current network
#RCy3 has a deleteDuplicateEdges function but it seems bugged since it always just removes 1 duplicate edge at a time
#Using the command line function removes all duplicate edges right away and avoids having to run a filter to select duplicate edges which is much slower
commandsRun(sprintf('network import file columnTypeList="x,sa,s,ta,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t',paste0(getwd(), "/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#Removing duplicate edges from current network
#RCy3 has a deleteDuplicateEdges function but it seems bugged since it always just removes 1 duplicate edge at a time
#Using the command line function removes all duplicate edges right away and avoids having to run a filter to select duplicate edges which is much slower
renameNetwork("KE-AOP")
#Removing duplicate edges from current network
renameNetwork("AOP-AO")
altmergeNetworks(sources=c("KE-AOP","AOP-AO"),
title='KE-AOP-AO',
operation='union',
nodeKeys=c('name','name'))
#Merging the AO and AOP networks
#Necessary to first import as separate networks and then merge as only one source and target col can be selected during network import
altmergeNetworks(sources=c('KE-AOP-AO','SCZ_SNW_filtered_STRING_clustered_GO_KER'),
title-'SCZ_SNW_filtered_STRING_clustered_GO_AOP',
operation='union',
nodeKeys=c('name','name'))
#Merging the AO and AOP networks
#Necessary to first import as separate networks and then merge as only one source and target col can be selected during network import
altmergeNetworks(sources=c('KE-AOP-AO','SCZ_SNW_filtered_STRING_clustered_GO_KER'),
title='SCZ_SNW_filtered_STRING_clustered_GO_AOP',
operation='union',
nodeKeys=c('name','name'))
#Merging the AOP-AO network to the SNW-KE network to extend KEs connected to risk genes with corresponding AOPs/AOs
deleteNetwork(network='KE-AOP-AO')
deleteNetwork(network='KERs')
deleteNetwork(network='SCZ_SNW_filtered_STRING_clustered_GO_KER')
deleteNetwork(network='KE-AOP')
deleteNetwork(network='AOP-AO')
#Deleting networks that are no longer needed, used to generate SNW-AOP network
SNW_AOP <- getNetworkName()
#Deleting networks that are no longer needed, used to generate SNW-AOP network
SNW_AOP <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,SNW_AOP),"CX",network=SNW_AOP)
createColumnFilter(
filter.name = "has_GO_result",
column = "N_nodes",
criterion = 0,
predicate = "GREATER_THAN",
anyMatch = TRUE,
apply = TRUE
)
#Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
#Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way
#The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
KERList <-  read.table(file=paste0(getwd(),"/CSVs/AOP/KERList.tsv"),header=TRUE, sep ="\t")
#Reading a tsv obtained from AOPwiki through a SPARQL query
#The tsv contains key-event relationships from AOPs containing AOs relating to manually selected neural/psychological outcomes
#The exported tsv from the AOPwiki SPARQL endpoint has quotation marks around each element, hindering mapping
#The quotation marks are removed using a text editor (Notepad++ here)
KEEnsembl <- read.table(file=paste0(getwd(),"/CSVs/AOP/KEEnsembl.tsv"),header=TRUE, sep ="\t")
#Reading a tsv from AOPWiki SPARQL endpoint containing all KEs and the ENSG IDs they are associated with
#For easier merging of ENSG IDs to the manually selected KEs contained in KERList, this file needs to be filtered
allKEsFromList <- data.frame(allKEs = c(KERList$KEup,KERList$KEdown))
#Combining both up- and downregulated KEs into a single column
filtered_KEEnsembl <- subset(KEEnsembl, ke %in% allKEsFromList$allKEs)
#Removing KE-Ensembl rows that are not found in the selected KEs
write.table(filtered_KEEnsembl, file=paste0(getwd(),"/CSVs/AOP/KEEnsembl_filtered.tsv"), quote=FALSE,row.names=FALSE,sep="\t" )
#Writing the filtered KE-ENSG list to file for Cytoscape loading
commandsRun(sprintf('network import file columnTypeList="ea,s,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList=-- Create new network collection --',paste0(getwd(),"/CSVs/AOP/KERList.tsv")))
#Loading selected KERs into Cytoscape as new network
commandsRun(sprintf('table import file dataTypeTargetForNetworkCollection="Node Table Columns" delimiters=\\t file=%s firstRowAsColumnNames=true keyColumnForMapping="shared name" keyColumnIndex=1 startLoadRow=1',paste0(getwd(),"/CSVs/AOP/KEMap.tsv")))
#Loading a KE mapping file generated from a second SPARQL query that fetches all KE URIs and their titles from AOPwiki into the KER network
#This file also had quotation marks removed using a text editor
commandsRun(sprintf('network import file columnTypeList="s,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList=-- Create new network collection --',paste0(getwd(),"/CSVs/AOP/KEEnsembl_filtered.tsv")))
#Loading the filtered KE-ENSG list as new network into Cytoscape
altmergeNetworks(sources = c('KERList.tsv','KEEnsembl_filtered.tsv'),
title='KERs',
operation='union'
)
#Merging the manually curated KERList network and the KE-ENSG list to extend the selected KEs with associated genes
deleteNetwork(network='KERList.tsv')
deleteNetwork(network='KEEnsembl_filtered.tsv')
#Deleting networks used to make merged network
mapTableColumn(
column = 'name',
species= 'Human',
map.from = 'Ensembl',
map.to = 'HGNC',
force.single = 'true'
)
renameTableColumn('HGNC','Name2')
commandsRun(sprintf('table export options=CSV outputFile=%s table="KERs default node"', paste0(getwd(),"/CSVs/AOP/KE_table.csv")))
#Exporting the node table for manipulation via R
KE_table <- read.csv(paste0(getwd(),"/CSVs/AOP/KE_table.csv"))
#Loading the previously exported node table as R object
KE_table <- KE_table %>%
mutate(Ensembl=ifelse(grepl("ENSG",name),name,NA))
#Getting and transposing ENSG IDs from the name col to a new 'Ensembl' col to be used as key
KE_table <- KE_table %>%
mutate(KE_URI=ifelse(!grepl("ENSG",name),name,NA))
#Getting and transposing KE URIs (all rows not containing 'ENSG') from the name col to a new 'KE_URI' col
#These two steps are done as the 'name' and 'shared name' columns will be difficult to work with since they mix both ENSG and other data types
KE_table <- KE_table %>%
mutate(AOPwiki=1)
#Adding a new column to the node table indicating that the gene nodes in the KE network are imported from AOPwiki
KE_table <- KE_table %>%
select(-shared.name)
#Loading the node table in R changes the name the 'shared name' column to 'shared.name' to avoid a space, this results in a duplicate 'shared.name' column when importing the table back to Cytoscape
#For this reason, 'shared.name'/'shared name' is simply removed from the df as 'names' can also be used for mapping and contains the same information anyways
write.csv(KE_table, file=paste0(getwd(),"/CSVs/AOP/KE_table.csv"), row.names=FALSE)
#Overwriting the previously exported node table with the updated version
loadTableData(
data = read.table(file=paste0(getwd(),"/CSVs/AOP/KE_table.csv"),header=TRUE, sep =","),
data.key.column = "name",
table.key.column = "name"
)
#Loading the updated node table back to the network
altmergeNetworks(sources = c('SCZ_SNW_filtered_STRING_clustered_GO','KERs'),
title='SCZ_SNW_filtered_STRING_clustered_GO_KER',
operation='union',
nodeKeys = c('Ensembl','Ensembl')
)
#Merging the KER network with the supernetwork based on Ensembl ID
#As this is an union merge, all nodes from the KER network are introduced to the SNW, but the goal was simply to annotate existing genes in the SNW with KEs
#Therefore, some filtering is needed
commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_filtered_STRING_clustered_GO_KER default node"', paste0(getwd(),"/CSVs/AOP/SNW_KER_node.csv")))
SNW_KER_node <- read.csv(paste0(getwd(),"/CSVs/AOP/SNW_KER_node.csv"))
#Saving the SNW node table to file and loading it as R object
KE_only_nodes <- SNW_KER_node %>%
filter(AOPwiki == 1 & is.na(DisGeNET) & is.na(WikiPathways) & is.na(Publication) & is.na(STRINGnode)) %>%
pull(Ensembl)
#Getting a list of nodes that only have AOPwiki as source
#This implies that these nodes were not already present in the network since they would've been merged to existing nodes that already had at least one source prior
#It is not desired to add new gene nodes to the network from the KER network; gene nodes serve only as references for connecting KEs to already existing genes in the supernetwork
selectNodes(nodes=KE_only_nodes,
by.col="Ensembl")
deleteSelectedNodes()
#Selecting and deleting nodes based on the prior criteria
commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_filtered_STRING_clustered_GO_KER default edge"', paste0(getwd(),"/CSVs/AOP/SNW_KER_edge.csv")))
SNW_KER_edge <- read.csv(paste0(getwd(),"/CSVs/AOP/SNW_KER_edge.csv"))
#Exporting the SNW edge table to file and loading it as R object
valid_KE_ensg <- SNW_KER_edge[grepl("ENSG", SNW_KER_edge$name) & grepl("aop.events", SNW_KER_edge$name),]
#Getting a list of KEs that do have interactions with genes
valid_KE <- str_extract(valid_KE_ensg$name, "https://identifiers.org/aop.events/\\S+")
valid_KE <- unique(valid_KE)
#Getting the URIs of the KEs that have interactions with genes
bad_KE_df <- SNW_KER_edge %>%
filter(
grepl("aop\\.events", name, ignore.case=TRUE) &
!grepl(paste(valid_KE, collapse="|"), name)
)
#Getting a list of the remaining KEs that are not associated with a gene or with a KE that is associated with a gene (to preserve KERs)
bad_KE_list <- str_extract_all(bad_KE_df$name, "https://identifiers\\.org/aop\\.events/\\d+")
bad_KE <- unique(unlist(bad_KE_list))
#Getting a list of unique bad KEs
selectNodes(nodes=bad_KE, by.col="name")
deleteSelectedNodes()
commandsRun(sprintf('network import file columnTypeList="s,ta,t,x,x" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t', paste0(getwd(),"/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
#Importing a list of AOPs associated with selected KEs that have prior been imported to the SNW
#The network contains numerous duplicate edges resulting from the way the SPARQL query is formulated
commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#Removing duplicate edges from current network
#RCy3 has a deleteDuplicateEdges function but it seems bugged since it always just removes 1 duplicate edge at a time
#Using the command line function removes all duplicate edges right away and avoids having to run a filter to select duplicate edges which is much slower
renameNetwork("KE-AOP")
commandsRun(sprintf('network import file columnTypeList="x,sa,s,ta,t" file=%s firstRowAsColumnNames=true startLoadRow=1 rootNetworkList="-- Create new network collection --" delimiters=\\t',paste0(getwd(), "/CSVs/AOP/AOPs_AOs_for_selected_KEs.tsv")))
commandsRun('analyzer remove duplicated edges createColumn=false ignoreDirection=false network=current')
#Removing duplicate edges from current network
renameNetwork("AOP-AO")
