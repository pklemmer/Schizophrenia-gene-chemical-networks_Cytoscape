commandsRun(sprintf("table create column columnName=Publication.doi table=%s type=string",nodetable))
commandsRun(sprintf("table create column columnName=fromSTRING table=%s type=string",nodetable))
#Creating a new column for each source used for all networks
if ( source == "STRINGnode") {
commandsRun(sprintf('table set values columnName=%1$s handleEquations=false rowList="selected:true" table=%2$s value=1',source,nodetable))
}
else {
commandsRun(sprintf("table set values columnName=%1$s handleEquations=false rowList=all table=%2$s value=1",source,nodetable))
#Filling the new column of the corresponding source with 1 to indicate which source the node is imported from
}
if (!is.null(doi)) {
commandsRun(sprintf("table set values columnName=Publication.doi handleEquations=false rowList=all table=%1$s value=%2$s",nodetable,doi))
#Adding doi for literature used if provided
}
}
#Function to create new column in node table specifying origin of network/node
disgenetRestUrl<-function(netType,host="127.0.0.1",port=1234,version="v7"){
if(is.null(netType)){
print("Network type not specified.")
}else{
disgeneturl<-sprintf("http://%s:%i/disgenet/%s/%s",host,port,version,netType)
}
return (disgeneturl)
}
net <- "gene-disease-net"
disgenetRestUrl(netType = net)
#Defining object for REST to call DisGeNET automation module; defining that we will be using gene-disease associations (GDA)
disgenetRestCall<-function(netType,netParams){
disgeneturl<-disgenetRestUrl(netType)
restCall<-POST(disgeneturl, body = netParams, encode = "json")
result<-content(restCall,"parsed")
return(result)
}
#Object that executes REST calls to DisGeNET module in Cytoscape
geneDisParams <- function(source,dis,min) {list(
source = source,
assocType = "Any",
diseaseClass = "Any",
diseaseSearch = dis,
geneSearch = " ",
initialScoreValue = min,
finalScoreValue = "1.0"
)}
#Specifying parameters of the GDA network to be imported
# SCHIZOPHRENIA =======================================================================================================================
## IMPORTING AND MERGING ---------------------------------------------------------------------------------------------------------------
start_section("Importing and merging")
sparqlquery("wp","metadataquery.txt","WikiPathways-SPARQL-metadata")
#Getting the metadata of the endpoint used for the WikiPathways SPARQL queries
metadata.add("WikiPathways SPARQL endpoint metadata")
metadata.add(`WikiPathways-SPARQL-metadata`)
#Adding the fetched metadata to the metadata file for the session
#It is technically possible that the metadata would describe an earlier version of the RDF if it is updated while the script runs but this is unlikely
sparqlquery("wp","pathwayquery.txt","wp_pathwaylist")
#Getting a list of pathways corresponding to a keyword as per defined in the query
writeLines(wp_pathwaylist[["PWID"]], con="Data/WikiPathways/Pathwaylists/automaticpathways.txt")
#Saving the output pathway list to file
manualpathways <- readLines("Data/WikiPathways/Pathwaylists/manualpathways.txt")
#Reading a file containing a list of manually selected pathways
allpathways <- c(wp_pathwaylist[["PWID"]],manualpathways)
#Joining the list of manually and automatically selected pathways together
allpathways_URL <- paste0("<",allpathways,">")
#Adding <> around all entries for easier use in SPARQL queries
#URLs need to be surrounded by <> to be recognised as such
writeLines(allpathways_URL, con="Data/WikiPathways/Pathwaylists/allpathways.txt")
#Writing list of all pathways in SPARQL URL format to file
genedisparams.scz.df <- read.table("Data/DisGeNET/disgenetparams-scz.txt",header=TRUE,sep = "\t")
#Loading relevant gene-disease networks from DisGeNET
#Networks of interest manually added into tsv where it is easier to adjust filters
disgeneturl <- c()
#Preparing container for DisGeNET URL to be saved for addition to metadata file
apply(genedisparams.scz.df,1,function(row) {
gdp <- geneDisParams(row["source"],row["dis"],row["min"])
disgeneturl <<- disgenetRestUrl(net)
#Fetching the DisGeNET URL used to make this call
geneDisResult <- disgenetRestCall(net,gdp)
#Executing the DisGeNET query
createNodeSource("fromDisGeNET")
#Adding information about data source to each node
mapTableColumn("geneId","Human","Entrez Gene","Ensembl")
#Mapping Entrez Gene IDs to Ensembl IDs
renameTableColumn("geneName","DisGeNETname")
})
#Importing networks from DisGeNET
metadata.add(paste("DisGeNET URL:",disgeneturl))
metadata.add(paste("DisGeNET net type:",net))
metadata.add("")
#Adding the DisGeNET URL and net type used to add networks to the metadata file
sparqlquery("wp","nodequery.txt","wp_nodelist")
#Making a SPARQL query to the endpoint to get all nodes associated with a list of pathways
if (any(grepl("identifiers\\.org", wp_nodelist$Identifier))) {
# Checking whether the 'Identifier' column contains the identifiers.org URL
#This is to avoid issues later when the identifiers.org part is removed and the code is reran
wp_nodelist$WPNodeIDType <- gsub(".*/([^/]+)/.*", "\\1", wp_nodelist$Identifier)
#If 'identifiers.org' is still in the column, extract part of the string into a new column to see what type the identifier is
} else {
# If 'identifiers.org' is not found, do nothing
}
wp_nodelist[] <- lapply(wp_nodelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
wp_nodelist$CNVassociated <- ifelse(grepl("copy number | CNV | deletion",wp_nodelist$PathwayTitle), 1, NA)
#Adding a new binary column showing if a given node is associated with a CNV based on pathway title
wp_nodelist$WPNodeID <- wp_nodelist$Identifier
#Generating a duplicate node identifier column since the original column will be lost during Cytoscape import due to it being selected as source column
write.table(wp_nodelist, file=paste0(getwd(),"/Data/WikiPathways/nodelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
#Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,sa,s,sa,sa,sa,sa,sa" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/Data/WikiPathways/nodelist.tsv")))
#Importing a list of nodes from the output of a WikiPathways SPARQL query (get all nodes in pathways matching the keyword 'Schizophrenia' and some manually selected pathways)
Sys.sleep(0.5)
#Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways nodes")
sparqlquery("wp","edgequery.txt","wp_edgelist")
#Making a SPARQL query to the endpoint to get a list of source-target pairs from selected pathways
wp_edgelist[] <- lapply(wp_edgelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
edge_df <- wp_edgelist[grepl("Interaction",wp_edgelist$source) | grepl("Interaction",wp_edgelist$target),]
#Extracting rows containing "Interaction" in either the source or target column
#Interaction nodes represent phosphorylation and the like and are not suitable for the network
#They can still provide information about the connection of gene or other nodes so they can't just be deleted either
#If an Interaction node is connected to two or more non-interaction nodes, these nodes should be connected to each other, and the interaction node can be deleted
interaction_freq <- table(edge_df$target)
edge_df_filtered <- edge_df[edge_df$target %in% names(interaction_freq[interaction_freq > 1]),]
#Counting if a certain interaction occurs more than once; this implies that it is connected to more than one non-interaction node
unique_targets <- unique(edge_df_filtered$target)
for (target_val in unique_targets) {
# Identify rows with duplicate target values
rows_with_duplicate_target <- which(edge_df_filtered$target == target_val)
if (length(rows_with_duplicate_target) > 1) {
# Select one of the source values
source_val_to_transpose <- edge_df_filtered$source[rows_with_duplicate_target[1]]
# Transpose the source value to the target column in the row of the remaining source value
edge_df_filtered$target[rows_with_duplicate_target[-1]] <- source_val_to_transpose
# Remove duplicate rows
edge_df_filtered <- edge_df_filtered[-rows_with_duplicate_target[1], ]
}
}
#Transposing the non-identifier nodes for source-target pairs; if two nodes are associated with the same interaction, they become source-target pairs
wp_edgelist <- wp_edgelist <- wp_edgelist[!grepl(".*interaction.*", wp_edgelist$source, ignore.case = TRUE) &
!grepl(".*interaction.*", wp_edgelist$target, ignore.case = TRUE), ]
#Removing any row containing "Interaction"
wp_edgelist <- rbind(wp_edgelist,edge_df_filtered)
#Appending the new source-target pairs to the original edge list
write.table(wp_edgelist, file=paste0(getwd(),"/Data/WikiPathways/edgelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
#Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,s,t" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(getwd(),"/Data/WikiPathways/edgelist.tsv")))
#Importing a list of source-target pairs from selected pathways from the ouput of a WikiPathways SPARQL query
Sys.sleep(0.5)
#Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways edges")
altmergeNetworks(sources = c("WikiPathways nodes","WikiPathways edges"),
title = "WikiPathways networks",
operation = "union",
nodeKeys=c("WPNodeID","name"))
#Union merging the node and edge networks to extend the node list with corresponding edges
Sys.sleep(0.5)
createNodeSource("fromWikiPathways")
deleteNetwork('WikiPathways nodes')
deleteNetwork('WikiPathways edges')
Sys.sleep(1)
#Pausing the script for 1 second - when letting the script run without this, the publication source creation fails
commandsRun(sprintf("network import file columnTypeList='sa,sa,source,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(getwd(),"/Data/Publications/Trubetskoy.txt")))
#Importing network from file
#List of 120 genes implicated in Trubetskoy et al., doi: 10.1038/s41586-022-04434-5
commandsRun("table rename column columnName=Ensembl.ID newColumnName=Ensembl table=Trubetskoy.txt default node")
#Renaming the Ensembl.ID column from the dataset to Ensembl for coherence with networks from other sources
commandsRun("table rename column columnName=Index.SNP newColumnName=snpID table=Trubetskoy.txt default node")
createNodeSource("fromPublication","10.1038/s41586-022-04434-5")
#Adding literature as  source to all imported nodes and adding the doi of the corresponding paper
renameNetwork("Trubetskoy risk genes")
#Renaming the newly imported network
metadata.add("Publications")
metadata.add("Trubetskoy et al. doi: 10.1038/s41586-022-04434-5")
metadata.add("")
networklist <- getNetworkList()
setCurrentNetwork(networklist[[1]])
for(i in 1:length(networklist)) {
current <- getNetworkName()
altmergeNetworks(c(current,networklist[[i]]), paste(current,networklist[[i]]),"union",inNetworkMerge = TRUE,nodeKeys=c("Ensembl","Ensembl"))
}
#Looping through the network list to merge all currently open networks with each other, creating one large unified network
renameNetwork("Schizophrenia supernetwork")
networklist <- getNetworkList()
snw_scz <- getNetworkName()
#Getting the name of the unified network to preserve it from deletion
lapply(networklist[networklist != snw_scz],deleteNetwork)
#Deleting all networks besides newly generated unified network
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW"),"CX", network = snw_scz, overwriteFile=TRUE)
#Exporting the supernetwork as cx file
end_section("Importing and merging")
## STRING --------------------------------------------------------------------------------------------------------------------------
start_section("STRING")
commandsRun('string stringify colDisplayName=name column=Ensembl compoundQuery=true cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
mapTableColumn("Ensembl","Human","Ensembl","HGNC")
#   #Generating a new column 'HGNC' from Ensembl identifiers - easier and less error-prone than merging various name columns from different import sources
renameTableColumn("HGNC","Name2")
#Renaming the new 'HGNC' column to 'Name2', which is now to be used as default name column. ('shared name' and 'name' columns are immutable and cannot be deleted or renamed)
marked_cols <- as.list(getTableColumnNames()[!(getTableColumnNames() %in% c("selected","name.copy" ,"SUID","shared name","name","fromDisGeNET","fromWikiPathways","Ensembl","fromPublication","Publication.doi","fromSTRING","CNVassociated","PathwayID","NodeID","NodeIDType","snpID","Name2","DisGeNETname"))])
lapply(marked_cols, function(column) {
deleteTableColumn(column=column)
})
#Filtering columns
renameNetwork("SCZ_SNW_STRING")
scz_snw_string <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING"),"CX",network=scz_snw_string,overwriteFile=TRUE)
#Exporting the filtered, stringified supernetwork as cx file and tagging it with the time and data to match with the metadata file
end_section("STRING")
## CLUSTERING ----------------------------------------------------------------------------------------------------------------------
start_section("Clustering")
createColumnFilter(filter.name="delete.noensembl", column="Ensembl","ENSG","DOES_NOT_CONTAIN")
deleteSelectedNodes()
#Filtering out nodes that do not have an ENSG Ensembl identifier mapped to them
# marked_cols <- as.list(getTableColumnNames()[!(getTableColumnNames() %in% c("selected","name.copy" ,"SUID","shared name","name","Name2","fromDisGeNET","fromWikiPathways","Ensembl","fromPublication","Publication.doi","fromSTRING","CNVassociated"))])
# lapply(marked_cols, function(column) {
#   deleteTableColumn(column=column)
# })
#Deleting all the columns besides immutable columns, Ensembl, name, and source columns
metadata.add("GLay Clustering")
metadata.add(capture.output(commandsRun('cluster glay clusterAttribute=__glayCluster createGroups=false network=current restoreEdges=true showUI=true undirectedEdges=true')))
#Clustering the network using the GLay community cluster from the clusterMaker Cytoscape app and recording outcome to metadata
renameNetwork("SCZ_SNW_STRING_clustered")
renameTableColumn('__glayCluster','gLayCluster')
#Renaming the newly generated gLayCluster column as the original name with two underscores is not recognized during gene ontology
snw_scz_string_clustered <- getNetworkName()
clustered_nodetable <- paste0(other_savepath,sprintf("/%s node table.csv",snw_scz_string_clustered))
#Saving the file path to the node table for easier reading (note the double space between node and table)
commandsRun(sprintf('table export options=CSV outputFile=%1$s table="%2$s default  node"',clustered_nodetable,snw_scz_string_clustered))
#Exporting the node table as .csv file to the current session's "Network" folder
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered"),"CX",network=snw_scz_string_clustered,overwriteFile=TRUE)
#Exporting the filtered, stringified, clustered supernetwork as cx file and tagging it with the time and data to match with the metadata file
read_clustered_nodetable <- read.csv(clustered_nodetable)
#Reading the exported csv
split_df <- split(read_clustered_nodetable$Ensembl,read_clustered_nodetable$gLayCluster)
#Splitting the node table by cluster
nodecount <- sapply(split_df, length)
#Counting how many nodes are in each cluster
countmatrix <- matrix(seq(1,length(nodecount)), ncol=1)
countmatrix <- cbind(countmatrix,as.numeric(nodecount))
#Construcing a matrix showing how many nodes are in each cluster
invalidclusters <- as.list(countmatrix[countmatrix[, 2] < 5, 1])
#Getting which clusters have fewer than 5 nodes associated with them
valid_clustered_nodetable <- read_clustered_nodetable[!read_clustered_nodetable$gLayCluster %in% invalidclusters, ]
#Generating a new df containing only nodes associated with clusters that had 5 or more nodes
split_tbl <- split(valid_clustered_nodetable, valid_clustered_nodetable$gLayCluster)
# test <- split_tbl[[1]]
# test2 <- test[, c("fromWikiPathways", "fromDisGeNET", "fromPublication")]
# colnames(test2) <- c("fromWikiPathways", "fromDisGeNET", "fromPublication")
#
# column_combinations_3 <- combn(colnames(test2),3,FUN=function(x) paste(x, collapse="_and_"))
# column_combinations_2 <- combn(colnames(test2),2,FUN=function(x) paste(x, collapse="_and_"))
# for (combination in column_combinations_2) {
#   test2[paste(combination,collapse="_and_")] <- test2[[combination[1]]] & test2[[combination[2]]]
# }
# for (combination in column_combinations_3) {
#   test2[paste(combination, collapse = "_")] <- test2[[combination[1]]] & test2[[combination[2]]] & test2[[combination[3]]]
# }
#
sourcecount <- function(cluster) {
wpcount <- sum(split_tbl[[cluster]][["fromWikiPathways"]] == 1, na.rm = TRUE)
dgcount <- sum(split_tbl[[cluster]][["fromDisGeNET"]] == 1, na.rm = TRUE)
litcount <- sum(split_tbl[[cluster]][["fromPublication"]] == 1, na.rm = TRUE)
stringcount <- sum(split_tbl[[cluster]][["fromSTRINGnode"]] == 1, na.rm = TRUE)
result_df <- data.frame(
gLayCluster = split_tbl[[cluster]][["gLayCluster"]][1],
WikiPathways_source = wpcount,
DisGeNET_source = dgcount,
Publication_source = litcount,
STRING_source = stringcount
)
}
sources_count <- do.call(rbind, lapply(seq_along(split_tbl),sourcecount))
#For each cluster, counting how many nodes are associated with which sources
cnvassociatedcount <- function(cluster) {
cnvcount <- sum(split_tbl[[cluster]][["CNVassociated"]] == 1,na.rm=TRUE)
total_wp_nodes <- sources_count[sources_count$gLayCluster == split_tbl[[cluster]][["gLayCluster"]][1], "WikiPathways_source"]
non_cnv_count <- total_wp_nodes - cnvcount
result_df <- data.frame(
gLayCluster = split_tbl[[cluster]][["gLayCluster"]][1],
WikiPathways_CNV = cnvcount,
WikiPathways_noCNV = non_cnv_count
)
}
cnvassociated_count <- do.call(rbind,lapply(seq_along(split_tbl),cnvassociatedcount))
#For each cluster, count how many nodes originally come from CNV-associated pathways which pathways they come from
end_section("Clustering")
## GO ANALYSIS ------------------------------------------------------------------------------------------------------------------------
start_section("GO Analysis")
split_df <- split(valid_clustered_nodetable$Ensembl,valid_clustered_nodetable$gLayCluster)
split_list <- lapply(split_df, as.vector)
#Splitting the node table by cluster number, i.e. lists of Ensembl IDs are created per cluster
go <- function(cluster) {
gost(
query = cluster,
organism = "hsapiens",
ordered_query = FALSE,
multi_query = TRUE,
significant = TRUE,
exclude_iea = FALSE,
measure_underrepresentation = FALSE,
evcodes = FALSE,
user_threshold = 0.05,
correction_method = "g_SCS",
domain_scope ="annotated",
custom_bg = NULL,
numeric_ns = "",
sources = NULL,
as_short_link = FALSE,
highlight = TRUE
)
}
go_list <- lapply(split_list,go)
#Iterating the gost GO function over all clusters
saveRDS(go_list, file=paste0(other_savepath,"/go_list.rds"))
#Saving the entire generated GO analysis as R object locally
get_top_terms <- function(cluster) {
terms <- toString(go_list[[cluster]][["result"]][["term_name"]][1:5])
#Extracting the top 5 term names associated with each cluster
pval <- toString(go_list[[cluster]][["result"]][["p_values"]][1:5])
#Extracting the p-values for the corresponding top 5 term names
nodes <- paste(go_list[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]],collapse=",")
nnodes <- str_count(toString(go_list[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]]),"\\S+")
#Extracing the number of nodes/genes contained in each cluster
result_df <- data.frame(
gLayCluster = cluster,
GO_Terms = terms,
GO_Pvals = pval,
Nodes = nodes,
N_nodes = nnodes
)
}
topterms_df <- do.call(rbind, lapply(names(go_list),get_top_terms))
#Getting top 5 term names and corresponding p-values for each cluster and storing in topterms_df
topterms_df <- cbind(topterms_df,sources_count,cnvassociated_count)
#joining the cluster table and the table detailing the amount of sources per cluster
write.table(topterms_df, file=paste0(getwd(),"/Data/GO-clusters-vis.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
#Writing the table to file for Cytoscape import during visualisation
loadTableData(topterms_df,data.key.column="gLayCluster",table.key.column="gLayCluster")
#Loading the generated top terms and p-values back to the supernetwork; every gene belonging to cluster x is now associated with the top terms of cluster x
deleteTableColumn('gLayCluster.1')
#Deleting duplicate gLayCluster column that appears after importing top terms data back to network
renameNetwork(title=paste0(getNetworkName(),"_GO"))
snw_scz_filtered_string_clustered_go <- getNetworkName()
#Renaming and saving the network name to indicate addition of GO information
compare_term_id_lists <- function(list1, list2) {
common_elements <- intersect(list1, list2)
return(length(common_elements))
}
#Setting up a function to get intersections between cluster term IDs
match_df <- data.frame(Cluster1 = character(),
Cluster2 = character(),
Matches = numeric(),
stringsAsFactors = FALSE)
#Setting up a df to store output in
for (i in 1:(length(go_list) - 1)) {
for (j in (i + 1):length(go_list)) {
term_id_i <- go_list[[i]][["result"]][["term_id"]]
term_id_j <- go_list[[j]][["result"]][["term_id"]]
matches <- compare_term_id_lists(term_id_i, term_id_j)
match_df <- rbind(match_df, data.frame(Cluster1 = names(go_list)[i],
Cluster2 = names(go_list)[j],
Matches = matches))
#Iterating over go_list to compare GO term IDs between every cluster and store number of overlaps
}
}
colnames(match_df) <- c("source","target","GO_term_matches")
#Renaming columns
write.table(match_df, file=paste0(getwd(),"/Data/match_df.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO"),"CX",network=snw_scz_filtered_string_clustered_go,overwriteFile=TRUE)
#Exporting the filtered, stringified, clustered supernetwork after GO as cx file and tagging it with the time and data to match with the metadata file
end_section("GO Analysis")
##AOP ---------------------------------------------------------------------------------------------------------------------------
start_section("AOP")
aopprocess <- function(input,tag) {
if (!"SCZ_SNW_STRING_clustered_GO" %in% getNetworkList()) {
importNetworkFromFile(file=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO.cx"))
commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
createColumnFilter(
filter.name = "has_GO_result",
column = "N_nodes",
criterion = 0,
predicate = "GREATER_THAN",
anyMatch = TRUE,
apply = TRUE
)
#Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
#Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way
#The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
}
else {
commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
createColumnFilter(
filter.name = "has_GO_result",
column = "N_nodes",
criterion = 0,
predicate = "GREATER_THAN",
anyMatch = TRUE,
apply = TRUE
)
#Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
#Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way
#The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
}
#Reimporting the network with GO information back to Cytoscape if needed
#Running aopprocess causes all changes to be applied to the GO network
#Running aopprocess a second time with other parameters would thus compound changes into the same network which is undesired
sparqlquery("AOP-Wiki",input,"keensgpairs")
#Querying AOP-Wiki for a list of all KEs and associated genes. KEs must be contained in an AOP that has an AO from a list of selected AOs
#Explicity listing keensgpairs so that it is caught by ls()
for (i in 1:ncol(keensgpairs)) {
for (j in 1:nrow(keensgpairs)) {
keensgpairs[j, i] <- gsub('"', '', keensgpairs[j, i])
}
}
#Removing quotation marks from the df
separate_keensgpairs <- separate_rows(keensgpairs,Ensembl,sep="; ")
#Dividing comma-separated Ensembl IDs into distinct rows
keensgpairs_byensg <- separate_keensgpairs %>%
group_by(Ensembl) %>%
summarise(KEid = paste(KEid, collapse="; "),
KEtitle = paste(KEtitle, collapse="; "),
AOid = paste(AOid, collapse="; "),
AOtitle = paste(AOtitle, collapse = "; "),
AOPid = paste(AOPid, collapse="; "),
AOPtitle =paste(AOPtitle, collapse="; "))
#Concateinating other variables based on unique Ensembl ID to get list of associated KEs, AOs, and AOPs per gene
keensgpairs_byensg_save <- paste0(getwd(),sprintf("/Data/AOP-Wiki/keensgpairs_byensg_%s.tsv",tag))
#Defining savepath for newly generated df
write.table(keensgpairs_byensg, file=keensgpairs_byensg_save,quote=FALSE, sep="\t", row.names=FALSE)
#Saving df containing gene-KE-AO-AOP associations to file as tsv for Cytoscape import
commandsRun(sprintf('table import file dataTypeTargetforNetworkCollection="Node Table Columns" delimiters=\\t file=%s firstRowAsColumnNames=true keyColumnForMapping="Ensembl" keyColumnIndex=1 startLoadRow=1',keensgpairs_byensg_save))
#Importing the gene-KE-AO-AOP table to Cytoscape as table add AOP-Wiki info as node attributes
renameNetwork(paste0(getNetworkName(),"_AOP"))
scz_snw_string_go_aop <- getNetworkName()
commandsRun(sprintf('table export options=CSV outputFile=%s table="SCZ_SNW_STRING_clustered_GO_AOP default  node"',paste0(other_savepath,"SCZ_SNW_STRING_GO_AOP default node","_",tag)))
#Exporting the network table
scz_snw_string_go_aop_node <- read.csv(file=paste0(other_savepath,"SCZ_SNW_STRING_GO_AOP default node","_",tag,".csv"),header=TRUE)
#Reading the exported table as Cytoscape object
aop_associated_genes <- scz_snw_string_go_aop_node[!(scz_snw_string_go_aop_node$KEid == ""), , drop=FALSE]
#Getting which rows (=gene nodes) have info from AOP-Wiki associated to them
renameNetwork(paste0(getNetworkName(),"_",tag))
summary_go_terms <- read.delim(paste0(getwd(),"/Data/summary_go_terms.txt"),header=TRUE,sep="\t",quote="")
#Loading cluster titles based on GO terms
aop_associated_genes <- merge(aop_associated_genes,summary_go_terms,"gLayCluster")
separate_aoptitles <- separate_rows(aop_associated_genes,AOPtitle,sep="; ")
aop_freq_table <- table(separate_aoptitles$AOPtitle)
aop_freq_df <- as.data.frame(aop_freq_table)
add_attributes <- separate_aoptitles %>%
group_by(AOPtitle) %>%
summarise (AOPEnsembl = paste(Ensembl,collapse="; "),
AOPgenename = paste(Name2, collapse="; "),
AOPsummary_go_term = paste(summary_term, collapse="; "))
names(aop_freq_df) <- c("AOPtitle","AOP frequency")
aop_freq_df_full <- merge(aop_freq_df, add_attributes,"AOPtitle")
#Counting how often which AOPs are associated with all genes
separate_aotitles <- separate_rows(aop_associated_genes,AOtitle,sep="; ")
ao_freq_table <- table(separate_aotitles$AOtitle)
ao_freq_df <- as.data.frame(ao_freq_table)
add_attributes <- separate_aotitles %>%
group_by(AOtitle) %>%
summarise (AOEnsembl = paste(Ensembl,collapse="; "),
AOgenename = paste(Name2, collapse="; "),
AOsummary_go_term = paste(summary_term, collapse="; "))
names(ao_freq_df) <- c("AOtitle","AO frequency")
ao_freq_df_full <- merge(ao_freq_df, add_attributes,"AOtitle")
#Counting how often which AOs are associated with all genes
separate_ketitles <- separate_rows(aop_associated_genes,KEtitle,sep="; ")
ke_freq_table <- table(separate_ketitles$KEtitle)
ke_freq_df <- as.data.frame(ke_freq_table)
add_attributes <- separate_ketitles %>%
group_by(KEtitle) %>%
summarise (KEEnsembl = paste(Ensembl,collapse="; "),
KEgenename = paste(Name2, collapse="; "),
KEsummary_go_term = paste(summary_term, collapse="; "))
names(ke_freq_df) <- c("KEtitle","KE frequency")
ke_freq_df_full <- merge(ke_freq_df, add_attributes,"KEtitle")
#Counting how often which KEs are associated with all genes
aop_associated_genes_freq <- bind_rows(aop_freq_df_full,ao_freq_df_full,ke_freq_df_full)
aop_link <- list()
variables <- ls()
#Getting a list of variables defined within the aopprocess function
#append_suffix <- function(variable, suffix) {
#assign(paste0(variable,"_",suffix), get(variable), envir = .GlobalEnv)
#}
#Defining a function to add a suffix to the variables created within the aopprocess function
for (variable in variables) {
aop_link[[variable]] <- get(variable)
}
return(aop_link)
#Appending the given tag to every produced variable within the aopprocess function
#Saving the resulting network
}
#Because a comparison should be made between selection criteria of the AOP-Wiki query,
#the aopprocess function is used to be more flexible in defining the query file
#as well as the suffix that is to be added so that the type of filter/query can be traced back
aoplink_selected <- aopprocess("AO_KE_Ensembl_query.txt","selected")
#Matching AOP information to risk genes in the network from selected adverse outcomes relating to neuronal development and psychiatric outcomes
snw_scz_string_clustered_GO_AOP_selected <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO_AOP_selected"),"CX",network=snw_scz_string_clustered_GO_AOP_selected,overwriteFile=TRUE)
#Exporting network
aoplink_all <- aopprocess("all_AO_KE_Ensembl_query.txt","all")
#Matching AOP information to risk genes in the network from all AOs available in AOP-Wiki
snw_scz_string_clustered_GO_AOP_all <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO_AOP_all"),"CX",network=snw_scz_string_clustered_GO_AOP_all,overwriteFile=TRUE)
#Exporting network
end_section("AOP")
