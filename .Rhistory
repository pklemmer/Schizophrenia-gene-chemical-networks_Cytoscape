Sys.sleep(0.5)
#Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways nodes")
sparqlquery("wp","edgequery.txt","wp_edgelist")
#Making a SPARQL query to the endpoint to get a list of source-target pairs from selected pathways
wp_edgelist[] <- lapply(wp_edgelist, function(x) str_replace_all(x, "https://identifiers\\.org/([^/]+)/", ""))
#Selecting and removing "https://identifiers.org/xyz" from every row in the df for improved readability
edge_df <- wp_edgelist[grepl("Interaction",wp_edgelist$source) | grepl("Interaction",wp_edgelist$target),]
#Extracting rows containing "Interaction" in either the source or target column
#Interaction nodes represent phosphorylation and the like and are not suitable for the network
#They can still provide information about the connection of gene or other nodes so they can't just be deleted either
#If an Interaction node is connected to two or more non-interaction nodes, these nodes should be connected to each other, and the interaction node can be deleted
interaction_freq <- table(edge_df$target)
edge_df_filtered <- edge_df[edge_df$target %in% names(interaction_freq[interaction_freq > 1]),]
#Counting if a certain interaction occurs more than once; this implies that it is connected to more than one non-interaction node
unique_targets <- unique(edge_df_filtered$target)
for (target_val in unique_targets) {
# Identify rows with duplicate target values
rows_with_duplicate_target <- which(edge_df_filtered$target == target_val)
if (length(rows_with_duplicate_target) > 1) {
# Select one of the source values
source_val_to_transpose <- edge_df_filtered$source[rows_with_duplicate_target[1]]
# Transpose the source value to the target column in the row of the remaining source value
edge_df_filtered$target[rows_with_duplicate_target[-1]] <- source_val_to_transpose
# Remove duplicate rows
edge_df_filtered <- edge_df_filtered[-rows_with_duplicate_target[1], ]
}
}
#Transposing the non-identifier nodes for source-target pairs; if two nodes are associated with the same interaction, they become source-target pairs
wp_edgelist <- wp_edgelist <- wp_edgelist[!grepl(".*interaction.*", wp_edgelist$source, ignore.case = TRUE) &
!grepl(".*interaction.*", wp_edgelist$target, ignore.case = TRUE), ]
#Removing any row containing "Interaction"
wp_edgelist <- rbind(wp_edgelist,edge_df_filtered)
#Appending the new source-target pairs to the original edge list
write.table(wp_edgelist, file=paste0(other_savepath,"WikiPathways/edgelist.tsv"), quote=FALSE, sep="\t", row.names=FALSE)
#Writing the modified file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList="sa,s,t" file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1 delimiters=\\t', paste0(other_savepath,"WikiPathways/edgelist.tsv")))
#Importing a list of source-target pairs from selected pathways from the ouput of a WikiPathways SPARQL query
Sys.sleep(0.5)
#Adding sys.sleep to give Cytoscape sufficient time to import the file as network; otherwise, renaming doesn't always work since no network is selected until the import is complete
renameNetwork("WikiPathways edges")
altmergeNetworks(sources = c("WikiPathways nodes","WikiPathways edges"),
title = "WikiPathways networks",
operation = "union",
nodeKeys=c("WPNodeID","name"))
#Union merging the node and edge networks to extend the node list with corresponding edges
Sys.sleep(0.5)
createNodeSource("fromWikiPathways")
metadata.add(paste0("WikiPathways nodes: ",getNodeCount()))
metadata.add("")
deleteNetwork('WikiPathways nodes')
deleteNetwork('WikiPathways edges')
Sys.sleep(1)
#Pausing the script for 1 second - when letting the script run without this, the publication source creation fails
commandsRun(sprintf("network import file columnTypeList='sa,sa,source,sa,sa,sa,sa' file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1", paste0(getwd(),"/Data/Publications/Trubetskoy.txt")))
#Importing network from file
#List of 120 genes implicated in Trubetskoy et al., doi: 10.1038/s41586-022-04434-5
commandsRun("table rename column columnName=Ensembl.ID newColumnName=Ensembl table=Trubetskoy.txt default node")
#Renaming the Ensembl.ID column from the dataset to Ensembl for coherence with networks from other sources
commandsRun("table rename column columnName=Index.SNP newColumnName=snpID table=Trubetskoy.txt default node")
createNodeSource("fromPublication","10.1038/s41586-022-04434-5")
#Adding literature as  source to all imported nodes and adding the doi of the corresponding paper
renameNetwork("Trubetskoy risk genes")
#Renaming the newly imported network
metadata.add("Publications")
metadata.add("Trubetskoy et al. doi: 10.1038/s41586-022-04434-5")
metadata.add(paste0("Publication nodes: ",getNodeCount()))
metadata.add("")
sparqlquery("AOP-Wiki","metadataquery.txt","aopwikimetadata")
aopwikimetadata <- paste(aopwikimetadata$dataset, aopwikimetadata$date, sep ="\t")
metadata.add("AOP-Wiki")
metadata.add("AOP-Wiki SPARQL endpoint metadata:")
metadata.add(paste("Dataset","Date",sep="\t"))
metadata.add(aopwikimetadata)
metadata.add("")
networklist <- getNetworkList()
setCurrentNetwork(networklist[[1]])
for(i in 1:length(networklist)) {
current <- getNetworkName()
altmergeNetworks(c(current,networklist[[i]]), paste(current,networklist[[i]]),"union",inNetworkMerge = TRUE,nodeKeys=c("Ensembl","Ensembl"))
}
#Looping through the network list to merge all currently open networks with each other, creating one large unified network
renameNetwork("Schizophrenia supernetwork")
networklist <- getNetworkList()
snw_scz <- getNetworkName()
#Getting the name of the unified network to preserve it from deletion
lapply(networklist[networklist != snw_scz],deleteNetwork)
#Deleting all networks besides newly generated unified network
snw_ensembl <- getTableColumns("node","Ensembl")
#Getting all values in the Ensembl column of the supernetwork
input <- data.frame(
source = rep("En", length(snw_ensembl[, 1])),
identifier = snw_ensembl[, 1]
)
#Making a new df to be used as input for bridgedb
#Map Ensembl ID
snw_map <- maps(mapper,input,"H")
#Mapping from Ensembl to HGNC
snw_map <- select(snw_map, c("identifier", "mapping"))
snw_map <- rename(snw_map,
Ensembl = identifier,
HGNCsymbol = mapping)
#Selecting and renaming relevant columns from bridgeDb mapping output
loadTableData(snw_map,
data.key.column = "Ensembl",
table = "node",
table.key.column = "Ensembl")
#loading HGNC names for Ensembl IDs in supernetwork back to node table
snw_nostring_edges <- getEdgeCount()
metadata.add(paste0("Total nodes in supernetwork: ",getNodeCount()))
metadata.add("")
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW"),"CX", network = snw_scz, overwriteFile=TRUE)
#Exporting the supernetwork as cx file
end_section("Importing and merging")
# stable <- getTableColumns("node",c("fromDisGeNET","fromPublication","fromWikiPathways"))
# stable$count_ones <- rowSums(!is.na(stable))
# combination_counts <- table(stable$count_ones)
#
# sourcenames <- c("One source","Two sources","Three sources")
# visframe <- data.frame(sourcenames,combination_counts)
# visframe <- select(visframe, -Var1)
# visframe <- visframe %>%
#   mutate(relative_freq = Freq / sum(Freq))
#
# ggplot(visframe,aes(x=factor(sourcenames,levels=c("One source","Two sources","Three sources")),y=Freq)) +
#   geom_bar(stat="identity", fill = 'darkorange2', width=0.5) +
#   labs(x=NULL,  y = "Counts", title = "Node counts by source") +
#   scale_y_continuous(trans="log10", breaks=c(1,10,100,1000,2000)) +
#   theme_minimal()
## STRING --------------------------------------------------------------------------------------------------------------------------
start_section("STRING")
commandsRun('string stringify colDisplayName=name column=Ensembl compoundQuery=true cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
#Interactions between nodes are poorly preserved during importing and merging, and really only WikiPathways provides edge information while DisGeNET and the publication only provide gene lists
metadata.add("STRING")
metadata.add("STRINGify parameters:")
metadata.add("- Perform STRINGification on: Ensembl")
metadata.add("- Query compounds: true")
metadata.add("- Cutoff: 0.9")
snw_string_edges <- getEdgeCount()
metadata.add(paste0("STRING-added edges: ",snw_string_edges - snw_nostring_edges))
metadata.add(paste0("Total edges in supernetwork: ",snw_string_edges))
metadata.add("")
marked_cols <- as.list(getTableColumnNames()[!(getTableColumnNames() %in% c("selected","name.copy" ,"SUID","shared name","name","fromDisGeNET","fromWikiPathways","Ensembl","fromPublication","Publication.doi","CNVassociated","PathwayID","WPNodeID","WPNodeIDType","snpID","HGNCsymbol","DisGeNETname","disgenet_curated","gdascore","Entrez_gene"))])
lapply(marked_cols, function(column) {
deleteTableColumn(column=column)
})
#Filtering columns
renameNetwork("SCZ_SNW_STRING")
scz_snw_string <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING"),"CX",network=scz_snw_string,overwriteFile=TRUE)
#Exporting the filtered, stringified supernetwork as cx file and tagging it with the time and data to match with the metadata file
end_section("STRING")
## CLUSTERING ----------------------------------------------------------------------------------------------------------------------
start_section("Clustering")
createColumnFilter(filter.name="delete.noensembl", column="Ensembl","ENSG","DOES_NOT_CONTAIN")
deleteSelectedNodes()
metadata.add(paste0("Ensembl nodes in supernetwork: ",getNodeCount()))
metadata.add("")
metadata.add("GLay Clustering")
metadata.add(capture.output(commandsRun('cluster glay clusterAttribute=__glayCluster createGroups=false network=current restoreEdges=true showUI=true undirectedEdges=true')))
#Clustering the network using the GLay community cluster from the clusterMaker Cytoscape app and recording outcome to metadata
renameNetwork("SCZ_SNW_STRING_clustered")
renameTableColumn('__glayCluster','gLayCluster')
#Renaming the newly generated gLayCluster column as the original name with two underscores is not recognized during gene ontology
snw_scz_string_clustered <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered"),"CX",network=snw_scz_string_clustered,overwriteFile=TRUE)
#Exporting the filtered, stringified, clustered supernetwork as cx file and tagging it with the time and data to match with the metadata file
read_clustered_nodetable <- getTableColumns("node")
#Reading the exported csv
split_df <- split(read_clustered_nodetable$Ensembl,read_clustered_nodetable$gLayCluster)
#Splitting the node table by cluster
nodecount <- sapply(split_df, length)
#Counting how many nodes are in each cluster
countmatrix <- matrix(seq(1,length(nodecount)), ncol=1)
countmatrix <- cbind(countmatrix,as.numeric(nodecount))
#Construcing a matrix showing how many nodes are in each cluster
invalidclusters <- as.list(countmatrix[countmatrix[, 2] < 5, 1])
#Getting which clusters have fewer than 5 nodes associated with them
valid_clustered_nodetable <- read_clustered_nodetable[!read_clustered_nodetable$gLayCluster %in% invalidclusters, ]
#Generating a new df containing only nodes associated with clusters that had 5 or more nodes
split_tbl <- split(valid_clustered_nodetable, valid_clustered_nodetable$gLayCluster)
# test <- split_tbl[[1]]
# test2 <- test[, c("fromWikiPathways", "fromDisGeNET", "fromPublication")]
# colnames(test2) <- c("fromWikiPathways", "fromDisGeNET", "fromPublication")
#
# column_combinations_3 <- combn(colnames(test2),3,FUN=function(x) paste(x, collapse="_and_"))
# column_combinations_2 <- combn(colnames(test2),2,FUN=function(x) paste(x, collapse="_and_"))
# for (combination in column_combinations_2) {
#   test2[paste(combination,collapse="_and_")] <- test2[[combination[1]]] & test2[[combination[2]]]
# }
# for (combination in column_combinations_3) {
#   test2[paste(combination, collapse = "_")] <- test2[[combination[1]]] & test2[[combination[2]]] & test2[[combination[3]]]
# }
#
sourcecount <- function(cluster) {
wpcount <- sum(split_tbl[[cluster]][["fromWikiPathways"]] == 1, na.rm = TRUE)
dgcount <- sum(split_tbl[[cluster]][["fromDisGeNET"]] == 1, na.rm = TRUE)
litcount <- sum(split_tbl[[cluster]][["fromPublication"]] == 1, na.rm = TRUE)
result_df <- data.frame(
gLayCluster = split_tbl[[cluster]][["gLayCluster"]][1],
WikiPathways_source = wpcount,
DisGeNET_source = dgcount,
Publication_source = litcount
)
}
sources_count <- do.call(rbind, lapply(seq_along(split_tbl),sourcecount))
#For each cluster, counting how many nodes are associated with which sources
cnvassociatedcount <- function(cluster) {
cnvcount <- sum(split_tbl[[cluster]][["CNVassociated"]] == 1,na.rm=TRUE)
total_wp_nodes <- sources_count[sources_count$gLayCluster == split_tbl[[cluster]][["gLayCluster"]][1], "WikiPathways_source"]
non_cnv_count <- total_wp_nodes - cnvcount
result_df <- data.frame(
gLayCluster = split_tbl[[cluster]][["gLayCluster"]][1],
WikiPathways_CNV = cnvcount,
WikiPathways_noCNV = non_cnv_count
)
}
cnvassociated_count <- do.call(rbind,lapply(seq_along(split_tbl),cnvassociatedcount))
#For each cluster, count how many nodes originally come from CNV-associated pathways which pathways they come from
end_section("Clustering")
## GO ANALYSIS ------------------------------------------------------------------------------------------------------------------------
start_section("GO Analysis")
split_df <- split(valid_clustered_nodetable$Ensembl,valid_clustered_nodetable$gLayCluster)
split_list <- lapply(split_df, as.vector)
#Splitting the node table by cluster number, i.e. lists of Ensembl IDs are created per cluster
go <- function(cluster) {
gost(
query = cluster,
organism = "hsapiens",
ordered_query = FALSE,
multi_query = TRUE,
significant = TRUE,
exclude_iea = FALSE,
measure_underrepresentation = FALSE,
evcodes = FALSE,
user_threshold = 0.05,
correction_method = "g_SCS",
domain_scope ="annotated",
custom_bg = NULL,
numeric_ns = "",
sources = NULL,
as_short_link = FALSE,
highlight = TRUE
)
}
go_list <- lapply(split_list,go)
#Iterating the gost GO function over all clusters
get_top_terms <- function(cluster) {
terms <- toString(go_list[[cluster]][["result"]][["term_name"]][1:5])
#Extracting the top 5 term names associated with each cluster
pval <- toString(go_list[[cluster]][["result"]][["p_values"]][1:5])
#Extracting the p-values for the corresponding top 5 term names
nodes <- paste(go_list[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]],collapse=",")
nnodes <- str_count(toString(go_list[[cluster]][["meta"]][["query_metadata"]][["queries"]][["query_1"]]),"\\S+")
#Extracing the number of nodes/genes contained in each cluster
result_df <- data.frame(
gLayCluster = cluster,
GO_Terms = terms,
GO_Pvals = pval,
Nodes = nodes,
N_nodes = nnodes
)
}
topterms_df <- do.call(rbind, lapply(names(go_list),get_top_terms))
#Getting top 5 term names and corresponding p-values for each cluster and storing in topterms_df
topterms_df <- cbind(topterms_df,sources_count,cnvassociated_count)
#joining the cluster table and the table detailing the amount of sources per cluster
write.table(topterms_df, file=paste0(other_savepath,"Clustering/GO-clusters-vis.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
#Writing the table to file for Cytoscape import during visualisation
loadTableData(topterms_df,data.key.column="gLayCluster",table.key.column="gLayCluster")
#Loading the generated top terms and p-values back to the supernetwork; every gene belonging to cluster x is now associated with the top terms of cluster x
deleteTableColumn('gLayCluster.1')
#Deleting duplicate gLayCluster column that appears after importing top terms data back to network
renameNetwork(title=paste0(getNetworkName(),"_GO"))
snw_scz_filtered_string_clustered_go <- getNetworkName()
#Renaming and saving the network name to indicate addition of GO information
compare_term_id_lists <- function(list1, list2) {
common_elements <- intersect(list1, list2)
return(length(common_elements))
}
#Setting up a function to get intersections between cluster term IDs
match_df <- data.frame(Cluster1 = character(),
Cluster2 = character(),
Matches = numeric(),
stringsAsFactors = FALSE)
#Setting up a df to store output in
for (i in 1:(length(go_list) - 1)) {
for (j in (i + 1):length(go_list)) {
term_id_i <- go_list[[i]][["result"]][["term_id"]]
term_id_j <- go_list[[j]][["result"]][["term_id"]]
matches <- compare_term_id_lists(term_id_i, term_id_j)
match_df <- rbind(match_df, data.frame(Cluster1 = names(go_list)[i],
Cluster2 = names(go_list)[j],
Matches = matches))
#Iterating over go_list to compare GO term IDs between every cluster and store number of overlaps
}
}
colnames(match_df) <- c("source","target","GO_term_matches")
#Renaming columns
write.table(match_df, file=paste0(other_savepath,"Clustering/match_df.tsv"), sep = "\t",row.names=FALSE,quote=FALSE)
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO"),"CX",network=snw_scz_filtered_string_clustered_go,overwriteFile=TRUE)
#Exporting the filtered, stringified, clustered supernetwork after GO as cx file and tagging it with the time and data to match with the metadata file
end_section("GO Analysis")
##AOP-Wiki extension ---------------------------------------------------------------------------------------------------------------------------
start_section("AOP-Wiki extension")
aopprocess <- function(input,keep,tag) {
if (!"SCZ_SNW_STRING_clustered_GO" %in% getNetworkList()) {
importNetworkFromFile(file=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO.cx"))
commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
createColumnFilter(
filter.name = "has_GO_result",
column = "N_nodes",
criterion = 0,
predicate = "GREATER_THAN",
anyMatch = TRUE,
apply = TRUE
)
#Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
#Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way
#The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
}
else {
commandsRun('table delete column column="gLayCluster.2" table="SCZ_SNW_STRING_clustered_GO default node')
createColumnFilter(
filter.name = "has_GO_result",
column = "N_nodes",
criterion = 0,
predicate = "GREATER_THAN",
anyMatch = TRUE,
apply = TRUE
)
#Selecting nodes included in a 'valid' cluster, i.e. clusters with 5 or more nodes (GO analysis only performed for these)
#N_nodes is only generated for 'valid' clusters, so good column to filter by
invertNodeSelection()
deleteSelectedNodes()
#Inverting the selection and deleting these nodes: now, the network contains only the nodes that make up the clusters fed into the GO analysis
#Nodes not associated to a large enough cluster/GO term are likely not involved in any significant SCZ-contributing way
#The idea is to link GO terms (formed by clusters/genes) to risk factors, so it wouldn't make sense to also link non-cluster/GO associated nodes
}
#Reimporting the network with GO information back to Cytoscape if needed
#Running aopprocess causes all changes to be applied to the GO network
#Running aopprocess a second time with other parameters would thus compound changes into the same network which is undesired
sparqlquery("AOP-Wiki",input,"keensgpairs")
#Querying AOP-Wiki for a list of all KEs and associated genes
for (i in 1:ncol(keensgpairs)) {
for (j in 1:nrow(keensgpairs)) {
keensgpairs[j, i] <- gsub('"', '', keensgpairs[j, i])
}
}
#Removing quotation marks from the df
separate_keensgpairs <- separate_rows(keensgpairs,Ensembl,sep="; ")
#Dividing comma-separated Ensembl IDs into distinct rows
keensgpairs_byensg <- separate_keensgpairs %>%
group_by(Ensembl) %>%
summarise(KEid = paste(KEid, collapse="; "),
AOPid = paste(AOPid, collapse="; "))
#Concatenating other variables based on unique Ensembl ID to get list of associated KEs and AOPs per gene
keensgpairs_byensg_save <- paste0(other_savepath,sprintf("AOP-Wiki/keensgpairs_byensg_%s.tsv",tag))
#Defining savepath for newly generated df
write.table(keensgpairs_byensg, file=keensgpairs_byensg_save,quote=FALSE, sep="\t", row.names=FALSE)
#Saving df containing gene-KE-AO-AOP associations to file as tsv for Cytoscape import
commandsRun(sprintf('table import file dataTypeTargetforNetworkCollection="Node Table Columns" delimiters=\\t file=%s firstRowAsColumnNames=true keyColumnForMapping="Ensembl" keyColumnIndex=1 startLoadRow=1',keensgpairs_byensg_save))
#Importing the gene-KE-AO-AOP table to Cytoscape as table add AOP-Wiki info as node attributes
renameNetwork(paste0(getNetworkName(),"_AOP"))
scz_snw_string_go_aop <- getNetworkName()
scz_snw_string_go_aop_node <- getTableColumns("node")
#Reading the exported table as Cytoscape object
aop_associated_genes <- scz_snw_string_go_aop_node[!is.na(scz_snw_string_go_aop_node$KEid), , drop=FALSE]
#Getting which rows (=gene nodes) have info from AOP-Wiki associated to them
renameNetwork(paste0(getNetworkName(),"_",tag))
summary_go_terms <- read.delim(paste0(getwd(),"/Data/summary_go_terms.txt"),header=TRUE,sep="\t",quote="")
#Loading cluster titles based on GO terms
if(keep == TRUE) {
aop_associated_genes <- scz_snw_string_go_aop_node }
aop_associated_genes <- merge(aop_associated_genes,summary_go_terms,"gLayCluster")
Sys.sleep(1)
separate_ketitles <- separate_rows(aop_associated_genes,KEid,sep="; ")
ke_freq_table <- table(separate_ketitles$KEid)
ke_freq_df <- as.data.frame(ke_freq_table)
add_attributes <- separate_ketitles %>%
group_by(KEid) %>%
summarise (KEEnsembl = paste(Ensembl,collapse="; "),
KEgenename = paste(HGNCsymbol, collapse="; "),
KEsummary_go_term = paste(summary_term, collapse="; "))
names(ke_freq_df) <- c("KEid","KE_frequency")
ke_freq_df_full <- merge(ke_freq_df, add_attributes,"KEid",all.y=TRUE)
#Counting how often which KEs are associated with all genes
ke_associated_genes_freq <- ke_freq_df_full
aop_link <- list()
variables <- ls()
#Getting a list of variables defined within the aopprocess function
#append_suffix <- function(variable, suffix) {
#assign(paste0(variable,"_",suffix), get(variable), envir = .GlobalEnv)
#}
#Defining a function to add a suffix to the variables created within the aopprocess function
for (variable in variables) {
aop_link[[variable]] <- get(variable)
}
return(aop_link)
#Appending the given tag to every produced variable within the aopprocess function
#Saving the resulting network
}
aoplink_all <- aopprocess("all_AO_KE_Ensembl_query.txt",TRUE,"all")
#Second function argument specifies whether to save all (gene) rows from the network (=true) or only rows that have AOP-Wiki data ssociated with them
#Matching AOP information to risk genes in the network from all AOs available in AOP-Wiki
snw_scz_string_clustered_GO_AOP_all <- getNetworkName()
exportNetwork(filename=paste0(nw_savepath,"SCZ_SNW_STRING_clustered_GO_AOP_all"),"CX",network=snw_scz_string_clustered_GO_AOP_all,overwriteFile=TRUE)
#Exporting network
nclusters <- as.character(count(unique(getTableColumns("node","gLayCluster"))))
#Counting how many valid clusters remain
metadata.add(paste0("Valid (>= 5 nodes) clusters: ",nclusters))
metadata.add(paste0("Nodes associated with valid clusters: ",getNodeCount()))
metadata.add("")
gettop <- function(input) {
freq_df <- input$ke_freq_df_full
#cutoff_ke <- quantile(freq_df$KE_frequency, probs=0.75,na.rm = TRUE)
#Defining cutoff for KE frequency (top 25% most frequent)
#topquarter_ke <- freq_df[freq_df$KE_frequency >= cutoff_ke & !is.na(freq_df$KE_frequency),,drop=FALSE]
#Selecting the top 25% most frequently matched with KEs and associated information
topquarter_ke <- freq_df
}
top_all <- gettop(aoplink_all)
getkegenepairs <- function(input) {
topquarter_ke <- input
topquarter_ke_sep <- separate_rows(topquarter_ke,KEEnsembl,sep="; ")
mergedkeensg <- union(topquarter_ke_sep$KEid,topquarter_ke_sep$KEEnsembl)
#topquarter_ke_node <- data.frame(combined=mergedkeensg)
topquarter_ke<- topquarter_ke_sep[,c("KEid","KEEnsembl")]
topquarter_ke <- topquarter_ke %>%
rename(KEid_source = KEid,
KEEnsembl_target = KEEnsembl)
#Renaming columns to source and target for Cytoscape import
topquarter_ke$KEid <- topquarter_ke$KEid_source
topquarter_ke$Ensembl <- topquarter_ke$KEEnsembl_target
#Creating duplicate columns of KEid and KEEnsembl to be used as source and target attributes
#This allows new columns in the network to easily select Ensembl and KE nodes separately etc.
#Without this, both KE and Ensembl nodes are stored in the 'names' column due to how Cytoscape import works
sparqlquery("AOP-Wiki","kemap.txt","kemap")
#Running query to get KEid-title mappings
for (i in 1:ncol(kemap)) {
for (j in 1:nrow(kemap)) {
kemap[j, i] <- gsub('"', '', kemap[j, i])
}
}
#Removing quotation marks from df
topquarter_ke <- merge(topquarter_ke,kemap,by="KEid",all.x=TRUE)
#Merging the mapping and node tables to extend node table with KE titles
topquarter_ke <- topquarter_ke[,c("KEid_source","KEEnsembl_target","KEid","KEtitle","Ensembl")]
#Reordering table columns
#write.table(topquarter_ke_node, file=paste0(getwd(),"/topquarter_ke_node.tsv"),sep="\t",quote=FALSE,row.names=FALSE)
write.table(topquarter_ke, file=paste0(other_savepath,sprintf("AOP-Wiki/topquarter_ke_edge%s.tsv",sub("top","",deparse(substitute(input))))),sep="\t",quote=FALSE,row.names=FALSE)
#Writing the KE-gene table to file for Cytoscape import
commandsRun(sprintf('network import file columnTypeList=s,t,sa,sa,ta delimiters=\\t file=%s firstRowAsColumnNames=true rootNetworkList=-- Create new network collection -- startLoadRow=1',paste0(other_savepath,sprintf("AOP-Wiki/topquarter_ke_edge%s.tsv",sub("top","",deparse(substitute(input)))))))
#Importing as network
Sys.sleep(0.5)
renameNetwork(sprintf("Top quarter key events - risk genes%s",sub("top","",deparse(substitute(input)))))
}
getkegenepairs(top_all)
kegenenetwork_all <- getNetworkName()
selectNodes("NA","KEid")
deleteSelectedNodes()
#Selecting and deleting a 'NA' node that results from all the genes not associated to any AOP data
getkeaoppairs <- function(input) {
keaoppairs <- keensgpairs[keensgpairs$KEid %in% input$KEid,c("KEid","AOPid")]
#For top quarter KEs, get which AOPs these are taken from from result of initial AOP-Wiki query
keaoppairs <- separate_rows(keaoppairs,AOPid,sep="; ")
sparqlquery("AOP-Wiki","aopmap.txt","aopmap")
#Running query to get AOPid-title mappings
for (i in 1:ncol(aopmap)) {
for (j in 1:nrow(aopmap)) {
aopmap[j, i] <- gsub('"', '', aopmap[j, i])
}
}
#Removing quotation marks from df
keaoppairs <- merge(keaoppairs,aopmap,by="AOPid",all.x=FALSE)
#Mapping AOPids to AOPtitles using mapping file
keaoppairs <- keaoppairs %>%
rename(KEid_target = KEid,
AOPid_source = AOPid)
#Renaming columns in preparation for import
keaoppairs$KEid <- keaoppairs$KEid_target
keaoppairs$AOPid <- keaoppairs$AOPid_source
#Creating duplicate columns of KEid and AOPid to be used as source and target attributes
#This allows new columns in the network to easily select AOP and KE nodes separately etc.
#Without this, both KE and AOP nodes are stored in the 'names' column due to how Cytoscape import works
keaoppairs <- keaoppairs[,c("KEid_target","KEid","AOPid_source","AOPid","AOPtitle")]
#Reordering columns
write.table(keaoppairs,file=paste0(other_savepath,sprintf("AOP-Wiki/keaoppairs%s.tsv",sub("top","",deparse(substitute(input))))),sep="\t",quote=FALSE,row.names=FALSE)
#Writing modified table to file
commandsRun(sprintf('network import file columnTypeList=t,ta,s,sa,sa delimiters=\\t file=%s firstRowAsColumnNames=true rootNetworkList= -- Create new network collection -- startLoadRow=1',paste0(other_savepath,sprintf("AOP-Wiki/keaoppairs%s.tsv",sub("top","",deparse(substitute(input)))))))
#Importing as network
Sys.sleep(0.5)
renameNetwork(sprintf("Top quarter key events - AOPs%s",sub("top","",deparse(substitute(input)))))
}
#Selecting and deleting a 'NA' node that results from all the genes not associated to any AOP data
commandsRun('string stringify colDisplayName=name column=Ensembl compoundQuery=false cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
#Selecting and deleting a 'NA' node that results from all the genes not associated to any AOP data
commandsRun('string stringify colDisplayName=label column=Ensembl compoundQuery=false cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
#Selecting and deleting a 'NA' node that results from all the genes not associated to any AOP data
gene_ke_edge <- getTableColumns("edge")
commandsRun('string stringify colDisplayName=label column=Ensembl compoundQuery=false cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
View(gene_ke_edge)
?loadTableData
commandsRun('string stringify colDisplayName=label column=Ensembl compoundQuery=false cutoff=0.9 includeNotMapped=true  networkType="full STRING network" species="Homo sapiens" networkNoGui=current')
altmergeNetworks(sources = c("Top quarter key events - risk genes_all", "STRING network - Top quarter key events - risk genes_all"),
title = "Top quarter key events - risk genes_all STRINGified",
operation = "union",
nodeKeys = c("shared name","shared name"))
